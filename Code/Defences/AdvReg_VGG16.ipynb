{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdvReg_VGG16.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c6a8b865b8843859e2c50a56c0bcf37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57a25f6448a546699feb4b1990180ec3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_785878a5be2e444daa8c45473a7f8850",
              "IPY_MODEL_961fe676dff540a9b0fb1d7f30b76b59"
            ]
          }
        },
        "57a25f6448a546699feb4b1990180ec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "785878a5be2e444daa8c45473a7f8850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d9b0d5fa7fe4ed6a4c88cfb948fdb42",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a186a18708f42e0be144efde10a2420"
          }
        },
        "961fe676dff540a9b0fb1d7f30b76b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c5cceec75021423aa51f06302ab88bfe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "170500096it [00:30, 17129940.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f51c8cbd76e46ee8b6c7b4f9a12f97c"
          }
        },
        "5d9b0d5fa7fe4ed6a4c88cfb948fdb42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a186a18708f42e0be144efde10a2420": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5cceec75021423aa51f06302ab88bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f51c8cbd76e46ee8b6c7b4f9a12f97c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhnG_uaW7tW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "import uuid\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as datasets\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Pxtf1y7XLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\n",
        "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImjIoRyR2QBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# VGG\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "cfg = {\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG13': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG19': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, vgg_name):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg[vgg_name])\n",
        "        self.classifier = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.classifier(out)\n",
        "        return out\n",
        "\n",
        "    def _make_layers(self, cfg):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for x in cfg:\n",
        "            if x == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
        "                           nn.BatchNorm2d(x),\n",
        "                           nn.ReLU(inplace=True)]\n",
        "                in_channels = x\n",
        "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "\n",
        "class InferenceAttack_HZ(nn.Module):\n",
        "    def __init__(self,num_classes):\n",
        "        self.num_classes=num_classes\n",
        "        super(InferenceAttack_HZ, self).__init__()\n",
        "        self.features=nn.Sequential(\n",
        "            nn.Linear(10,1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,64),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "        self.labels=nn.Sequential(\n",
        "           nn.Linear(num_classes,128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,64),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "        self.combine=nn.Sequential(\n",
        "            nn.Linear(64*2,256),\n",
        "            \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,128),\n",
        "            \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,1),\n",
        "            )\n",
        "        for key in self.state_dict():\n",
        "            print (key)\n",
        "            if key.split('.')[-1] == 'weight':    \n",
        "                nn.init.normal(self.state_dict()[key], std=0.01)\n",
        "                print (key)\n",
        "                \n",
        "            elif key.split('.')[-1] == 'bias':\n",
        "                self.state_dict()[key][...] = 0\n",
        "        self.output= nn.Sigmoid()\n",
        " \n",
        "    def forward(self,x,l):       \n",
        "        out_x = self.features(x)\n",
        "        out_l = self.labels(l)      \n",
        "        is_member =self.combine( torch.cat((out_x  ,out_l),1))     \n",
        "        return self.output(is_member)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Md2tk-H4k1M",
        "colab_type": "code",
        "outputId": "83cdca0b-f375-4f87-e5a1-411c6e524d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "batch_privacy=100\n",
        "train_batch=100\n",
        "test_batch=100\n",
        "lr=0.05\n",
        "state={}\n",
        "state['lr']=lr\n",
        "\n",
        "\n",
        "model = VGG('VGG16')\n",
        "model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_attack = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "inferenece_model = InferenceAttack_HZ(10).cuda()\n",
        "private_train_criterion = nn.MSELoss()\n",
        "optimizer_mem = optim.Adam(inferenece_model.parameters(), lr=0.00001)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features.0.weight\n",
            "features.0.weight\n",
            "features.0.bias\n",
            "features.2.weight\n",
            "features.2.weight\n",
            "features.2.bias\n",
            "features.4.weight\n",
            "features.4.weight\n",
            "features.4.bias\n",
            "labels.0.weight\n",
            "labels.0.weight\n",
            "labels.0.bias\n",
            "labels.2.weight\n",
            "labels.2.weight\n",
            "labels.2.bias\n",
            "combine.0.weight\n",
            "combine.0.weight\n",
            "combine.0.bias\n",
            "combine.2.weight\n",
            "combine.2.weight\n",
            "combine.2.bias\n",
            "combine.4.weight\n",
            "combine.4.weight\n",
            "combine.4.bias\n",
            "combine.6.weight\n",
            "combine.6.weight\n",
            "combine.6.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:74: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hCbzfiB49lW",
        "colab_type": "code",
        "outputId": "a346a0a5-3279-45e7-881c-5ab55133f3b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136,
          "referenced_widgets": [
            "5c6a8b865b8843859e2c50a56c0bcf37",
            "57a25f6448a546699feb4b1990180ec3",
            "785878a5be2e444daa8c45473a7f8850",
            "961fe676dff540a9b0fb1d7f30b76b59",
            "5d9b0d5fa7fe4ed6a4c88cfb948fdb42",
            "9a186a18708f42e0be144efde10a2420",
            "c5cceec75021423aa51f06302ab88bfe",
            "0f51c8cbd76e46ee8b6c7b4f9a12f97c"
          ]
        }
      },
      "source": [
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "\n",
        "trainset_private = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "trainloader_private = data.DataLoader(trainset, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "\n",
        "\n",
        "r = np.arange(50000)\n",
        "np.random.shuffle(r)\n",
        "\n",
        "private_trainset_intrain = []\n",
        "private_trainset_intest = []\n",
        "\n",
        "private_testset_intrain =[] \n",
        "private_testset_intest =[] \n",
        "\n",
        "\n",
        "for i in range(25000):\n",
        "    private_trainset_intrain.append(trainset[r[i]])\n",
        "\n",
        "\n",
        "for i in range(25000,50000):\n",
        "    private_testset_intrain.append(trainset[r[i]])\n",
        "\n",
        "    \n",
        "r = np.arange(10000)\n",
        "np.random.shuffle(r)\n",
        "  \n",
        "for i in range(5000):\n",
        "    private_trainset_intest.append(testset[r[i]])\n",
        "\n",
        "\n",
        "for i in range(5000,10000):\n",
        "    private_testset_intest.append(testset[r[i]])\n",
        "\n",
        "\n",
        "private_trainloader_intrain = data.DataLoader(private_trainset_intrain, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "private_trainloader_intest = data.DataLoader(private_trainset_intest, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "\n",
        "\n",
        "private_testloader_intrain = data.DataLoader(private_testset_intrain, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "private_testloader_intest = data.DataLoader(private_testset_intest, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c6a8b865b8843859e2c50a56c0bcf37",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvR5h0D-6ne-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#privacy_train = train_inference_model\n",
        "def train_inference_model(trainloader, model,inference_model, criterion, optimizer, epoch, use_cuda,num_batchs=1000):\n",
        "    global best_acc\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    mtop1_a = AverageMeter()\n",
        "    mtop5_a = AverageMeter()\n",
        "    \n",
        "    inference_model.train()\n",
        "    model.eval()\n",
        "    # switch to evaluate mode\n",
        "\n",
        "    end = time.time()\n",
        "    first_id = -1\n",
        "    for batch_idx,((tr_input, tr_target) ,(te_input, te_target)) in trainloader:\n",
        "        # measure data loading time\n",
        "        if first_id == -1:\n",
        "            first_id = batch_idx\n",
        "        \n",
        "        data_time.update(time.time() - end)\n",
        "        tr_input = tr_input.cuda()\n",
        "        te_input = te_input.cuda()\n",
        "        tr_target = tr_target.cuda()\n",
        "        te_target = te_target.cuda()\n",
        "        \n",
        "        \n",
        "        v_tr_input = torch.autograd.Variable(tr_input)\n",
        "        v_te_input = torch.autograd.Variable(te_input)\n",
        "        v_tr_target = torch.autograd.Variable(tr_target)\n",
        "        v_te_target = torch.autograd.Variable(te_target)\n",
        "        \n",
        "        # compute output\n",
        "        model_input =torch.cat((v_tr_input,v_te_input))\n",
        "        \n",
        "        pred_outputs = model(model_input)\n",
        "        \n",
        "        infer_input= torch.cat((v_tr_target,v_te_target))\n",
        "        \n",
        "        mtop1, mtop5 =accuracy(pred_outputs.data, infer_input.data, topk=(1, 5))\n",
        "        \n",
        "        mtop1_a.update(mtop1.item(), model_input.size(0))\n",
        "        mtop5_a.update(mtop5.item(), model_input.size(0))\n",
        "\n",
        "        \n",
        "        \n",
        "        one_hot_tr = torch.from_numpy((np.zeros((infer_input.size(0),10))-1)).cuda().type(torch.cuda.FloatTensor)\n",
        "        target_one_hot_tr = one_hot_tr.scatter_(1, infer_input.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
        "\n",
        "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
        "        \n",
        "\n",
        "        attack_model_input = pred_outputs#torch.cat((pred_outputs,infer_input_one_hot),1)\n",
        "        member_output = inference_model(attack_model_input,infer_input_one_hot)\n",
        "        \n",
        "        \n",
        "        \n",
        "        is_member_labels = torch.from_numpy(np.reshape(np.concatenate((np.zeros(v_tr_input.size(0)),np.ones(v_te_input.size(0)))),[-1,1])).cuda()\n",
        "        \n",
        "        v_is_member_labels = torch.autograd.Variable(is_member_labels).type(torch.cuda.FloatTensor)\n",
        "\n",
        "        loss = criterion(member_output, v_is_member_labels)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1=np.mean((member_output.data.cpu().numpy() >0.5)==v_is_member_labels.data.cpu().numpy())\n",
        "        losses.update(loss.item(), model_input.size(0))\n",
        "        top1.update(prec1, model_input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        if batch_idx-first_id > num_batchs:\n",
        "            break\n",
        "\n",
        "        # plot progress\n",
        "        if batch_idx%100==0:\n",
        "            print  ('({batch}/{size}) | Loss: {loss:.4f} | '.format(\n",
        "                    batch=batch_idx ,\n",
        "                    size=500,\n",
        "                    loss=losses.avg,\n",
        "                    ))\n",
        "\n",
        "    return (losses.avg, top1.avg)\n",
        "\n",
        "#train_privatly=train_model_advreg\n",
        "def train_model_advreg(trainloader, model,inference_model, criterion, optimizer, epoch, use_cuda,num_batchs=10000,alpha=0.9):\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    inference_model.eval()\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    end = time.time()\n",
        "    first_id = -1\n",
        "    for batch_idx, (inputs, targets) in (trainloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        if first_id == -1:\n",
        "            first_id = batch_idx\n",
        "        \n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n",
        "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "        # compute output\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        \n",
        "        one_hot_tr = torch.from_numpy((np.zeros((outputs.size(0),10))-1)).cuda().type(torch.cuda.FloatTensor)\n",
        "        target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
        "\n",
        "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
        "        \n",
        "        inference_output = inference_model ( outputs,infer_input_one_hot)\n",
        "        #print (inference_output.mean())\n",
        "        \n",
        "\n",
        "        loss = criterion(outputs, targets) + (alpha)*(((inference_output-1.0).pow(2).mean()))\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        # plot progress\n",
        "        if batch_idx%100==0:\n",
        "            print  ('({batch}/{size}) | Loss: {loss:.4f} |'.format(\n",
        "                    batch=batch_idx + 1,\n",
        "                    size=500,\n",
        "                    loss=losses.avg,\n",
        "                    ))\n",
        "        if batch_idx-first_id >= num_batchs:\n",
        "            break\n",
        "\n",
        "    return (losses.avg, top1.avg)\n",
        "\n",
        "\n",
        "def test(testloader, model, criterion, epoch, use_cuda):\n",
        "    global best_acc\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
        "\n",
        "        # compute output\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "    return (losses.avg, top1.avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNMVIcCl5FVB",
        "colab_type": "code",
        "outputId": "0596c390-316c-474d-e154-3e4ca5f7466b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        }
      },
      "source": [
        "epochs=200\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "\n",
        "    print('\\nEpoch: [%d | %d]' % (epoch + 1, epochs))\n",
        "\n",
        "    train_enum = enumerate(trainloader)\n",
        "    train_private_enum = enumerate(zip(trainloader_private,testloader))\n",
        "    for i in range(500//2):\n",
        "        \n",
        "        if epoch>3:\n",
        "            privacy_loss, privacy_acc = train_inference_model(train_private_enum,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda,1)\n",
        "            train_loss, train_acc = train_model_advreg(train_enum, model,inferenece_model, criterion, optimizer, epoch, use_cuda,1,1)\n",
        "            \n",
        "            if i%100 ==0:\n",
        "                print('Privacy Accuracy',privacy_acc)\n",
        "                print('Training Accuracy',train_acc)\n",
        "            if  (i+1)%50 ==0:\n",
        "                train_private_enum = enumerate(zip(trainloader_private,testloader))\n",
        "        else:\n",
        "            train_loss, train_acc = train_model_advreg(train_enum, model,inferenece_model, criterion, optimizer, epoch, use_cuda,1000,0)\n",
        "            break\n",
        "        \n",
        "        \n",
        "    test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n",
        "    train_loss, train_acc = test(trainloader, model, criterion, epoch, use_cuda)\n",
        "    print ('Train Accuracy',train_acc)\n",
        "    print ('Test Accuracy',test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: [1 | 200]\n",
            "(1/500) | Loss: 2.6037 |\n",
            "(101/500) | Loss: 2.9935 |\n",
            "(201/500) | Loss: 2.6883 |\n",
            "(301/500) | Loss: 2.5036 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:173: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy 23.186\n",
            "Test Accuracy 24.1\n",
            "\n",
            "Epoch: [2 | 200]\n",
            "(1/500) | Loss: 1.9584 |\n",
            "(101/500) | Loss: 1.9704 |\n",
            "(201/500) | Loss: 1.9316 |\n",
            "(301/500) | Loss: 1.8992 |\n",
            "Train Accuracy 32.532\n",
            "Test Accuracy 34.07\n",
            "\n",
            "Epoch: [3 | 200]\n",
            "(1/500) | Loss: 1.7505 |\n",
            "(101/500) | Loss: 1.7452 |\n",
            "(201/500) | Loss: 1.7087 |\n",
            "(301/500) | Loss: 1.6793 |\n",
            "Train Accuracy 42.09\n",
            "Test Accuracy 42.9\n",
            "\n",
            "Epoch: [4 | 200]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}