{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KD_AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t-hPybLM4vN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fcnal\n",
        "from sklearn.pipeline import Pipeline\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlJUHUVrhCil",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 2 * 2, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), 256 * 2 * 2)\n",
        "        x = self.classifier(x)\n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZGLo1B4Nsgs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BinActive(torch.autograd.Function):\n",
        "    '''\n",
        "    Binarize the input activations and calculate the mean across channel dimension.\n",
        "    '''\n",
        "    def forward(self, input):\n",
        "        self.save_for_backward(input)\n",
        "        size = input.size()\n",
        "        mean = torch.mean(input.abs(), 1, keepdim=True)\n",
        "        input = input.sign()\n",
        "        return input, mean\n",
        "\n",
        "    def backward(self, grad_output, grad_output_mean):\n",
        "        input, = self.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input.ge(1)] = 0\n",
        "        grad_input[input.le(-1)] = 0\n",
        "        return grad_input\n",
        "\n",
        "class BinConv2d(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels,\n",
        "            kernel_size=-1, stride=-1, padding=-1, dropout=0):\n",
        "        super(BinConv2d, self).__init__()\n",
        "        self.layer_type = 'BinConv2d'\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dropout_ratio = 0\n",
        "        dropout=0\n",
        "        self.bn = nn.BatchNorm2d(input_channels, eps=1e-4, momentum=0.1, affine=True)\n",
        "        self.bn.weight.data = self.bn.weight.data.zero_().add(1.0)\n",
        "        if dropout!=0:\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "        self.conv = nn.Conv2d(input_channels, output_channels,\n",
        "                kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x, mean = BinActive()(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class BinNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(BinNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=2, padding=2),\n",
        "            nn.BatchNorm2d(64, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            BinConv2d(64, 192, stride=1, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(192, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            BinConv2d(192, 384, stride=1, kernel_size=3, padding=2),\n",
        "            nn.BatchNorm2d(384, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            BinConv2d(384, 256, stride=1, kernel_size=3, padding=2),\n",
        "            nn.BatchNorm2d(256, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            BinConv2d(256, 256, stride=1, kernel_size=3, padding=2),\n",
        "            nn.BatchNorm2d(256, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXiyRQx2jmW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import numpy\n",
        "\n",
        "class BinOp():\n",
        "    def __init__(self, model):\n",
        "        # count the number of Conv2d\n",
        "        count_Conv2d = 0\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                count_Conv2d = count_Conv2d + 1\n",
        "\n",
        "        start_range = 1\n",
        "        end_range = count_Conv2d-2\n",
        "        self.bin_range = numpy.linspace(start_range,\n",
        "                end_range, end_range-start_range+1)\\\n",
        "                        .astype('int').tolist()\n",
        "        self.num_of_params = len(self.bin_range)\n",
        "        self.saved_params = []\n",
        "        self.target_params = []\n",
        "        self.target_modules = []\n",
        "        index = -1\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                index = index + 1\n",
        "                if index in self.bin_range:\n",
        "                    tmp = m.weight.data.clone()\n",
        "                    self.saved_params.append(tmp)\n",
        "                    self.target_modules.append(m.weight)\n",
        "\n",
        "    def binarization(self):\n",
        "        self.meancenterConvParams()\n",
        "        self.clampConvParams()\n",
        "        self.save_params()\n",
        "        self.binarizeConvParams()\n",
        "\n",
        "    def meancenterConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            s = self.target_modules[index].data.size()\n",
        "            negMean = self.target_modules[index].data.mean(1, keepdim=True).\\\n",
        "                    mul(-1).expand_as(self.target_modules[index].data)\n",
        "            self.target_modules[index].data = self.target_modules[index].data.add(negMean)\n",
        "\n",
        "    def clampConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.target_modules[index].data = \\\n",
        "                    self.target_modules[index].data.clamp(-1.0, 1.0)\n",
        "\n",
        "    def save_params(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.saved_params[index].copy_(self.target_modules[index].data)\n",
        "\n",
        "    def binarizeConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            n = self.target_modules[index].data[0].nelement()\n",
        "            s = self.target_modules[index].data.size()\n",
        "            m = self.target_modules[index].data.norm(1, 3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n)\n",
        "            self.target_modules[index].data = \\\n",
        "                    self.target_modules[index].data.sign().mul(m.expand(s))\n",
        "\n",
        "    def restore(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.target_modules[index].data.copy_(self.saved_params[index])\n",
        "\n",
        "    def updateBinaryGradWeight(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            weight = self.target_modules[index].data\n",
        "            n = weight[0].nelement()\n",
        "            s = weight.size()\n",
        "            m = weight.norm(1, 3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n",
        "            m[weight.lt(-1.0)] = 0 \n",
        "            m[weight.gt(1.0)] = 0\n",
        "            # m = m.add(1.0/n).mul(1.0-1.0/s[1]).mul(n)\n",
        "            # self.target_modules[index].grad.data = \\\n",
        "            #         self.target_modules[index].grad.data.mul(m)\n",
        "            m = m.mul(self.target_modules[index].grad.data)\n",
        "            m_add = weight.sign().mul(self.target_modules[index].grad.data)\n",
        "            m_add = m_add.sum(3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n",
        "            m_add = m_add.mul(weight.sign())\n",
        "            self.target_modules[index].grad.data = m.add(m_add).mul(1.0-1.0/s[1]).mul(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM9Y1oghNyeU",
        "colab_type": "code",
        "outputId": "3350053d-8b0b-4f46-e7ae-125d97d48c0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "batch_size=128\n",
        "lr=1e-3\n",
        "log_interval=100\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnXlrLa9NwbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(trainloader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            #loss = nn.NLLLoss(output,target)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            if batch_idx % 100 == 0:\n",
        "                done = batch_idx * len(data)\n",
        "                percentage = 100. * batch_idx / len(trainloader)\n",
        "                print(f'Train Epoch: {epoch} [{done:5}/{len(trainloader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')\n",
        "\n",
        "        test(model, trainloader)\n",
        "        test(model, testloader)\n",
        "\n",
        "\n",
        "def test(model, loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item() # sum up batch loss\n",
        "            #test_loss += nn.NLLLoss(output, target).item()\n",
        "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(loader.dataset)\n",
        "        accuracy = 100. * correct / len(loader.dataset)\n",
        "        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loader.dataset)} ({accuracy:.2f}%)')\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def distill_training(teacher=None, learner=None, data_loader=None,\n",
        "                     test_loader=None, optimizer=None,\n",
        "                     criterion=None, n_epochs=0):\n",
        "    \"\"\"\n",
        "    :param teacher: network to provide soft labels in training\n",
        "    :param learner: network to distill knowledge into\n",
        "    :param data_loader: data loader for training data set\n",
        "    :param test_loaderL data loader for validation data\n",
        "    :param optimizer: optimizer for training\n",
        "    :param criterion: objective function, should allow for soft labels.\n",
        "                      We suggest softCrossEntropy\n",
        "    :param n_epochs: epochs for training\n",
        "    :param verbose: verbose == True will print loss at each batch\n",
        "    :return: None, teacher model is trained in place\n",
        "    \"\"\"\n",
        "    losses = []\n",
        "    for epoch in range(n_epochs):\n",
        "        teacher.eval()\n",
        "        learner.train()\n",
        "        print(\"[{}/{}] \".format(epoch, n_epochs))\n",
        "        for i, batch in enumerate(data_loader):\n",
        "            with torch.set_grad_enabled(False):\n",
        "                data, labels = batch\n",
        "                data, labels = data.to(device), labels.to(device)\n",
        "                soft_lables = teacher(data)\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "                optimizer.zero_grad()\n",
        "                outputs = learner(data)\n",
        "                loss = criterion(outputs, torch.max(soft_lables.type(torch.cuda.LongTensor), 1)[1])#, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                losses.append(loss.item())\n",
        "\n",
        "            if i%100==0:\n",
        "                done= i * len(data)\n",
        "                percentage = 100. * i / len(data_loader)\n",
        "                print(f'Train Epoch: {epoch} [{done:5}/{len(data_loader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')\n",
        "\n",
        "        # evaluate performance on testset at the end of each epoch\n",
        "       \n",
        "\n",
        "        train_acc = test(learner, data_loader)\n",
        "        test_acc = test(learner, test_loader)\n",
        "    return train_acc, test_acc\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAWwRzdKOB2a",
        "colab_type": "code",
        "outputId": "5c6b91b2-d9c9-4550-e26e-12b93bb96d64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Model\n",
        "print('==> Building model..')\n",
        "teacher = Net()\n",
        "teacher = teacher.to(device)\n",
        "teacher = torch.nn.DataParallel(teacher)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0)\n",
        "optimizer = optim.Adam(teacher.parameters(), lr=1e-3, weight_decay=0.0000)\n",
        "\n",
        "train(teacher,  90)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Building model..\n",
            "Train Epoch: 0 [    0/50000 (  0%)]  Loss: 2.303198\n",
            "Train Epoch: 0 [12800/50000 ( 26%)]  Loss: 1.905345\n",
            "Train Epoch: 0 [25600/50000 ( 51%)]  Loss: 1.617092\n",
            "Train Epoch: 0 [38400/50000 ( 77%)]  Loss: 1.658061\n",
            "Test set: Average loss: 0.0119, Accuracy: 21303/50000 (42.61%)\n",
            "Test set: Average loss: 0.0149, Accuracy: 4395/10000 (43.95%)\n",
            "Train Epoch: 1 [    0/50000 (  0%)]  Loss: 1.548327\n",
            "Train Epoch: 1 [12800/50000 ( 26%)]  Loss: 1.343607\n",
            "Train Epoch: 1 [25600/50000 ( 51%)]  Loss: 1.468584\n",
            "Train Epoch: 1 [38400/50000 ( 77%)]  Loss: 1.323904\n",
            "Test set: Average loss: 0.0109, Accuracy: 24489/50000 (48.98%)\n",
            "Test set: Average loss: 0.0138, Accuracy: 4926/10000 (49.26%)\n",
            "Train Epoch: 2 [    0/50000 (  0%)]  Loss: 1.496271\n",
            "Train Epoch: 2 [12800/50000 ( 26%)]  Loss: 1.456753\n",
            "Train Epoch: 2 [25600/50000 ( 51%)]  Loss: 1.335973\n",
            "Train Epoch: 2 [38400/50000 ( 77%)]  Loss: 1.148891\n",
            "Test set: Average loss: 0.0096, Accuracy: 27986/50000 (55.97%)\n",
            "Test set: Average loss: 0.0122, Accuracy: 5677/10000 (56.77%)\n",
            "Train Epoch: 3 [    0/50000 (  0%)]  Loss: 1.316361\n",
            "Train Epoch: 3 [12800/50000 ( 26%)]  Loss: 0.997622\n",
            "Train Epoch: 3 [25600/50000 ( 51%)]  Loss: 1.050073\n",
            "Train Epoch: 3 [38400/50000 ( 77%)]  Loss: 1.135661\n",
            "Test set: Average loss: 0.0088, Accuracy: 29942/50000 (59.88%)\n",
            "Test set: Average loss: 0.0110, Accuracy: 6082/10000 (60.82%)\n",
            "Train Epoch: 4 [    0/50000 (  0%)]  Loss: 1.228449\n",
            "Train Epoch: 4 [12800/50000 ( 26%)]  Loss: 1.345996\n",
            "Train Epoch: 4 [25600/50000 ( 51%)]  Loss: 0.899691\n",
            "Train Epoch: 4 [38400/50000 ( 77%)]  Loss: 1.040896\n",
            "Test set: Average loss: 0.0083, Accuracy: 31163/50000 (62.33%)\n",
            "Test set: Average loss: 0.0107, Accuracy: 6172/10000 (61.72%)\n",
            "Train Epoch: 5 [    0/50000 (  0%)]  Loss: 1.057910\n",
            "Train Epoch: 5 [12800/50000 ( 26%)]  Loss: 0.954650\n",
            "Train Epoch: 5 [25600/50000 ( 51%)]  Loss: 1.160675\n",
            "Train Epoch: 5 [38400/50000 ( 77%)]  Loss: 0.927275\n",
            "Test set: Average loss: 0.0077, Accuracy: 32600/50000 (65.20%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6516/10000 (65.16%)\n",
            "Train Epoch: 6 [    0/50000 (  0%)]  Loss: 1.070802\n",
            "Train Epoch: 6 [12800/50000 ( 26%)]  Loss: 1.175370\n",
            "Train Epoch: 6 [25600/50000 ( 51%)]  Loss: 0.786835\n",
            "Train Epoch: 6 [38400/50000 ( 77%)]  Loss: 1.056401\n",
            "Test set: Average loss: 0.0071, Accuracy: 33919/50000 (67.84%)\n",
            "Test set: Average loss: 0.0091, Accuracy: 6845/10000 (68.45%)\n",
            "Train Epoch: 7 [    0/50000 (  0%)]  Loss: 0.916639\n",
            "Train Epoch: 7 [12800/50000 ( 26%)]  Loss: 1.153451\n",
            "Train Epoch: 7 [25600/50000 ( 51%)]  Loss: 0.690069\n",
            "Train Epoch: 7 [38400/50000 ( 77%)]  Loss: 0.862593\n",
            "Test set: Average loss: 0.0073, Accuracy: 33651/50000 (67.30%)\n",
            "Test set: Average loss: 0.0093, Accuracy: 6769/10000 (67.69%)\n",
            "Train Epoch: 8 [    0/50000 (  0%)]  Loss: 1.021835\n",
            "Train Epoch: 8 [12800/50000 ( 26%)]  Loss: 0.960723\n",
            "Train Epoch: 8 [25600/50000 ( 51%)]  Loss: 0.833738\n",
            "Train Epoch: 8 [38400/50000 ( 77%)]  Loss: 0.916270\n",
            "Test set: Average loss: 0.0068, Accuracy: 34625/50000 (69.25%)\n",
            "Test set: Average loss: 0.0087, Accuracy: 6913/10000 (69.13%)\n",
            "Train Epoch: 9 [    0/50000 (  0%)]  Loss: 0.853681\n",
            "Train Epoch: 9 [12800/50000 ( 26%)]  Loss: 0.654893\n",
            "Train Epoch: 9 [25600/50000 ( 51%)]  Loss: 0.871468\n",
            "Train Epoch: 9 [38400/50000 ( 77%)]  Loss: 0.911112\n",
            "Test set: Average loss: 0.0066, Accuracy: 35333/50000 (70.67%)\n",
            "Test set: Average loss: 0.0085, Accuracy: 7035/10000 (70.35%)\n",
            "Train Epoch: 10 [    0/50000 (  0%)]  Loss: 0.824471\n",
            "Train Epoch: 10 [12800/50000 ( 26%)]  Loss: 0.951712\n",
            "Train Epoch: 10 [25600/50000 ( 51%)]  Loss: 0.669740\n",
            "Train Epoch: 10 [38400/50000 ( 77%)]  Loss: 0.829280\n",
            "Test set: Average loss: 0.0062, Accuracy: 36133/50000 (72.27%)\n",
            "Test set: Average loss: 0.0081, Accuracy: 7177/10000 (71.77%)\n",
            "Train Epoch: 11 [    0/50000 (  0%)]  Loss: 0.810843\n",
            "Train Epoch: 11 [12800/50000 ( 26%)]  Loss: 0.749805\n",
            "Train Epoch: 11 [25600/50000 ( 51%)]  Loss: 0.990311\n",
            "Train Epoch: 11 [38400/50000 ( 77%)]  Loss: 0.742108\n",
            "Test set: Average loss: 0.0061, Accuracy: 36319/50000 (72.64%)\n",
            "Test set: Average loss: 0.0080, Accuracy: 7210/10000 (72.10%)\n",
            "Train Epoch: 12 [    0/50000 (  0%)]  Loss: 0.641204\n",
            "Train Epoch: 12 [12800/50000 ( 26%)]  Loss: 0.884305\n",
            "Train Epoch: 12 [25600/50000 ( 51%)]  Loss: 0.808486\n",
            "Train Epoch: 12 [38400/50000 ( 77%)]  Loss: 0.790977\n",
            "Test set: Average loss: 0.0061, Accuracy: 36294/50000 (72.59%)\n",
            "Test set: Average loss: 0.0081, Accuracy: 7191/10000 (71.91%)\n",
            "Train Epoch: 13 [    0/50000 (  0%)]  Loss: 0.754164\n",
            "Train Epoch: 13 [12800/50000 ( 26%)]  Loss: 0.666181\n",
            "Train Epoch: 13 [25600/50000 ( 51%)]  Loss: 0.731600\n",
            "Train Epoch: 13 [38400/50000 ( 77%)]  Loss: 0.823467\n",
            "Test set: Average loss: 0.0058, Accuracy: 36864/50000 (73.73%)\n",
            "Test set: Average loss: 0.0078, Accuracy: 7292/10000 (72.92%)\n",
            "Train Epoch: 14 [    0/50000 (  0%)]  Loss: 0.709093\n",
            "Train Epoch: 14 [12800/50000 ( 26%)]  Loss: 0.616416\n",
            "Train Epoch: 14 [25600/50000 ( 51%)]  Loss: 0.791337\n",
            "Train Epoch: 14 [38400/50000 ( 77%)]  Loss: 0.697981\n",
            "Test set: Average loss: 0.0057, Accuracy: 37099/50000 (74.20%)\n",
            "Test set: Average loss: 0.0080, Accuracy: 7276/10000 (72.76%)\n",
            "Train Epoch: 15 [    0/50000 (  0%)]  Loss: 0.578939\n",
            "Train Epoch: 15 [12800/50000 ( 26%)]  Loss: 0.695975\n",
            "Train Epoch: 15 [25600/50000 ( 51%)]  Loss: 0.731343\n",
            "Train Epoch: 15 [38400/50000 ( 77%)]  Loss: 0.644953\n",
            "Test set: Average loss: 0.0055, Accuracy: 37765/50000 (75.53%)\n",
            "Test set: Average loss: 0.0077, Accuracy: 7425/10000 (74.25%)\n",
            "Train Epoch: 16 [    0/50000 (  0%)]  Loss: 0.726671\n",
            "Train Epoch: 16 [12800/50000 ( 26%)]  Loss: 0.801241\n",
            "Train Epoch: 16 [25600/50000 ( 51%)]  Loss: 0.551626\n",
            "Train Epoch: 16 [38400/50000 ( 77%)]  Loss: 0.588485\n",
            "Test set: Average loss: 0.0056, Accuracy: 37495/50000 (74.99%)\n",
            "Test set: Average loss: 0.0076, Accuracy: 7433/10000 (74.33%)\n",
            "Train Epoch: 17 [    0/50000 (  0%)]  Loss: 0.647691\n",
            "Train Epoch: 17 [12800/50000 ( 26%)]  Loss: 0.718339\n",
            "Train Epoch: 17 [25600/50000 ( 51%)]  Loss: 0.687697\n",
            "Train Epoch: 17 [38400/50000 ( 77%)]  Loss: 0.748247\n",
            "Test set: Average loss: 0.0053, Accuracy: 37983/50000 (75.97%)\n",
            "Test set: Average loss: 0.0073, Accuracy: 7533/10000 (75.33%)\n",
            "Train Epoch: 18 [    0/50000 (  0%)]  Loss: 0.650872\n",
            "Train Epoch: 18 [12800/50000 ( 26%)]  Loss: 0.561029\n",
            "Train Epoch: 18 [25600/50000 ( 51%)]  Loss: 0.610770\n",
            "Train Epoch: 18 [38400/50000 ( 77%)]  Loss: 0.448899\n",
            "Test set: Average loss: 0.0052, Accuracy: 38478/50000 (76.96%)\n",
            "Test set: Average loss: 0.0073, Accuracy: 7516/10000 (75.16%)\n",
            "Train Epoch: 19 [    0/50000 (  0%)]  Loss: 0.674744\n",
            "Train Epoch: 19 [12800/50000 ( 26%)]  Loss: 0.818138\n",
            "Train Epoch: 19 [25600/50000 ( 51%)]  Loss: 0.539891\n",
            "Train Epoch: 19 [38400/50000 ( 77%)]  Loss: 0.773647\n",
            "Test set: Average loss: 0.0053, Accuracy: 38213/50000 (76.43%)\n",
            "Test set: Average loss: 0.0075, Accuracy: 7506/10000 (75.06%)\n",
            "Train Epoch: 20 [    0/50000 (  0%)]  Loss: 0.595960\n",
            "Train Epoch: 20 [12800/50000 ( 26%)]  Loss: 0.627971\n",
            "Train Epoch: 20 [25600/50000 ( 51%)]  Loss: 0.679792\n",
            "Train Epoch: 20 [38400/50000 ( 77%)]  Loss: 0.833681\n",
            "Test set: Average loss: 0.0049, Accuracy: 38870/50000 (77.74%)\n",
            "Test set: Average loss: 0.0071, Accuracy: 7550/10000 (75.50%)\n",
            "Train Epoch: 21 [    0/50000 (  0%)]  Loss: 0.689068\n",
            "Train Epoch: 21 [12800/50000 ( 26%)]  Loss: 0.768310\n",
            "Train Epoch: 21 [25600/50000 ( 51%)]  Loss: 0.591078\n",
            "Train Epoch: 21 [38400/50000 ( 77%)]  Loss: 0.689831\n",
            "Test set: Average loss: 0.0051, Accuracy: 38576/50000 (77.15%)\n",
            "Test set: Average loss: 0.0072, Accuracy: 7487/10000 (74.87%)\n",
            "Train Epoch: 22 [    0/50000 (  0%)]  Loss: 0.614161\n",
            "Train Epoch: 22 [12800/50000 ( 26%)]  Loss: 0.653671\n",
            "Train Epoch: 22 [25600/50000 ( 51%)]  Loss: 0.503383\n",
            "Train Epoch: 22 [38400/50000 ( 77%)]  Loss: 0.533780\n",
            "Test set: Average loss: 0.0049, Accuracy: 39041/50000 (78.08%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7583/10000 (75.83%)\n",
            "Train Epoch: 23 [    0/50000 (  0%)]  Loss: 0.500577\n",
            "Train Epoch: 23 [12800/50000 ( 26%)]  Loss: 0.558937\n",
            "Train Epoch: 23 [25600/50000 ( 51%)]  Loss: 0.774160\n",
            "Train Epoch: 23 [38400/50000 ( 77%)]  Loss: 0.617660\n",
            "Test set: Average loss: 0.0048, Accuracy: 39147/50000 (78.29%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7600/10000 (76.00%)\n",
            "Train Epoch: 24 [    0/50000 (  0%)]  Loss: 0.544740\n",
            "Train Epoch: 24 [12800/50000 ( 26%)]  Loss: 0.597847\n",
            "Train Epoch: 24 [25600/50000 ( 51%)]  Loss: 0.541968\n",
            "Train Epoch: 24 [38400/50000 ( 77%)]  Loss: 0.702005\n",
            "Test set: Average loss: 0.0047, Accuracy: 39385/50000 (78.77%)\n",
            "Test set: Average loss: 0.0069, Accuracy: 7676/10000 (76.76%)\n",
            "Train Epoch: 25 [    0/50000 (  0%)]  Loss: 0.650683\n",
            "Train Epoch: 25 [12800/50000 ( 26%)]  Loss: 0.623933\n",
            "Train Epoch: 25 [25600/50000 ( 51%)]  Loss: 0.468753\n",
            "Train Epoch: 25 [38400/50000 ( 77%)]  Loss: 0.478932\n",
            "Test set: Average loss: 0.0045, Accuracy: 39864/50000 (79.73%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7717/10000 (77.17%)\n",
            "Train Epoch: 26 [    0/50000 (  0%)]  Loss: 0.578432\n",
            "Train Epoch: 26 [12800/50000 ( 26%)]  Loss: 0.691824\n",
            "Train Epoch: 26 [25600/50000 ( 51%)]  Loss: 0.591050\n",
            "Train Epoch: 26 [38400/50000 ( 77%)]  Loss: 0.570814\n",
            "Test set: Average loss: 0.0045, Accuracy: 39857/50000 (79.71%)\n",
            "Test set: Average loss: 0.0068, Accuracy: 7673/10000 (76.73%)\n",
            "Train Epoch: 27 [    0/50000 (  0%)]  Loss: 0.677451\n",
            "Train Epoch: 27 [12800/50000 ( 26%)]  Loss: 0.700536\n",
            "Train Epoch: 27 [25600/50000 ( 51%)]  Loss: 0.605606\n",
            "Train Epoch: 27 [38400/50000 ( 77%)]  Loss: 0.575688\n",
            "Test set: Average loss: 0.0047, Accuracy: 39429/50000 (78.86%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7659/10000 (76.59%)\n",
            "Train Epoch: 28 [    0/50000 (  0%)]  Loss: 0.672329\n",
            "Train Epoch: 28 [12800/50000 ( 26%)]  Loss: 0.654809\n",
            "Train Epoch: 28 [25600/50000 ( 51%)]  Loss: 0.750879\n",
            "Train Epoch: 28 [38400/50000 ( 77%)]  Loss: 0.825557\n",
            "Test set: Average loss: 0.0047, Accuracy: 39562/50000 (79.12%)\n",
            "Test set: Average loss: 0.0071, Accuracy: 7600/10000 (76.00%)\n",
            "Train Epoch: 29 [    0/50000 (  0%)]  Loss: 0.552362\n",
            "Train Epoch: 29 [12800/50000 ( 26%)]  Loss: 0.466301\n",
            "Train Epoch: 29 [25600/50000 ( 51%)]  Loss: 0.532289\n",
            "Train Epoch: 29 [38400/50000 ( 77%)]  Loss: 0.675435\n",
            "Test set: Average loss: 0.0044, Accuracy: 40086/50000 (80.17%)\n",
            "Test set: Average loss: 0.0069, Accuracy: 7735/10000 (77.35%)\n",
            "Train Epoch: 30 [    0/50000 (  0%)]  Loss: 0.606960\n",
            "Train Epoch: 30 [12800/50000 ( 26%)]  Loss: 0.724743\n",
            "Train Epoch: 30 [25600/50000 ( 51%)]  Loss: 0.623291\n",
            "Train Epoch: 30 [38400/50000 ( 77%)]  Loss: 0.694432\n",
            "Test set: Average loss: 0.0045, Accuracy: 39702/50000 (79.40%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7718/10000 (77.18%)\n",
            "Train Epoch: 31 [    0/50000 (  0%)]  Loss: 0.594625\n",
            "Train Epoch: 31 [12800/50000 ( 26%)]  Loss: 0.526604\n",
            "Train Epoch: 31 [25600/50000 ( 51%)]  Loss: 0.690364\n",
            "Train Epoch: 31 [38400/50000 ( 77%)]  Loss: 0.808492\n",
            "Test set: Average loss: 0.0043, Accuracy: 40413/50000 (80.83%)\n",
            "Test set: Average loss: 0.0065, Accuracy: 7805/10000 (78.05%)\n",
            "Train Epoch: 32 [    0/50000 (  0%)]  Loss: 0.572861\n",
            "Train Epoch: 32 [12800/50000 ( 26%)]  Loss: 0.534807\n",
            "Train Epoch: 32 [25600/50000 ( 51%)]  Loss: 0.592548\n",
            "Train Epoch: 32 [38400/50000 ( 77%)]  Loss: 0.616360\n",
            "Test set: Average loss: 0.0042, Accuracy: 40471/50000 (80.94%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7796/10000 (77.96%)\n",
            "Train Epoch: 33 [    0/50000 (  0%)]  Loss: 0.430624\n",
            "Train Epoch: 33 [12800/50000 ( 26%)]  Loss: 0.471435\n",
            "Train Epoch: 33 [25600/50000 ( 51%)]  Loss: 0.787137\n",
            "Train Epoch: 33 [38400/50000 ( 77%)]  Loss: 0.450785\n",
            "Test set: Average loss: 0.0042, Accuracy: 40560/50000 (81.12%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7810/10000 (78.10%)\n",
            "Train Epoch: 34 [    0/50000 (  0%)]  Loss: 0.515113\n",
            "Train Epoch: 34 [12800/50000 ( 26%)]  Loss: 0.554150\n",
            "Train Epoch: 34 [25600/50000 ( 51%)]  Loss: 0.604420\n",
            "Train Epoch: 34 [38400/50000 ( 77%)]  Loss: 0.552870\n",
            "Test set: Average loss: 0.0041, Accuracy: 40746/50000 (81.49%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7765/10000 (77.65%)\n",
            "Train Epoch: 35 [    0/50000 (  0%)]  Loss: 0.550316\n",
            "Train Epoch: 35 [12800/50000 ( 26%)]  Loss: 0.545804\n",
            "Train Epoch: 35 [25600/50000 ( 51%)]  Loss: 0.406955\n",
            "Train Epoch: 35 [38400/50000 ( 77%)]  Loss: 0.542466\n",
            "Test set: Average loss: 0.0042, Accuracy: 40583/50000 (81.17%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7764/10000 (77.64%)\n",
            "Train Epoch: 36 [    0/50000 (  0%)]  Loss: 0.671546\n",
            "Train Epoch: 36 [12800/50000 ( 26%)]  Loss: 0.555042\n",
            "Train Epoch: 36 [25600/50000 ( 51%)]  Loss: 0.634004\n",
            "Train Epoch: 36 [38400/50000 ( 77%)]  Loss: 0.581151\n",
            "Test set: Average loss: 0.0039, Accuracy: 41115/50000 (82.23%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7811/10000 (78.11%)\n",
            "Train Epoch: 37 [    0/50000 (  0%)]  Loss: 0.481254\n",
            "Train Epoch: 37 [12800/50000 ( 26%)]  Loss: 0.606337\n",
            "Train Epoch: 37 [25600/50000 ( 51%)]  Loss: 0.500320\n",
            "Train Epoch: 37 [38400/50000 ( 77%)]  Loss: 0.523568\n",
            "Test set: Average loss: 0.0040, Accuracy: 41033/50000 (82.07%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7818/10000 (78.18%)\n",
            "Train Epoch: 38 [    0/50000 (  0%)]  Loss: 0.472036\n",
            "Train Epoch: 38 [12800/50000 ( 26%)]  Loss: 0.395818\n",
            "Train Epoch: 38 [25600/50000 ( 51%)]  Loss: 0.514045\n",
            "Train Epoch: 38 [38400/50000 ( 77%)]  Loss: 0.578240\n",
            "Test set: Average loss: 0.0039, Accuracy: 41204/50000 (82.41%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7799/10000 (77.99%)\n",
            "Train Epoch: 39 [    0/50000 (  0%)]  Loss: 0.436464\n",
            "Train Epoch: 39 [12800/50000 ( 26%)]  Loss: 0.480126\n",
            "Train Epoch: 39 [25600/50000 ( 51%)]  Loss: 0.539036\n",
            "Train Epoch: 39 [38400/50000 ( 77%)]  Loss: 0.504721\n",
            "Test set: Average loss: 0.0039, Accuracy: 41214/50000 (82.43%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7806/10000 (78.06%)\n",
            "Train Epoch: 40 [    0/50000 (  0%)]  Loss: 0.623043\n",
            "Train Epoch: 40 [12800/50000 ( 26%)]  Loss: 0.544005\n",
            "Train Epoch: 40 [25600/50000 ( 51%)]  Loss: 0.530450\n",
            "Train Epoch: 40 [38400/50000 ( 77%)]  Loss: 0.538622\n",
            "Test set: Average loss: 0.0040, Accuracy: 40844/50000 (81.69%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7733/10000 (77.33%)\n",
            "Train Epoch: 41 [    0/50000 (  0%)]  Loss: 0.524414\n",
            "Train Epoch: 41 [12800/50000 ( 26%)]  Loss: 0.583258\n",
            "Train Epoch: 41 [25600/50000 ( 51%)]  Loss: 0.641090\n",
            "Train Epoch: 41 [38400/50000 ( 77%)]  Loss: 0.416368\n",
            "Test set: Average loss: 0.0038, Accuracy: 41543/50000 (83.09%)\n",
            "Test set: Average loss: 0.0065, Accuracy: 7871/10000 (78.71%)\n",
            "Train Epoch: 42 [    0/50000 (  0%)]  Loss: 0.621757\n",
            "Train Epoch: 42 [12800/50000 ( 26%)]  Loss: 0.535857\n",
            "Train Epoch: 42 [25600/50000 ( 51%)]  Loss: 0.452440\n",
            "Train Epoch: 42 [38400/50000 ( 77%)]  Loss: 0.629948\n",
            "Test set: Average loss: 0.0038, Accuracy: 41427/50000 (82.85%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7854/10000 (78.54%)\n",
            "Train Epoch: 43 [    0/50000 (  0%)]  Loss: 0.346670\n",
            "Train Epoch: 43 [12800/50000 ( 26%)]  Loss: 0.440370\n",
            "Train Epoch: 43 [25600/50000 ( 51%)]  Loss: 0.392835\n",
            "Train Epoch: 43 [38400/50000 ( 77%)]  Loss: 0.509784\n",
            "Test set: Average loss: 0.0039, Accuracy: 41139/50000 (82.28%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7823/10000 (78.23%)\n",
            "Train Epoch: 44 [    0/50000 (  0%)]  Loss: 0.430483\n",
            "Train Epoch: 44 [12800/50000 ( 26%)]  Loss: 0.376038\n",
            "Train Epoch: 44 [25600/50000 ( 51%)]  Loss: 0.667248\n",
            "Train Epoch: 44 [38400/50000 ( 77%)]  Loss: 0.509461\n",
            "Test set: Average loss: 0.0037, Accuracy: 41494/50000 (82.99%)\n",
            "Test set: Average loss: 0.0065, Accuracy: 7875/10000 (78.75%)\n",
            "Train Epoch: 45 [    0/50000 (  0%)]  Loss: 0.427029\n",
            "Train Epoch: 45 [12800/50000 ( 26%)]  Loss: 0.503502\n",
            "Train Epoch: 45 [25600/50000 ( 51%)]  Loss: 0.628834\n",
            "Train Epoch: 45 [38400/50000 ( 77%)]  Loss: 0.501197\n",
            "Test set: Average loss: 0.0037, Accuracy: 41695/50000 (83.39%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7890/10000 (78.90%)\n",
            "Train Epoch: 46 [    0/50000 (  0%)]  Loss: 0.395791\n",
            "Train Epoch: 46 [12800/50000 ( 26%)]  Loss: 0.431489\n",
            "Train Epoch: 46 [25600/50000 ( 51%)]  Loss: 0.569623\n",
            "Train Epoch: 46 [38400/50000 ( 77%)]  Loss: 0.419497\n",
            "Test set: Average loss: 0.0038, Accuracy: 41513/50000 (83.03%)\n",
            "Test set: Average loss: 0.0065, Accuracy: 7846/10000 (78.46%)\n",
            "Train Epoch: 47 [    0/50000 (  0%)]  Loss: 0.338509\n",
            "Train Epoch: 47 [12800/50000 ( 26%)]  Loss: 0.448028\n",
            "Train Epoch: 47 [25600/50000 ( 51%)]  Loss: 0.472366\n",
            "Train Epoch: 47 [38400/50000 ( 77%)]  Loss: 0.676671\n",
            "Test set: Average loss: 0.0036, Accuracy: 41877/50000 (83.75%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7856/10000 (78.56%)\n",
            "Train Epoch: 48 [    0/50000 (  0%)]  Loss: 0.461321\n",
            "Train Epoch: 48 [12800/50000 ( 26%)]  Loss: 0.507096\n",
            "Train Epoch: 48 [25600/50000 ( 51%)]  Loss: 0.397386\n",
            "Train Epoch: 48 [38400/50000 ( 77%)]  Loss: 0.791470\n",
            "Test set: Average loss: 0.0037, Accuracy: 41645/50000 (83.29%)\n",
            "Test set: Average loss: 0.0068, Accuracy: 7837/10000 (78.37%)\n",
            "Train Epoch: 49 [    0/50000 (  0%)]  Loss: 0.491187\n",
            "Train Epoch: 49 [12800/50000 ( 26%)]  Loss: 0.427045\n",
            "Train Epoch: 49 [25600/50000 ( 51%)]  Loss: 0.420384\n",
            "Train Epoch: 49 [38400/50000 ( 77%)]  Loss: 0.578433\n",
            "Test set: Average loss: 0.0036, Accuracy: 41853/50000 (83.71%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7831/10000 (78.31%)\n",
            "Train Epoch: 50 [    0/50000 (  0%)]  Loss: 0.494232\n",
            "Train Epoch: 50 [12800/50000 ( 26%)]  Loss: 0.509375\n",
            "Train Epoch: 50 [25600/50000 ( 51%)]  Loss: 0.479608\n",
            "Train Epoch: 50 [38400/50000 ( 77%)]  Loss: 0.461908\n",
            "Test set: Average loss: 0.0037, Accuracy: 41564/50000 (83.13%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7862/10000 (78.62%)\n",
            "Train Epoch: 51 [    0/50000 (  0%)]  Loss: 0.305978\n",
            "Train Epoch: 51 [12800/50000 ( 26%)]  Loss: 0.608388\n",
            "Train Epoch: 51 [25600/50000 ( 51%)]  Loss: 0.572528\n",
            "Train Epoch: 51 [38400/50000 ( 77%)]  Loss: 0.445755\n",
            "Test set: Average loss: 0.0036, Accuracy: 41941/50000 (83.88%)\n",
            "Test set: Average loss: 0.0068, Accuracy: 7874/10000 (78.74%)\n",
            "Train Epoch: 52 [    0/50000 (  0%)]  Loss: 0.427883\n",
            "Train Epoch: 52 [12800/50000 ( 26%)]  Loss: 0.595987\n",
            "Train Epoch: 52 [25600/50000 ( 51%)]  Loss: 0.332399\n",
            "Train Epoch: 52 [38400/50000 ( 77%)]  Loss: 0.545930\n",
            "Test set: Average loss: 0.0036, Accuracy: 41876/50000 (83.75%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7805/10000 (78.05%)\n",
            "Train Epoch: 53 [    0/50000 (  0%)]  Loss: 0.495273\n",
            "Train Epoch: 53 [12800/50000 ( 26%)]  Loss: 0.633079\n",
            "Train Epoch: 53 [25600/50000 ( 51%)]  Loss: 0.452683\n",
            "Train Epoch: 53 [38400/50000 ( 77%)]  Loss: 0.415046\n",
            "Test set: Average loss: 0.0034, Accuracy: 42401/50000 (84.80%)\n",
            "Test set: Average loss: 0.0065, Accuracy: 7906/10000 (79.06%)\n",
            "Train Epoch: 54 [    0/50000 (  0%)]  Loss: 0.415345\n",
            "Train Epoch: 54 [12800/50000 ( 26%)]  Loss: 0.413851\n",
            "Train Epoch: 54 [25600/50000 ( 51%)]  Loss: 0.381265\n",
            "Train Epoch: 54 [38400/50000 ( 77%)]  Loss: 0.385057\n",
            "Test set: Average loss: 0.0034, Accuracy: 42224/50000 (84.45%)\n",
            "Test set: Average loss: 0.0065, Accuracy: 7904/10000 (79.04%)\n",
            "Train Epoch: 55 [    0/50000 (  0%)]  Loss: 0.511693\n",
            "Train Epoch: 55 [12800/50000 ( 26%)]  Loss: 0.395929\n",
            "Train Epoch: 55 [25600/50000 ( 51%)]  Loss: 0.499732\n",
            "Train Epoch: 55 [38400/50000 ( 77%)]  Loss: 0.487691\n",
            "Test set: Average loss: 0.0033, Accuracy: 42457/50000 (84.91%)\n",
            "Test set: Average loss: 0.0065, Accuracy: 7975/10000 (79.75%)\n",
            "Train Epoch: 56 [    0/50000 (  0%)]  Loss: 0.401526\n",
            "Train Epoch: 56 [12800/50000 ( 26%)]  Loss: 0.440955\n",
            "Train Epoch: 56 [25600/50000 ( 51%)]  Loss: 0.396126\n",
            "Train Epoch: 56 [38400/50000 ( 77%)]  Loss: 0.377506\n",
            "Test set: Average loss: 0.0033, Accuracy: 42467/50000 (84.93%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7865/10000 (78.65%)\n",
            "Train Epoch: 57 [    0/50000 (  0%)]  Loss: 0.322711\n",
            "Train Epoch: 57 [12800/50000 ( 26%)]  Loss: 0.498117\n",
            "Train Epoch: 57 [25600/50000 ( 51%)]  Loss: 0.361578\n",
            "Train Epoch: 57 [38400/50000 ( 77%)]  Loss: 0.423358\n",
            "Test set: Average loss: 0.0033, Accuracy: 42494/50000 (84.99%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7893/10000 (78.93%)\n",
            "Train Epoch: 58 [    0/50000 (  0%)]  Loss: 0.342866\n",
            "Train Epoch: 58 [12800/50000 ( 26%)]  Loss: 0.467260\n",
            "Train Epoch: 58 [25600/50000 ( 51%)]  Loss: 0.615632\n",
            "Train Epoch: 58 [38400/50000 ( 77%)]  Loss: 0.488212\n",
            "Test set: Average loss: 0.0035, Accuracy: 42197/50000 (84.39%)\n",
            "Test set: Average loss: 0.0069, Accuracy: 7829/10000 (78.29%)\n",
            "Train Epoch: 59 [    0/50000 (  0%)]  Loss: 0.477668\n",
            "Train Epoch: 59 [12800/50000 ( 26%)]  Loss: 0.502858\n",
            "Train Epoch: 59 [25600/50000 ( 51%)]  Loss: 0.510987\n",
            "Train Epoch: 59 [38400/50000 ( 77%)]  Loss: 0.421464\n",
            "Test set: Average loss: 0.0032, Accuracy: 42679/50000 (85.36%)\n",
            "Test set: Average loss: 0.0065, Accuracy: 7918/10000 (79.18%)\n",
            "Train Epoch: 60 [    0/50000 (  0%)]  Loss: 0.332169\n",
            "Train Epoch: 60 [12800/50000 ( 26%)]  Loss: 0.458922\n",
            "Train Epoch: 60 [25600/50000 ( 51%)]  Loss: 0.536880\n",
            "Train Epoch: 60 [38400/50000 ( 77%)]  Loss: 0.533776\n",
            "Test set: Average loss: 0.0033, Accuracy: 42670/50000 (85.34%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7867/10000 (78.67%)\n",
            "Train Epoch: 61 [    0/50000 (  0%)]  Loss: 0.340489\n",
            "Train Epoch: 61 [12800/50000 ( 26%)]  Loss: 0.444121\n",
            "Train Epoch: 61 [25600/50000 ( 51%)]  Loss: 0.485992\n",
            "Train Epoch: 61 [38400/50000 ( 77%)]  Loss: 0.571430\n",
            "Test set: Average loss: 0.0033, Accuracy: 42620/50000 (85.24%)\n",
            "Test set: Average loss: 0.0069, Accuracy: 7934/10000 (79.34%)\n",
            "Train Epoch: 62 [    0/50000 (  0%)]  Loss: 0.459173\n",
            "Train Epoch: 62 [12800/50000 ( 26%)]  Loss: 0.348230\n",
            "Train Epoch: 62 [25600/50000 ( 51%)]  Loss: 0.362935\n",
            "Train Epoch: 62 [38400/50000 ( 77%)]  Loss: 0.554092\n",
            "Test set: Average loss: 0.0036, Accuracy: 42032/50000 (84.06%)\n",
            "Test set: Average loss: 0.0069, Accuracy: 7861/10000 (78.61%)\n",
            "Train Epoch: 63 [    0/50000 (  0%)]  Loss: 0.484790\n",
            "Train Epoch: 63 [12800/50000 ( 26%)]  Loss: 0.363070\n",
            "Train Epoch: 63 [25600/50000 ( 51%)]  Loss: 0.406076\n",
            "Train Epoch: 63 [38400/50000 ( 77%)]  Loss: 0.435701\n",
            "Test set: Average loss: 0.0032, Accuracy: 42707/50000 (85.41%)\n",
            "Test set: Average loss: 0.0068, Accuracy: 7930/10000 (79.30%)\n",
            "Train Epoch: 64 [    0/50000 (  0%)]  Loss: 0.383816\n",
            "Train Epoch: 64 [12800/50000 ( 26%)]  Loss: 0.319465\n",
            "Train Epoch: 64 [25600/50000 ( 51%)]  Loss: 0.562180\n",
            "Train Epoch: 64 [38400/50000 ( 77%)]  Loss: 0.370457\n",
            "Test set: Average loss: 0.0032, Accuracy: 42802/50000 (85.60%)\n",
            "Test set: Average loss: 0.0068, Accuracy: 7969/10000 (79.69%)\n",
            "Train Epoch: 65 [    0/50000 (  0%)]  Loss: 0.385732\n",
            "Train Epoch: 65 [12800/50000 ( 26%)]  Loss: 0.327378\n",
            "Train Epoch: 65 [25600/50000 ( 51%)]  Loss: 0.534196\n",
            "Train Epoch: 65 [38400/50000 ( 77%)]  Loss: 0.486194\n",
            "Test set: Average loss: 0.0031, Accuracy: 43082/50000 (86.16%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7901/10000 (79.01%)\n",
            "Train Epoch: 66 [    0/50000 (  0%)]  Loss: 0.373217\n",
            "Train Epoch: 66 [12800/50000 ( 26%)]  Loss: 0.474697\n",
            "Train Epoch: 66 [25600/50000 ( 51%)]  Loss: 0.313827\n",
            "Train Epoch: 66 [38400/50000 ( 77%)]  Loss: 0.362627\n",
            "Test set: Average loss: 0.0031, Accuracy: 42929/50000 (85.86%)\n",
            "Test set: Average loss: 0.0068, Accuracy: 7925/10000 (79.25%)\n",
            "Train Epoch: 67 [    0/50000 (  0%)]  Loss: 0.401120\n",
            "Train Epoch: 67 [12800/50000 ( 26%)]  Loss: 0.364072\n",
            "Train Epoch: 67 [25600/50000 ( 51%)]  Loss: 0.339489\n",
            "Train Epoch: 67 [38400/50000 ( 77%)]  Loss: 0.470140\n",
            "Test set: Average loss: 0.0031, Accuracy: 43043/50000 (86.09%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7935/10000 (79.35%)\n",
            "Train Epoch: 68 [    0/50000 (  0%)]  Loss: 0.551977\n",
            "Train Epoch: 68 [12800/50000 ( 26%)]  Loss: 0.371823\n",
            "Train Epoch: 68 [25600/50000 ( 51%)]  Loss: 0.367373\n",
            "Train Epoch: 68 [38400/50000 ( 77%)]  Loss: 0.415882\n",
            "Test set: Average loss: 0.0034, Accuracy: 42595/50000 (85.19%)\n",
            "Test set: Average loss: 0.0076, Accuracy: 7848/10000 (78.48%)\n",
            "Train Epoch: 69 [    0/50000 (  0%)]  Loss: 0.376487\n",
            "Train Epoch: 69 [12800/50000 ( 26%)]  Loss: 0.405243\n",
            "Train Epoch: 69 [25600/50000 ( 51%)]  Loss: 0.312315\n",
            "Train Epoch: 69 [38400/50000 ( 77%)]  Loss: 0.538147\n",
            "Test set: Average loss: 0.0032, Accuracy: 42871/50000 (85.74%)\n",
            "Test set: Average loss: 0.0069, Accuracy: 7888/10000 (78.88%)\n",
            "Train Epoch: 70 [    0/50000 (  0%)]  Loss: 0.369335\n",
            "Train Epoch: 70 [12800/50000 ( 26%)]  Loss: 0.359541\n",
            "Train Epoch: 70 [25600/50000 ( 51%)]  Loss: 0.283292\n",
            "Train Epoch: 70 [38400/50000 ( 77%)]  Loss: 0.623492\n",
            "Test set: Average loss: 0.0030, Accuracy: 43333/50000 (86.67%)\n",
            "Test set: Average loss: 0.0068, Accuracy: 7914/10000 (79.14%)\n",
            "Train Epoch: 71 [    0/50000 (  0%)]  Loss: 0.372715\n",
            "Train Epoch: 71 [12800/50000 ( 26%)]  Loss: 0.369265\n",
            "Train Epoch: 71 [25600/50000 ( 51%)]  Loss: 0.432622\n",
            "Train Epoch: 71 [38400/50000 ( 77%)]  Loss: 0.395813\n",
            "Test set: Average loss: 0.0030, Accuracy: 43231/50000 (86.46%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7933/10000 (79.33%)\n",
            "Train Epoch: 72 [    0/50000 (  0%)]  Loss: 0.369491\n",
            "Train Epoch: 72 [12800/50000 ( 26%)]  Loss: 0.332052\n",
            "Train Epoch: 72 [25600/50000 ( 51%)]  Loss: 0.417084\n",
            "Train Epoch: 72 [38400/50000 ( 77%)]  Loss: 0.445697\n",
            "Test set: Average loss: 0.0031, Accuracy: 43019/50000 (86.04%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7898/10000 (78.98%)\n",
            "Train Epoch: 73 [    0/50000 (  0%)]  Loss: 0.410547\n",
            "Train Epoch: 73 [12800/50000 ( 26%)]  Loss: 0.472777\n",
            "Train Epoch: 73 [25600/50000 ( 51%)]  Loss: 0.459911\n",
            "Train Epoch: 73 [38400/50000 ( 77%)]  Loss: 0.301410\n",
            "Test set: Average loss: 0.0029, Accuracy: 43273/50000 (86.55%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7984/10000 (79.84%)\n",
            "Train Epoch: 74 [    0/50000 (  0%)]  Loss: 0.364883\n",
            "Train Epoch: 74 [12800/50000 ( 26%)]  Loss: 0.453274\n",
            "Train Epoch: 74 [25600/50000 ( 51%)]  Loss: 0.325162\n",
            "Train Epoch: 74 [38400/50000 ( 77%)]  Loss: 0.366087\n",
            "Test set: Average loss: 0.0028, Accuracy: 43621/50000 (87.24%)\n",
            "Test set: Average loss: 0.0066, Accuracy: 7970/10000 (79.70%)\n",
            "Train Epoch: 75 [    0/50000 (  0%)]  Loss: 0.485326\n",
            "Train Epoch: 75 [12800/50000 ( 26%)]  Loss: 0.342912\n",
            "Train Epoch: 75 [25600/50000 ( 51%)]  Loss: 0.287267\n",
            "Train Epoch: 75 [38400/50000 ( 77%)]  Loss: 0.466573\n",
            "Test set: Average loss: 0.0030, Accuracy: 43397/50000 (86.79%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7891/10000 (78.91%)\n",
            "Train Epoch: 76 [    0/50000 (  0%)]  Loss: 0.351659\n",
            "Train Epoch: 76 [12800/50000 ( 26%)]  Loss: 0.370701\n",
            "Train Epoch: 76 [25600/50000 ( 51%)]  Loss: 0.357900\n",
            "Train Epoch: 76 [38400/50000 ( 77%)]  Loss: 0.370241\n",
            "Test set: Average loss: 0.0030, Accuracy: 43455/50000 (86.91%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7918/10000 (79.18%)\n",
            "Train Epoch: 77 [    0/50000 (  0%)]  Loss: 0.419194\n",
            "Train Epoch: 77 [12800/50000 ( 26%)]  Loss: 0.498491\n",
            "Train Epoch: 77 [25600/50000 ( 51%)]  Loss: 0.382731\n",
            "Train Epoch: 77 [38400/50000 ( 77%)]  Loss: 0.355940\n",
            "Test set: Average loss: 0.0031, Accuracy: 43044/50000 (86.09%)\n",
            "Test set: Average loss: 0.0074, Accuracy: 7892/10000 (78.92%)\n",
            "Train Epoch: 78 [    0/50000 (  0%)]  Loss: 0.319001\n",
            "Train Epoch: 78 [12800/50000 ( 26%)]  Loss: 0.351992\n",
            "Train Epoch: 78 [25600/50000 ( 51%)]  Loss: 0.392370\n",
            "Train Epoch: 78 [38400/50000 ( 77%)]  Loss: 0.488650\n",
            "Test set: Average loss: 0.0029, Accuracy: 43368/50000 (86.74%)\n",
            "Test set: Average loss: 0.0069, Accuracy: 7937/10000 (79.37%)\n",
            "Train Epoch: 79 [    0/50000 (  0%)]  Loss: 0.363745\n",
            "Train Epoch: 79 [12800/50000 ( 26%)]  Loss: 0.290972\n",
            "Train Epoch: 79 [25600/50000 ( 51%)]  Loss: 0.359034\n",
            "Train Epoch: 79 [38400/50000 ( 77%)]  Loss: 0.312144\n",
            "Test set: Average loss: 0.0028, Accuracy: 43656/50000 (87.31%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7916/10000 (79.16%)\n",
            "Train Epoch: 80 [    0/50000 (  0%)]  Loss: 0.357883\n",
            "Train Epoch: 80 [12800/50000 ( 26%)]  Loss: 0.278744\n",
            "Train Epoch: 80 [25600/50000 ( 51%)]  Loss: 0.274380\n",
            "Train Epoch: 80 [38400/50000 ( 77%)]  Loss: 0.313465\n",
            "Test set: Average loss: 0.0028, Accuracy: 43547/50000 (87.09%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7980/10000 (79.80%)\n",
            "Train Epoch: 81 [    0/50000 (  0%)]  Loss: 0.300771\n",
            "Train Epoch: 81 [12800/50000 ( 26%)]  Loss: 0.378365\n",
            "Train Epoch: 81 [25600/50000 ( 51%)]  Loss: 0.394585\n",
            "Train Epoch: 81 [38400/50000 ( 77%)]  Loss: 0.433627\n",
            "Test set: Average loss: 0.0028, Accuracy: 43674/50000 (87.35%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7949/10000 (79.49%)\n",
            "Train Epoch: 82 [    0/50000 (  0%)]  Loss: 0.382735\n",
            "Train Epoch: 82 [12800/50000 ( 26%)]  Loss: 0.286434\n",
            "Train Epoch: 82 [25600/50000 ( 51%)]  Loss: 0.385922\n",
            "Train Epoch: 82 [38400/50000 ( 77%)]  Loss: 0.238320\n",
            "Test set: Average loss: 0.0029, Accuracy: 43391/50000 (86.78%)\n",
            "Test set: Average loss: 0.0068, Accuracy: 7981/10000 (79.81%)\n",
            "Train Epoch: 83 [    0/50000 (  0%)]  Loss: 0.464696\n",
            "Train Epoch: 83 [12800/50000 ( 26%)]  Loss: 0.391806\n",
            "Train Epoch: 83 [25600/50000 ( 51%)]  Loss: 0.257613\n",
            "Train Epoch: 83 [38400/50000 ( 77%)]  Loss: 0.303261\n",
            "Test set: Average loss: 0.0029, Accuracy: 43550/50000 (87.10%)\n",
            "Test set: Average loss: 0.0070, Accuracy: 7928/10000 (79.28%)\n",
            "Train Epoch: 84 [    0/50000 (  0%)]  Loss: 0.304128\n",
            "Train Epoch: 84 [12800/50000 ( 26%)]  Loss: 0.356142\n",
            "Train Epoch: 84 [25600/50000 ( 51%)]  Loss: 0.267637\n",
            "Train Epoch: 84 [38400/50000 ( 77%)]  Loss: 0.309864\n",
            "Test set: Average loss: 0.0030, Accuracy: 43428/50000 (86.86%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7934/10000 (79.34%)\n",
            "Train Epoch: 85 [    0/50000 (  0%)]  Loss: 0.440902\n",
            "Train Epoch: 85 [12800/50000 ( 26%)]  Loss: 0.399325\n",
            "Train Epoch: 85 [25600/50000 ( 51%)]  Loss: 0.370325\n",
            "Train Epoch: 85 [38400/50000 ( 77%)]  Loss: 0.499702\n",
            "Test set: Average loss: 0.0027, Accuracy: 43928/50000 (87.86%)\n",
            "Test set: Average loss: 0.0067, Accuracy: 7984/10000 (79.84%)\n",
            "Train Epoch: 86 [    0/50000 (  0%)]  Loss: 0.382126\n",
            "Train Epoch: 86 [12800/50000 ( 26%)]  Loss: 0.300193\n",
            "Train Epoch: 86 [25600/50000 ( 51%)]  Loss: 0.296396\n",
            "Train Epoch: 86 [38400/50000 ( 77%)]  Loss: 0.296383\n",
            "Test set: Average loss: 0.0028, Accuracy: 43728/50000 (87.46%)\n",
            "Test set: Average loss: 0.0072, Accuracy: 7904/10000 (79.04%)\n",
            "Train Epoch: 87 [    0/50000 (  0%)]  Loss: 0.487833\n",
            "Train Epoch: 87 [12800/50000 ( 26%)]  Loss: 0.373191\n",
            "Train Epoch: 87 [25600/50000 ( 51%)]  Loss: 0.493606\n",
            "Train Epoch: 87 [38400/50000 ( 77%)]  Loss: 0.357892\n",
            "Test set: Average loss: 0.0028, Accuracy: 43829/50000 (87.66%)\n",
            "Test set: Average loss: 0.0071, Accuracy: 8026/10000 (80.26%)\n",
            "Train Epoch: 88 [    0/50000 (  0%)]  Loss: 0.252979\n",
            "Train Epoch: 88 [12800/50000 ( 26%)]  Loss: 0.385435\n",
            "Train Epoch: 88 [25600/50000 ( 51%)]  Loss: 0.307105\n",
            "Train Epoch: 88 [38400/50000 ( 77%)]  Loss: 0.366547\n",
            "Test set: Average loss: 0.0027, Accuracy: 44035/50000 (88.07%)\n",
            "Test set: Average loss: 0.0069, Accuracy: 7992/10000 (79.92%)\n",
            "Train Epoch: 89 [    0/50000 (  0%)]  Loss: 0.399877\n",
            "Train Epoch: 89 [12800/50000 ( 26%)]  Loss: 0.376415\n",
            "Train Epoch: 89 [25600/50000 ( 51%)]  Loss: 0.297498\n",
            "Train Epoch: 89 [38400/50000 ( 77%)]  Loss: 0.367528\n",
            "Test set: Average loss: 0.0027, Accuracy: 44083/50000 (88.17%)\n",
            "Test set: Average loss: 0.0071, Accuracy: 7995/10000 (79.95%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhgYCdffOD7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3e6f56a2-e249-4feb-8c49-1468a3b14641"
      },
      "source": [
        "learner = BinNet()\n",
        "\n",
        "learner.cuda()\n",
        "learner = torch.nn.DataParallel(learner, device_ids=range(torch.cuda.device_count()))\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(learner.parameters(), lr=1e-3,weight_decay=0.0000)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the binarization operator\n",
        "bin_op = BinOp(learner)\n",
        "\n",
        "distill_training(teacher, learner, trainloader, testloader, optimizer, criterion, 75)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0/75] \n",
            "Train Epoch: 0 [    0/50000 (  0%)]  Loss: 2.335976\n",
            "Train Epoch: 0 [12800/50000 ( 26%)]  Loss: 2.129011\n",
            "Train Epoch: 0 [25600/50000 ( 51%)]  Loss: 2.050554\n",
            "Train Epoch: 0 [38400/50000 ( 77%)]  Loss: 1.807318\n",
            "Test set: Average loss: 0.0136, Accuracy: 15958/50000 (31.92%)\n",
            "Test set: Average loss: 0.0172, Accuracy: 3261/10000 (32.61%)\n",
            "[1/75] \n",
            "Train Epoch: 1 [    0/50000 (  0%)]  Loss: 1.709836\n",
            "Train Epoch: 1 [12800/50000 ( 26%)]  Loss: 1.783804\n",
            "Train Epoch: 1 [25600/50000 ( 51%)]  Loss: 1.672413\n",
            "Train Epoch: 1 [38400/50000 ( 77%)]  Loss: 1.458604\n",
            "Test set: Average loss: 0.0131, Accuracy: 18690/50000 (37.38%)\n",
            "Test set: Average loss: 0.0167, Accuracy: 3784/10000 (37.84%)\n",
            "[2/75] \n",
            "Train Epoch: 2 [    0/50000 (  0%)]  Loss: 1.547668\n",
            "Train Epoch: 2 [12800/50000 ( 26%)]  Loss: 1.503431\n",
            "Train Epoch: 2 [25600/50000 ( 51%)]  Loss: 1.569696\n",
            "Train Epoch: 2 [38400/50000 ( 77%)]  Loss: 1.574756\n",
            "Test set: Average loss: 0.0118, Accuracy: 22287/50000 (44.57%)\n",
            "Test set: Average loss: 0.0151, Accuracy: 4543/10000 (45.43%)\n",
            "[3/75] \n",
            "Train Epoch: 3 [    0/50000 (  0%)]  Loss: 1.423192\n",
            "Train Epoch: 3 [12800/50000 ( 26%)]  Loss: 1.363146\n",
            "Train Epoch: 3 [25600/50000 ( 51%)]  Loss: 1.320810\n",
            "Train Epoch: 3 [38400/50000 ( 77%)]  Loss: 1.372926\n",
            "Test set: Average loss: 0.0105, Accuracy: 25742/50000 (51.48%)\n",
            "Test set: Average loss: 0.0134, Accuracy: 5250/10000 (52.50%)\n",
            "[4/75] \n",
            "Train Epoch: 4 [    0/50000 (  0%)]  Loss: 1.479492\n",
            "Train Epoch: 4 [12800/50000 ( 26%)]  Loss: 1.273902\n",
            "Train Epoch: 4 [25600/50000 ( 51%)]  Loss: 1.520662\n",
            "Train Epoch: 4 [38400/50000 ( 77%)]  Loss: 1.321173\n",
            "Test set: Average loss: 0.0101, Accuracy: 26820/50000 (53.64%)\n",
            "Test set: Average loss: 0.0128, Accuracy: 5540/10000 (55.40%)\n",
            "[5/75] \n",
            "Train Epoch: 5 [    0/50000 (  0%)]  Loss: 1.201581\n",
            "Train Epoch: 5 [12800/50000 ( 26%)]  Loss: 1.345489\n",
            "Train Epoch: 5 [25600/50000 ( 51%)]  Loss: 1.210706\n",
            "Train Epoch: 5 [38400/50000 ( 77%)]  Loss: 1.363670\n",
            "Test set: Average loss: 0.0100, Accuracy: 27173/50000 (54.35%)\n",
            "Test set: Average loss: 0.0127, Accuracy: 5548/10000 (55.48%)\n",
            "[6/75] \n",
            "Train Epoch: 6 [    0/50000 (  0%)]  Loss: 1.147527\n",
            "Train Epoch: 6 [12800/50000 ( 26%)]  Loss: 1.127366\n",
            "Train Epoch: 6 [25600/50000 ( 51%)]  Loss: 1.218347\n",
            "Train Epoch: 6 [38400/50000 ( 77%)]  Loss: 1.199243\n",
            "Test set: Average loss: 0.0099, Accuracy: 27930/50000 (55.86%)\n",
            "Test set: Average loss: 0.0129, Accuracy: 5582/10000 (55.82%)\n",
            "[7/75] \n",
            "Train Epoch: 7 [    0/50000 (  0%)]  Loss: 1.151661\n",
            "Train Epoch: 7 [12800/50000 ( 26%)]  Loss: 1.208931\n",
            "Train Epoch: 7 [25600/50000 ( 51%)]  Loss: 1.220788\n",
            "Train Epoch: 7 [38400/50000 ( 77%)]  Loss: 1.440490\n",
            "Test set: Average loss: 0.0095, Accuracy: 28828/50000 (57.66%)\n",
            "Test set: Average loss: 0.0121, Accuracy: 5874/10000 (58.74%)\n",
            "[8/75] \n",
            "Train Epoch: 8 [    0/50000 (  0%)]  Loss: 1.188387\n",
            "Train Epoch: 8 [12800/50000 ( 26%)]  Loss: 1.117542\n",
            "Train Epoch: 8 [25600/50000 ( 51%)]  Loss: 1.177010\n",
            "Train Epoch: 8 [38400/50000 ( 77%)]  Loss: 1.125668\n",
            "Test set: Average loss: 0.0091, Accuracy: 29788/50000 (59.58%)\n",
            "Test set: Average loss: 0.0119, Accuracy: 5965/10000 (59.65%)\n",
            "[9/75] \n",
            "Train Epoch: 9 [    0/50000 (  0%)]  Loss: 1.009846\n",
            "Train Epoch: 9 [12800/50000 ( 26%)]  Loss: 1.113023\n",
            "Train Epoch: 9 [25600/50000 ( 51%)]  Loss: 1.025257\n",
            "Train Epoch: 9 [38400/50000 ( 77%)]  Loss: 1.088961\n",
            "Test set: Average loss: 0.0091, Accuracy: 29619/50000 (59.24%)\n",
            "Test set: Average loss: 0.0116, Accuracy: 5966/10000 (59.66%)\n",
            "[10/75] \n",
            "Train Epoch: 10 [    0/50000 (  0%)]  Loss: 1.363425\n",
            "Train Epoch: 10 [12800/50000 ( 26%)]  Loss: 1.092802\n",
            "Train Epoch: 10 [25600/50000 ( 51%)]  Loss: 0.986844\n",
            "Train Epoch: 10 [38400/50000 ( 77%)]  Loss: 1.055081\n",
            "Test set: Average loss: 0.0087, Accuracy: 30429/50000 (60.86%)\n",
            "Test set: Average loss: 0.0112, Accuracy: 6104/10000 (61.04%)\n",
            "[11/75] \n",
            "Train Epoch: 11 [    0/50000 (  0%)]  Loss: 1.258296\n",
            "Train Epoch: 11 [12800/50000 ( 26%)]  Loss: 1.020771\n",
            "Train Epoch: 11 [25600/50000 ( 51%)]  Loss: 1.079647\n",
            "Train Epoch: 11 [38400/50000 ( 77%)]  Loss: 1.137003\n",
            "Test set: Average loss: 0.0085, Accuracy: 31007/50000 (62.01%)\n",
            "Test set: Average loss: 0.0112, Accuracy: 6176/10000 (61.76%)\n",
            "[12/75] \n",
            "Train Epoch: 12 [    0/50000 (  0%)]  Loss: 1.010180\n",
            "Train Epoch: 12 [12800/50000 ( 26%)]  Loss: 0.950030\n",
            "Train Epoch: 12 [25600/50000 ( 51%)]  Loss: 0.848473\n",
            "Train Epoch: 12 [38400/50000 ( 77%)]  Loss: 0.991863\n",
            "Test set: Average loss: 0.0083, Accuracy: 31350/50000 (62.70%)\n",
            "Test set: Average loss: 0.0109, Accuracy: 6271/10000 (62.71%)\n",
            "[13/75] \n",
            "Train Epoch: 13 [    0/50000 (  0%)]  Loss: 1.014403\n",
            "Train Epoch: 13 [12800/50000 ( 26%)]  Loss: 0.935105\n",
            "Train Epoch: 13 [25600/50000 ( 51%)]  Loss: 1.052471\n",
            "Train Epoch: 13 [38400/50000 ( 77%)]  Loss: 1.119647\n",
            "Test set: Average loss: 0.0081, Accuracy: 32214/50000 (64.43%)\n",
            "Test set: Average loss: 0.0106, Accuracy: 6375/10000 (63.75%)\n",
            "[14/75] \n",
            "Train Epoch: 14 [    0/50000 (  0%)]  Loss: 0.877146\n",
            "Train Epoch: 14 [12800/50000 ( 26%)]  Loss: 0.886598\n",
            "Train Epoch: 14 [25600/50000 ( 51%)]  Loss: 0.963934\n",
            "Train Epoch: 14 [38400/50000 ( 77%)]  Loss: 0.913251\n",
            "Test set: Average loss: 0.0082, Accuracy: 31654/50000 (63.31%)\n",
            "Test set: Average loss: 0.0106, Accuracy: 6383/10000 (63.83%)\n",
            "[15/75] \n",
            "Train Epoch: 15 [    0/50000 (  0%)]  Loss: 1.049044\n",
            "Train Epoch: 15 [12800/50000 ( 26%)]  Loss: 0.943274\n",
            "Train Epoch: 15 [25600/50000 ( 51%)]  Loss: 0.913451\n",
            "Train Epoch: 15 [38400/50000 ( 77%)]  Loss: 0.902365\n",
            "Test set: Average loss: 0.0078, Accuracy: 32717/50000 (65.43%)\n",
            "Test set: Average loss: 0.0102, Accuracy: 6464/10000 (64.64%)\n",
            "[16/75] \n",
            "Train Epoch: 16 [    0/50000 (  0%)]  Loss: 1.008514\n",
            "Train Epoch: 16 [12800/50000 ( 26%)]  Loss: 0.999880\n",
            "Train Epoch: 16 [25600/50000 ( 51%)]  Loss: 0.902492\n",
            "Train Epoch: 16 [38400/50000 ( 77%)]  Loss: 1.119615\n",
            "Test set: Average loss: 0.0081, Accuracy: 32249/50000 (64.50%)\n",
            "Test set: Average loss: 0.0107, Accuracy: 6391/10000 (63.91%)\n",
            "[17/75] \n",
            "Train Epoch: 17 [    0/50000 (  0%)]  Loss: 0.938279\n",
            "Train Epoch: 17 [12800/50000 ( 26%)]  Loss: 1.077757\n",
            "Train Epoch: 17 [25600/50000 ( 51%)]  Loss: 1.019121\n",
            "Train Epoch: 17 [38400/50000 ( 77%)]  Loss: 0.843095\n",
            "Test set: Average loss: 0.0077, Accuracy: 32984/50000 (65.97%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6536/10000 (65.36%)\n",
            "[18/75] \n",
            "Train Epoch: 18 [    0/50000 (  0%)]  Loss: 0.950754\n",
            "Train Epoch: 18 [12800/50000 ( 26%)]  Loss: 0.929429\n",
            "Train Epoch: 18 [25600/50000 ( 51%)]  Loss: 1.008704\n",
            "Train Epoch: 18 [38400/50000 ( 77%)]  Loss: 0.790698\n",
            "Test set: Average loss: 0.0080, Accuracy: 32561/50000 (65.12%)\n",
            "Test set: Average loss: 0.0105, Accuracy: 6466/10000 (64.66%)\n",
            "[19/75] \n",
            "Train Epoch: 19 [    0/50000 (  0%)]  Loss: 0.874859\n",
            "Train Epoch: 19 [12800/50000 ( 26%)]  Loss: 1.068498\n",
            "Train Epoch: 19 [25600/50000 ( 51%)]  Loss: 0.968076\n",
            "Train Epoch: 19 [38400/50000 ( 77%)]  Loss: 0.983087\n",
            "Test set: Average loss: 0.0072, Accuracy: 33946/50000 (67.89%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6695/10000 (66.95%)\n",
            "[20/75] \n",
            "Train Epoch: 20 [    0/50000 (  0%)]  Loss: 0.870853\n",
            "Train Epoch: 20 [12800/50000 ( 26%)]  Loss: 0.947291\n",
            "Train Epoch: 20 [25600/50000 ( 51%)]  Loss: 1.150806\n",
            "Train Epoch: 20 [38400/50000 ( 77%)]  Loss: 0.927262\n",
            "Test set: Average loss: 0.0073, Accuracy: 34056/50000 (68.11%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6689/10000 (66.89%)\n",
            "[21/75] \n",
            "Train Epoch: 21 [    0/50000 (  0%)]  Loss: 0.751711\n",
            "Train Epoch: 21 [12800/50000 ( 26%)]  Loss: 0.908722\n",
            "Train Epoch: 21 [25600/50000 ( 51%)]  Loss: 0.949053\n",
            "Train Epoch: 21 [38400/50000 ( 77%)]  Loss: 0.824286\n",
            "Test set: Average loss: 0.0073, Accuracy: 33592/50000 (67.18%)\n",
            "Test set: Average loss: 0.0095, Accuracy: 6730/10000 (67.30%)\n",
            "[22/75] \n",
            "Train Epoch: 22 [    0/50000 (  0%)]  Loss: 0.862303\n",
            "Train Epoch: 22 [12800/50000 ( 26%)]  Loss: 0.764143\n",
            "Train Epoch: 22 [25600/50000 ( 51%)]  Loss: 0.795853\n",
            "Train Epoch: 22 [38400/50000 ( 77%)]  Loss: 0.710460\n",
            "Test set: Average loss: 0.0072, Accuracy: 34215/50000 (68.43%)\n",
            "Test set: Average loss: 0.0094, Accuracy: 6794/10000 (67.94%)\n",
            "[23/75] \n",
            "Train Epoch: 23 [    0/50000 (  0%)]  Loss: 0.954955\n",
            "Train Epoch: 23 [12800/50000 ( 26%)]  Loss: 1.028037\n",
            "Train Epoch: 23 [25600/50000 ( 51%)]  Loss: 0.987031\n",
            "Train Epoch: 23 [38400/50000 ( 77%)]  Loss: 0.861503\n",
            "Test set: Average loss: 0.0073, Accuracy: 33848/50000 (67.70%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6699/10000 (66.99%)\n",
            "[24/75] \n",
            "Train Epoch: 24 [    0/50000 (  0%)]  Loss: 0.889203\n",
            "Train Epoch: 24 [12800/50000 ( 26%)]  Loss: 0.888913\n",
            "Train Epoch: 24 [25600/50000 ( 51%)]  Loss: 0.818381\n",
            "Train Epoch: 24 [38400/50000 ( 77%)]  Loss: 0.998144\n",
            "Test set: Average loss: 0.0072, Accuracy: 34130/50000 (68.26%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6753/10000 (67.53%)\n",
            "[25/75] \n",
            "Train Epoch: 25 [    0/50000 (  0%)]  Loss: 0.887067\n",
            "Train Epoch: 25 [12800/50000 ( 26%)]  Loss: 0.793823\n",
            "Train Epoch: 25 [25600/50000 ( 51%)]  Loss: 0.930917\n",
            "Train Epoch: 25 [38400/50000 ( 77%)]  Loss: 0.957789\n",
            "Test set: Average loss: 0.0070, Accuracy: 34703/50000 (69.41%)\n",
            "Test set: Average loss: 0.0094, Accuracy: 6808/10000 (68.08%)\n",
            "[26/75] \n",
            "Train Epoch: 26 [    0/50000 (  0%)]  Loss: 0.874042\n",
            "Train Epoch: 26 [12800/50000 ( 26%)]  Loss: 0.967270\n",
            "Train Epoch: 26 [25600/50000 ( 51%)]  Loss: 0.877500\n",
            "Train Epoch: 26 [38400/50000 ( 77%)]  Loss: 0.870419\n",
            "Test set: Average loss: 0.0070, Accuracy: 34836/50000 (69.67%)\n",
            "Test set: Average loss: 0.0094, Accuracy: 6868/10000 (68.68%)\n",
            "[27/75] \n",
            "Train Epoch: 27 [    0/50000 (  0%)]  Loss: 0.907200\n",
            "Train Epoch: 27 [12800/50000 ( 26%)]  Loss: 0.978995\n",
            "Train Epoch: 27 [25600/50000 ( 51%)]  Loss: 0.955969\n",
            "Train Epoch: 27 [38400/50000 ( 77%)]  Loss: 0.804731\n",
            "Test set: Average loss: 0.0066, Accuracy: 35445/50000 (70.89%)\n",
            "Test set: Average loss: 0.0090, Accuracy: 6982/10000 (69.82%)\n",
            "[28/75] \n",
            "Train Epoch: 28 [    0/50000 (  0%)]  Loss: 1.188046\n",
            "Train Epoch: 28 [12800/50000 ( 26%)]  Loss: 0.810438\n",
            "Train Epoch: 28 [25600/50000 ( 51%)]  Loss: 1.037107\n",
            "Train Epoch: 28 [38400/50000 ( 77%)]  Loss: 0.854888\n",
            "Test set: Average loss: 0.0070, Accuracy: 34866/50000 (69.73%)\n",
            "Test set: Average loss: 0.0093, Accuracy: 6871/10000 (68.71%)\n",
            "[29/75] \n",
            "Train Epoch: 29 [    0/50000 (  0%)]  Loss: 0.864975\n",
            "Train Epoch: 29 [12800/50000 ( 26%)]  Loss: 0.893414\n",
            "Train Epoch: 29 [25600/50000 ( 51%)]  Loss: 0.864364\n",
            "Train Epoch: 29 [38400/50000 ( 77%)]  Loss: 0.798220\n",
            "Test set: Average loss: 0.0067, Accuracy: 35229/50000 (70.46%)\n",
            "Test set: Average loss: 0.0091, Accuracy: 6900/10000 (69.00%)\n",
            "[30/75] \n",
            "Train Epoch: 30 [    0/50000 (  0%)]  Loss: 0.729328\n",
            "Train Epoch: 30 [12800/50000 ( 26%)]  Loss: 0.784541\n",
            "Train Epoch: 30 [25600/50000 ( 51%)]  Loss: 0.818854\n",
            "Train Epoch: 30 [38400/50000 ( 77%)]  Loss: 0.823241\n",
            "Test set: Average loss: 0.0066, Accuracy: 35556/50000 (71.11%)\n",
            "Test set: Average loss: 0.0089, Accuracy: 7032/10000 (70.32%)\n",
            "[31/75] \n",
            "Train Epoch: 31 [    0/50000 (  0%)]  Loss: 0.819837\n",
            "Train Epoch: 31 [12800/50000 ( 26%)]  Loss: 1.016294\n",
            "Train Epoch: 31 [25600/50000 ( 51%)]  Loss: 0.932405\n",
            "Train Epoch: 31 [38400/50000 ( 77%)]  Loss: 0.842920\n",
            "Test set: Average loss: 0.0067, Accuracy: 35695/50000 (71.39%)\n",
            "Test set: Average loss: 0.0089, Accuracy: 6999/10000 (69.99%)\n",
            "[32/75] \n",
            "Train Epoch: 32 [    0/50000 (  0%)]  Loss: 0.833985\n",
            "Train Epoch: 32 [12800/50000 ( 26%)]  Loss: 0.818310\n",
            "Train Epoch: 32 [25600/50000 ( 51%)]  Loss: 0.756824\n",
            "Train Epoch: 32 [38400/50000 ( 77%)]  Loss: 0.788923\n",
            "Test set: Average loss: 0.0065, Accuracy: 35958/50000 (71.92%)\n",
            "Test set: Average loss: 0.0088, Accuracy: 7020/10000 (70.20%)\n",
            "[33/75] \n",
            "Train Epoch: 33 [    0/50000 (  0%)]  Loss: 0.707047\n",
            "Train Epoch: 33 [12800/50000 ( 26%)]  Loss: 0.838925\n",
            "Train Epoch: 33 [25600/50000 ( 51%)]  Loss: 0.848678\n",
            "Train Epoch: 33 [38400/50000 ( 77%)]  Loss: 0.780735\n",
            "Test set: Average loss: 0.0062, Accuracy: 36304/50000 (72.61%)\n",
            "Test set: Average loss: 0.0084, Accuracy: 7154/10000 (71.54%)\n",
            "[34/75] \n",
            "Train Epoch: 34 [    0/50000 (  0%)]  Loss: 0.715018\n",
            "Train Epoch: 34 [12800/50000 ( 26%)]  Loss: 0.741390\n",
            "Train Epoch: 34 [25600/50000 ( 51%)]  Loss: 0.749125\n",
            "Train Epoch: 34 [38400/50000 ( 77%)]  Loss: 0.928718\n",
            "Test set: Average loss: 0.0063, Accuracy: 36326/50000 (72.65%)\n",
            "Test set: Average loss: 0.0088, Accuracy: 7019/10000 (70.19%)\n",
            "[35/75] \n",
            "Train Epoch: 35 [    0/50000 (  0%)]  Loss: 0.763694\n",
            "Train Epoch: 35 [12800/50000 ( 26%)]  Loss: 0.900835\n",
            "Train Epoch: 35 [25600/50000 ( 51%)]  Loss: 0.760820\n",
            "Train Epoch: 35 [38400/50000 ( 77%)]  Loss: 0.863009\n",
            "Test set: Average loss: 0.0066, Accuracy: 35476/50000 (70.95%)\n",
            "Test set: Average loss: 0.0091, Accuracy: 6916/10000 (69.16%)\n",
            "[36/75] \n",
            "Train Epoch: 36 [    0/50000 (  0%)]  Loss: 0.859286\n",
            "Train Epoch: 36 [12800/50000 ( 26%)]  Loss: 0.685257\n",
            "Train Epoch: 36 [25600/50000 ( 51%)]  Loss: 0.730366\n",
            "Train Epoch: 36 [38400/50000 ( 77%)]  Loss: 0.830471\n",
            "Test set: Average loss: 0.0063, Accuracy: 36040/50000 (72.08%)\n",
            "Test set: Average loss: 0.0086, Accuracy: 7099/10000 (70.99%)\n",
            "[37/75] \n",
            "Train Epoch: 37 [    0/50000 (  0%)]  Loss: 0.807976\n",
            "Train Epoch: 37 [12800/50000 ( 26%)]  Loss: 0.704908\n",
            "Train Epoch: 37 [25600/50000 ( 51%)]  Loss: 0.672117\n",
            "Train Epoch: 37 [38400/50000 ( 77%)]  Loss: 0.956240\n",
            "Test set: Average loss: 0.0064, Accuracy: 36235/50000 (72.47%)\n",
            "Test set: Average loss: 0.0087, Accuracy: 7054/10000 (70.54%)\n",
            "[38/75] \n",
            "Train Epoch: 38 [    0/50000 (  0%)]  Loss: 0.999632\n",
            "Train Epoch: 38 [12800/50000 ( 26%)]  Loss: 0.861934\n",
            "Train Epoch: 38 [25600/50000 ( 51%)]  Loss: 0.833311\n",
            "Train Epoch: 38 [38400/50000 ( 77%)]  Loss: 0.814958\n",
            "Test set: Average loss: 0.0066, Accuracy: 35873/50000 (71.75%)\n",
            "Test set: Average loss: 0.0089, Accuracy: 7071/10000 (70.71%)\n",
            "[39/75] \n",
            "Train Epoch: 39 [    0/50000 (  0%)]  Loss: 0.822030\n",
            "Train Epoch: 39 [12800/50000 ( 26%)]  Loss: 0.934274\n",
            "Train Epoch: 39 [25600/50000 ( 51%)]  Loss: 0.854284\n",
            "Train Epoch: 39 [38400/50000 ( 77%)]  Loss: 0.865737\n",
            "Test set: Average loss: 0.0062, Accuracy: 36539/50000 (73.08%)\n",
            "Test set: Average loss: 0.0085, Accuracy: 7115/10000 (71.15%)\n",
            "[40/75] \n",
            "Train Epoch: 40 [    0/50000 (  0%)]  Loss: 0.884860\n",
            "Train Epoch: 40 [12800/50000 ( 26%)]  Loss: 0.643980\n",
            "Train Epoch: 40 [25600/50000 ( 51%)]  Loss: 0.910952\n",
            "Train Epoch: 40 [38400/50000 ( 77%)]  Loss: 0.828313\n",
            "Test set: Average loss: 0.0065, Accuracy: 35966/50000 (71.93%)\n",
            "Test set: Average loss: 0.0090, Accuracy: 6990/10000 (69.90%)\n",
            "[41/75] \n",
            "Train Epoch: 41 [    0/50000 (  0%)]  Loss: 0.681398\n",
            "Train Epoch: 41 [12800/50000 ( 26%)]  Loss: 0.779189\n",
            "Train Epoch: 41 [25600/50000 ( 51%)]  Loss: 0.842130\n",
            "Train Epoch: 41 [38400/50000 ( 77%)]  Loss: 0.699362\n",
            "Test set: Average loss: 0.0062, Accuracy: 36576/50000 (73.15%)\n",
            "Test set: Average loss: 0.0085, Accuracy: 7114/10000 (71.14%)\n",
            "[42/75] \n",
            "Train Epoch: 42 [    0/50000 (  0%)]  Loss: 0.832972\n",
            "Train Epoch: 42 [12800/50000 ( 26%)]  Loss: 0.833449\n",
            "Train Epoch: 42 [25600/50000 ( 51%)]  Loss: 0.983803\n",
            "Train Epoch: 42 [38400/50000 ( 77%)]  Loss: 0.837578\n",
            "Test set: Average loss: 0.0065, Accuracy: 35851/50000 (71.70%)\n",
            "Test set: Average loss: 0.0088, Accuracy: 6998/10000 (69.98%)\n",
            "[43/75] \n",
            "Train Epoch: 43 [    0/50000 (  0%)]  Loss: 0.789718\n",
            "Train Epoch: 43 [12800/50000 ( 26%)]  Loss: 0.695924\n",
            "Train Epoch: 43 [25600/50000 ( 51%)]  Loss: 0.647298\n",
            "Train Epoch: 43 [38400/50000 ( 77%)]  Loss: 0.817452\n",
            "Test set: Average loss: 0.0062, Accuracy: 36589/50000 (73.18%)\n",
            "Test set: Average loss: 0.0085, Accuracy: 7146/10000 (71.46%)\n",
            "[44/75] \n",
            "Train Epoch: 44 [    0/50000 (  0%)]  Loss: 0.798617\n",
            "Train Epoch: 44 [12800/50000 ( 26%)]  Loss: 0.879315\n",
            "Train Epoch: 44 [25600/50000 ( 51%)]  Loss: 0.890096\n",
            "Train Epoch: 44 [38400/50000 ( 77%)]  Loss: 0.781896\n",
            "Test set: Average loss: 0.0060, Accuracy: 36743/50000 (73.49%)\n",
            "Test set: Average loss: 0.0084, Accuracy: 7102/10000 (71.02%)\n",
            "[45/75] \n",
            "Train Epoch: 45 [    0/50000 (  0%)]  Loss: 0.735611\n",
            "Train Epoch: 45 [12800/50000 ( 26%)]  Loss: 0.681520\n",
            "Train Epoch: 45 [25600/50000 ( 51%)]  Loss: 0.852104\n",
            "Train Epoch: 45 [38400/50000 ( 77%)]  Loss: 0.902278\n",
            "Test set: Average loss: 0.0061, Accuracy: 36800/50000 (73.60%)\n",
            "Test set: Average loss: 0.0087, Accuracy: 7084/10000 (70.84%)\n",
            "[46/75] \n",
            "Train Epoch: 46 [    0/50000 (  0%)]  Loss: 0.735587\n",
            "Train Epoch: 46 [12800/50000 ( 26%)]  Loss: 0.733771\n",
            "Train Epoch: 46 [25600/50000 ( 51%)]  Loss: 0.877663\n",
            "Train Epoch: 46 [38400/50000 ( 77%)]  Loss: 0.597183\n",
            "Test set: Average loss: 0.0062, Accuracy: 36323/50000 (72.65%)\n",
            "Test set: Average loss: 0.0085, Accuracy: 7095/10000 (70.95%)\n",
            "[47/75] \n",
            "Train Epoch: 47 [    0/50000 (  0%)]  Loss: 0.718035\n",
            "Train Epoch: 47 [12800/50000 ( 26%)]  Loss: 0.941102\n",
            "Train Epoch: 47 [25600/50000 ( 51%)]  Loss: 0.873867\n",
            "Train Epoch: 47 [38400/50000 ( 77%)]  Loss: 0.818374\n",
            "Test set: Average loss: 0.0061, Accuracy: 36726/50000 (73.45%)\n",
            "Test set: Average loss: 0.0084, Accuracy: 7144/10000 (71.44%)\n",
            "[48/75] \n",
            "Train Epoch: 48 [    0/50000 (  0%)]  Loss: 0.758855\n",
            "Train Epoch: 48 [12800/50000 ( 26%)]  Loss: 0.719099\n",
            "Train Epoch: 48 [25600/50000 ( 51%)]  Loss: 0.648913\n",
            "Train Epoch: 48 [38400/50000 ( 77%)]  Loss: 0.777504\n",
            "Test set: Average loss: 0.0060, Accuracy: 37079/50000 (74.16%)\n",
            "Test set: Average loss: 0.0084, Accuracy: 7190/10000 (71.90%)\n",
            "[49/75] \n",
            "Train Epoch: 49 [    0/50000 (  0%)]  Loss: 0.669659\n",
            "Train Epoch: 49 [12800/50000 ( 26%)]  Loss: 0.682024\n",
            "Train Epoch: 49 [25600/50000 ( 51%)]  Loss: 0.635903\n",
            "Train Epoch: 49 [38400/50000 ( 77%)]  Loss: 0.832644\n",
            "Test set: Average loss: 0.0059, Accuracy: 37063/50000 (74.13%)\n",
            "Test set: Average loss: 0.0083, Accuracy: 7180/10000 (71.80%)\n",
            "[50/75] \n",
            "Train Epoch: 50 [    0/50000 (  0%)]  Loss: 0.729497\n",
            "Train Epoch: 50 [12800/50000 ( 26%)]  Loss: 0.805576\n",
            "Train Epoch: 50 [25600/50000 ( 51%)]  Loss: 0.643237\n",
            "Train Epoch: 50 [38400/50000 ( 77%)]  Loss: 0.775685\n",
            "Test set: Average loss: 0.0060, Accuracy: 36994/50000 (73.99%)\n",
            "Test set: Average loss: 0.0084, Accuracy: 7208/10000 (72.08%)\n",
            "[51/75] \n",
            "Train Epoch: 51 [    0/50000 (  0%)]  Loss: 0.658930\n",
            "Train Epoch: 51 [12800/50000 ( 26%)]  Loss: 0.987269\n",
            "Train Epoch: 51 [25600/50000 ( 51%)]  Loss: 0.841651\n",
            "Train Epoch: 51 [38400/50000 ( 77%)]  Loss: 0.793591\n",
            "Test set: Average loss: 0.0060, Accuracy: 36932/50000 (73.86%)\n",
            "Test set: Average loss: 0.0086, Accuracy: 7158/10000 (71.58%)\n",
            "[52/75] \n",
            "Train Epoch: 52 [    0/50000 (  0%)]  Loss: 0.847156\n",
            "Train Epoch: 52 [12800/50000 ( 26%)]  Loss: 0.653757\n",
            "Train Epoch: 52 [25600/50000 ( 51%)]  Loss: 0.694152\n",
            "Train Epoch: 52 [38400/50000 ( 77%)]  Loss: 0.679143\n",
            "Test set: Average loss: 0.0059, Accuracy: 37349/50000 (74.70%)\n",
            "Test set: Average loss: 0.0082, Accuracy: 7271/10000 (72.71%)\n",
            "[53/75] \n",
            "Train Epoch: 53 [    0/50000 (  0%)]  Loss: 0.571692\n",
            "Train Epoch: 53 [12800/50000 ( 26%)]  Loss: 0.851746\n",
            "Train Epoch: 53 [25600/50000 ( 51%)]  Loss: 0.698121\n",
            "Train Epoch: 53 [38400/50000 ( 77%)]  Loss: 0.718060\n",
            "Test set: Average loss: 0.0062, Accuracy: 36947/50000 (73.89%)\n",
            "Test set: Average loss: 0.0088, Accuracy: 7139/10000 (71.39%)\n",
            "[54/75] \n",
            "Train Epoch: 54 [    0/50000 (  0%)]  Loss: 0.847100\n",
            "Train Epoch: 54 [12800/50000 ( 26%)]  Loss: 0.817469\n",
            "Train Epoch: 54 [25600/50000 ( 51%)]  Loss: 0.624203\n",
            "Train Epoch: 54 [38400/50000 ( 77%)]  Loss: 0.974072\n",
            "Test set: Average loss: 0.0058, Accuracy: 37485/50000 (74.97%)\n",
            "Test set: Average loss: 0.0082, Accuracy: 7269/10000 (72.69%)\n",
            "[55/75] \n",
            "Train Epoch: 55 [    0/50000 (  0%)]  Loss: 0.627488\n",
            "Train Epoch: 55 [12800/50000 ( 26%)]  Loss: 0.590052\n",
            "Train Epoch: 55 [25600/50000 ( 51%)]  Loss: 0.850019\n",
            "Train Epoch: 55 [38400/50000 ( 77%)]  Loss: 0.944167\n",
            "Test set: Average loss: 0.0061, Accuracy: 37055/50000 (74.11%)\n",
            "Test set: Average loss: 0.0085, Accuracy: 7188/10000 (71.88%)\n",
            "[56/75] \n",
            "Train Epoch: 56 [    0/50000 (  0%)]  Loss: 0.827460\n",
            "Train Epoch: 56 [12800/50000 ( 26%)]  Loss: 0.584712\n",
            "Train Epoch: 56 [25600/50000 ( 51%)]  Loss: 0.826364\n",
            "Train Epoch: 56 [38400/50000 ( 77%)]  Loss: 0.683465\n",
            "Test set: Average loss: 0.0060, Accuracy: 37018/50000 (74.04%)\n",
            "Test set: Average loss: 0.0086, Accuracy: 7190/10000 (71.90%)\n",
            "[57/75] \n",
            "Train Epoch: 57 [    0/50000 (  0%)]  Loss: 0.602757\n",
            "Train Epoch: 57 [12800/50000 ( 26%)]  Loss: 0.688786\n",
            "Train Epoch: 57 [25600/50000 ( 51%)]  Loss: 0.746047\n",
            "Train Epoch: 57 [38400/50000 ( 77%)]  Loss: 0.621022\n",
            "Test set: Average loss: 0.0058, Accuracy: 37605/50000 (75.21%)\n",
            "Test set: Average loss: 0.0083, Accuracy: 7239/10000 (72.39%)\n",
            "[58/75] \n",
            "Train Epoch: 58 [    0/50000 (  0%)]  Loss: 0.663920\n",
            "Train Epoch: 58 [12800/50000 ( 26%)]  Loss: 0.680523\n",
            "Train Epoch: 58 [25600/50000 ( 51%)]  Loss: 0.864290\n",
            "Train Epoch: 58 [38400/50000 ( 77%)]  Loss: 0.788157\n",
            "Test set: Average loss: 0.0057, Accuracy: 37684/50000 (75.37%)\n",
            "Test set: Average loss: 0.0083, Accuracy: 7246/10000 (72.46%)\n",
            "[59/75] \n",
            "Train Epoch: 59 [    0/50000 (  0%)]  Loss: 0.566698\n",
            "Train Epoch: 59 [12800/50000 ( 26%)]  Loss: 0.771565\n",
            "Train Epoch: 59 [25600/50000 ( 51%)]  Loss: 0.783672\n",
            "Train Epoch: 59 [38400/50000 ( 77%)]  Loss: 0.767753\n",
            "Test set: Average loss: 0.0059, Accuracy: 37324/50000 (74.65%)\n",
            "Test set: Average loss: 0.0083, Accuracy: 7217/10000 (72.17%)\n",
            "[60/75] \n",
            "Train Epoch: 60 [    0/50000 (  0%)]  Loss: 0.810598\n",
            "Train Epoch: 60 [12800/50000 ( 26%)]  Loss: 0.823912\n",
            "Train Epoch: 60 [25600/50000 ( 51%)]  Loss: 0.655177\n",
            "Train Epoch: 60 [38400/50000 ( 77%)]  Loss: 0.728130\n",
            "Test set: Average loss: 0.0057, Accuracy: 37783/50000 (75.57%)\n",
            "Test set: Average loss: 0.0082, Accuracy: 7272/10000 (72.72%)\n",
            "[61/75] \n",
            "Train Epoch: 61 [    0/50000 (  0%)]  Loss: 0.670785\n",
            "Train Epoch: 61 [12800/50000 ( 26%)]  Loss: 0.599397\n",
            "Train Epoch: 61 [25600/50000 ( 51%)]  Loss: 0.995976\n",
            "Train Epoch: 61 [38400/50000 ( 77%)]  Loss: 0.672526\n",
            "Test set: Average loss: 0.0060, Accuracy: 37089/50000 (74.18%)\n",
            "Test set: Average loss: 0.0085, Accuracy: 7198/10000 (71.98%)\n",
            "[62/75] \n",
            "Train Epoch: 62 [    0/50000 (  0%)]  Loss: 0.607653\n",
            "Train Epoch: 62 [12800/50000 ( 26%)]  Loss: 0.633074\n",
            "Train Epoch: 62 [25600/50000 ( 51%)]  Loss: 0.747785\n",
            "Train Epoch: 62 [38400/50000 ( 77%)]  Loss: 0.611616\n",
            "Test set: Average loss: 0.0055, Accuracy: 37992/50000 (75.98%)\n",
            "Test set: Average loss: 0.0080, Accuracy: 7301/10000 (73.01%)\n",
            "[63/75] \n",
            "Train Epoch: 63 [    0/50000 (  0%)]  Loss: 0.543198\n",
            "Train Epoch: 63 [12800/50000 ( 26%)]  Loss: 0.698168\n",
            "Train Epoch: 63 [25600/50000 ( 51%)]  Loss: 0.610834\n",
            "Train Epoch: 63 [38400/50000 ( 77%)]  Loss: 0.721040\n",
            "Test set: Average loss: 0.0060, Accuracy: 37259/50000 (74.52%)\n",
            "Test set: Average loss: 0.0087, Accuracy: 7149/10000 (71.49%)\n",
            "[64/75] \n",
            "Train Epoch: 64 [    0/50000 (  0%)]  Loss: 0.699249\n",
            "Train Epoch: 64 [12800/50000 ( 26%)]  Loss: 0.581231\n",
            "Train Epoch: 64 [25600/50000 ( 51%)]  Loss: 0.993545\n",
            "Train Epoch: 64 [38400/50000 ( 77%)]  Loss: 0.774110\n",
            "Test set: Average loss: 0.0057, Accuracy: 37689/50000 (75.38%)\n",
            "Test set: Average loss: 0.0081, Accuracy: 7282/10000 (72.82%)\n",
            "[65/75] \n",
            "Train Epoch: 65 [    0/50000 (  0%)]  Loss: 0.948173\n",
            "Train Epoch: 65 [12800/50000 ( 26%)]  Loss: 0.626062\n",
            "Train Epoch: 65 [25600/50000 ( 51%)]  Loss: 0.653965\n",
            "Train Epoch: 65 [38400/50000 ( 77%)]  Loss: 0.653290\n",
            "Test set: Average loss: 0.0055, Accuracy: 38058/50000 (76.12%)\n",
            "Test set: Average loss: 0.0079, Accuracy: 7363/10000 (73.63%)\n",
            "[66/75] \n",
            "Train Epoch: 66 [    0/50000 (  0%)]  Loss: 0.806485\n",
            "Train Epoch: 66 [12800/50000 ( 26%)]  Loss: 0.469914\n",
            "Train Epoch: 66 [25600/50000 ( 51%)]  Loss: 0.545402\n",
            "Train Epoch: 66 [38400/50000 ( 77%)]  Loss: 0.679521\n",
            "Test set: Average loss: 0.0057, Accuracy: 37695/50000 (75.39%)\n",
            "Test set: Average loss: 0.0082, Accuracy: 7277/10000 (72.77%)\n",
            "[67/75] \n",
            "Train Epoch: 67 [    0/50000 (  0%)]  Loss: 0.801425\n",
            "Train Epoch: 67 [12800/50000 ( 26%)]  Loss: 0.713794\n",
            "Train Epoch: 67 [25600/50000 ( 51%)]  Loss: 0.597216\n",
            "Train Epoch: 67 [38400/50000 ( 77%)]  Loss: 0.873934\n",
            "Test set: Average loss: 0.0055, Accuracy: 38043/50000 (76.09%)\n",
            "Test set: Average loss: 0.0079, Accuracy: 7323/10000 (73.23%)\n",
            "[68/75] \n",
            "Train Epoch: 68 [    0/50000 (  0%)]  Loss: 0.775031\n",
            "Train Epoch: 68 [12800/50000 ( 26%)]  Loss: 0.717938\n",
            "Train Epoch: 68 [25600/50000 ( 51%)]  Loss: 0.795007\n",
            "Train Epoch: 68 [38400/50000 ( 77%)]  Loss: 0.559765\n",
            "Test set: Average loss: 0.0056, Accuracy: 37843/50000 (75.69%)\n",
            "Test set: Average loss: 0.0079, Accuracy: 7336/10000 (73.36%)\n",
            "[69/75] \n",
            "Train Epoch: 69 [    0/50000 (  0%)]  Loss: 0.855356\n",
            "Train Epoch: 69 [12800/50000 ( 26%)]  Loss: 0.708996\n",
            "Train Epoch: 69 [25600/50000 ( 51%)]  Loss: 0.750694\n",
            "Train Epoch: 69 [38400/50000 ( 77%)]  Loss: 0.686960\n",
            "Test set: Average loss: 0.0054, Accuracy: 38249/50000 (76.50%)\n",
            "Test set: Average loss: 0.0077, Accuracy: 7423/10000 (74.23%)\n",
            "[70/75] \n",
            "Train Epoch: 70 [    0/50000 (  0%)]  Loss: 0.738450\n",
            "Train Epoch: 70 [12800/50000 ( 26%)]  Loss: 0.657042\n",
            "Train Epoch: 70 [25600/50000 ( 51%)]  Loss: 0.757030\n",
            "Train Epoch: 70 [38400/50000 ( 77%)]  Loss: 0.857716\n",
            "Test set: Average loss: 0.0057, Accuracy: 37733/50000 (75.47%)\n",
            "Test set: Average loss: 0.0082, Accuracy: 7307/10000 (73.07%)\n",
            "[71/75] \n",
            "Train Epoch: 71 [    0/50000 (  0%)]  Loss: 0.727471\n",
            "Train Epoch: 71 [12800/50000 ( 26%)]  Loss: 0.770213\n",
            "Train Epoch: 71 [25600/50000 ( 51%)]  Loss: 0.668290\n",
            "Train Epoch: 71 [38400/50000 ( 77%)]  Loss: 0.716766\n",
            "Test set: Average loss: 0.0056, Accuracy: 37803/50000 (75.61%)\n",
            "Test set: Average loss: 0.0081, Accuracy: 7263/10000 (72.63%)\n",
            "[72/75] \n",
            "Train Epoch: 72 [    0/50000 (  0%)]  Loss: 0.547106\n",
            "Train Epoch: 72 [12800/50000 ( 26%)]  Loss: 0.565727\n",
            "Train Epoch: 72 [25600/50000 ( 51%)]  Loss: 0.792133\n",
            "Train Epoch: 72 [38400/50000 ( 77%)]  Loss: 0.542053\n",
            "Test set: Average loss: 0.0056, Accuracy: 37909/50000 (75.82%)\n",
            "Test set: Average loss: 0.0081, Accuracy: 7285/10000 (72.85%)\n",
            "[73/75] \n",
            "Train Epoch: 73 [    0/50000 (  0%)]  Loss: 0.709149\n",
            "Train Epoch: 73 [12800/50000 ( 26%)]  Loss: 0.883054\n",
            "Train Epoch: 73 [25600/50000 ( 51%)]  Loss: 0.771945\n",
            "Train Epoch: 73 [38400/50000 ( 77%)]  Loss: 0.616168\n",
            "Test set: Average loss: 0.0057, Accuracy: 37739/50000 (75.48%)\n",
            "Test set: Average loss: 0.0083, Accuracy: 7302/10000 (73.02%)\n",
            "[74/75] \n",
            "Train Epoch: 74 [    0/50000 (  0%)]  Loss: 0.585589\n",
            "Train Epoch: 74 [12800/50000 ( 26%)]  Loss: 0.658189\n",
            "Train Epoch: 74 [25600/50000 ( 51%)]  Loss: 0.577363\n",
            "Train Epoch: 74 [38400/50000 ( 77%)]  Loss: 0.613268\n",
            "Test set: Average loss: 0.0054, Accuracy: 38353/50000 (76.71%)\n",
            "Test set: Average loss: 0.0080, Accuracy: 7350/10000 (73.50%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(76.706, 73.5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3Eh90Rzk5io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_by_row(logits, T = 1.0):\n",
        "    mx = np.max(logits, axis=-1, keepdims=True)\n",
        "    exp = np.exp((logits - mx)/T)\n",
        "    denominator = np.sum(exp, axis=-1, keepdims=True)\n",
        "    return exp/denominator\n",
        "\n",
        "def classifier_performance(model, train_loader, test_loader):\n",
        "\n",
        "    output_train_benign = []\n",
        "    train_label = []\n",
        "    for num, data in enumerate(train_loader):\n",
        "        images,labels = data\n",
        "        image_tensor= images.to(device)\n",
        "        img_variable = Variable(image_tensor, requires_grad=True)\n",
        "        output = model.forward(img_variable)\n",
        "\n",
        "        train_label.append(labels.numpy())\n",
        "        output_train_benign.append(softmax_by_row(output.data.cpu().numpy(),T = 1))\n",
        "\n",
        "\n",
        "    train_label = np.concatenate(train_label)\n",
        "    output_train_benign=np.concatenate(output_train_benign)\n",
        "\n",
        "    test_label = []\n",
        "    output_test_benign = []\n",
        "\n",
        "    for num, data in enumerate(test_loader):\n",
        "        images,labels = data\n",
        "\n",
        "        image_tensor= images.to(device)\n",
        "        img_variable = Variable(image_tensor, requires_grad=True)\n",
        "\n",
        "        output = model.forward(img_variable)\n",
        "\n",
        "        test_label.append(labels.numpy())\n",
        "        output_test_benign.append(softmax_by_row(output.data.cpu().numpy(),T = 1))\n",
        "\n",
        "\n",
        "    test_label = np.concatenate(test_label)\n",
        "    output_test_benign=np.concatenate(output_test_benign)\n",
        "\n",
        "\n",
        "    train_acc1 = np.sum(np.argmax(output_train_benign,axis=1) == train_label.flatten())/len(train_label)\n",
        "    test_acc1 = np.sum(np.argmax(output_test_benign,axis=1) == test_label.flatten())/len(test_label)\n",
        "\n",
        "    print('Accuracy: ', (train_acc1, test_acc1))\n",
        "\n",
        "    return output_train_benign, output_test_benign, train_label, test_label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def inference_via_confidence(confidence_mtx1, confidence_mtx2, label_vec1, label_vec2):\n",
        "    \n",
        "    #----------------First step: obtain confidence lists for both training dataset and test dataset--------------\n",
        "    confidence1 = []\n",
        "    confidence2 = []\n",
        "    acc1 = 0\n",
        "    acc2 = 0\n",
        "    for num in range(confidence_mtx1.shape[0]):\n",
        "        confidence1.append(confidence_mtx1[num,label_vec1[num]])\n",
        "        if np.argmax(confidence_mtx1[num,:]) == label_vec1[num]:\n",
        "            acc1 += 1\n",
        "            \n",
        "    for num in range(confidence_mtx2.shape[0]):\n",
        "        confidence2.append(confidence_mtx2[num,label_vec2[num]])\n",
        "        if np.argmax(confidence_mtx2[num,:]) == label_vec2[num]:\n",
        "            acc2 += 1\n",
        "    confidence1 = np.array(confidence1)\n",
        "    confidence2 = np.array(confidence2)\n",
        "    \n",
        "    print('model accuracy for training and test-', (acc1/confidence_mtx1.shape[0], acc2/confidence_mtx2.shape[0]) )\n",
        "    \n",
        "    \n",
        "    #sort_confidence = np.sort(confidence1)\n",
        "    sort_confidence = np.sort(np.concatenate((confidence1, confidence2)))\n",
        "    max_accuracy = 0.5\n",
        "    best_precision = 0.5\n",
        "    best_recall = 0.5\n",
        "    for num in range(len(sort_confidence)):\n",
        "        delta = sort_confidence[num]\n",
        "        ratio1 = np.sum(confidence1>=delta)/confidence_mtx1.shape[0]\n",
        "        ratio2 = np.sum(confidence2>=delta)/confidence_mtx2.shape[0]\n",
        "        accuracy_now = 0.5*(ratio1+1-ratio2)\n",
        "        if accuracy_now > max_accuracy:\n",
        "            max_accuracy = accuracy_now\n",
        "            best_precision = ratio1/(ratio1+ratio2)\n",
        "            best_recall = ratio1\n",
        "    print('membership inference accuracy is:', max_accuracy)\n",
        "    return max_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOgF49n9k-46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "6fd167d9-4d53-40cb-c61c-dd1a20929d0f"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import os\n",
        "import numpy as np\n",
        "import math \n",
        "import scipy\n",
        "import sys  \n",
        "\n",
        "\n",
        "output_train, output_test, train_label, test_label = classifier_performance(learner, trainloader, testloader)\n",
        "inference_accuracy=inference_via_confidence(output_train, output_test, train_label, test_label)\n",
        "print(\"Maximum Accuracy:\",inference_accuracy)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  (0.76796, 0.735)\n",
            "model accuracy for training and test- (0.76796, 0.735)\n",
            "membership inference accuracy is: 0.51856\n",
            "Maximum Accuracy: 0.51856\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}