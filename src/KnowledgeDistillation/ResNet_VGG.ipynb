{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ResNet_VGG.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPLOPeiziOPoxrZGKdh1ah4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"c12296b4353b4fb280abb7392cc5e7c9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f475f271651842889b5fe874f6d630af","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_311ef3694ee2409b8cb8bb71e60ea772","IPY_MODEL_b1ebb7d82a744aada6987fe0a79ff45c"]}},"f475f271651842889b5fe874f6d630af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"311ef3694ee2409b8cb8bb71e60ea772":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8f8f9a12ea5a459083e0e1b3ed7540b5","_dom_classes":[],"description":"","_model_name":"IntProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0392135006af404787ea706edbe080b4"}},"b1ebb7d82a744aada6987fe0a79ff45c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b003ff5d8d50470c9efc53b4427b0be8","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"170500096it [00:04, 41545556.70it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_db93b756642c4453a4d35c450eb91e63"}},"8f8f9a12ea5a459083e0e1b3ed7540b5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0392135006af404787ea706edbe080b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b003ff5d8d50470c9efc53b4427b0be8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"db93b756642c4453a4d35c450eb91e63":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"g4rbY_S3rySE","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as fcnal\n","from sklearn.pipeline import Pipeline\n","import torch.nn.functional as F\n","from torchvision import datasets, transforms\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","from collections import OrderedDict\n","import math\n","import os\n","from google.colab import drive\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ao6L5vXsfUN","colab_type":"code","outputId":"0e8a437f-07d9-4300-878a-42e00b44e5ea","executionInfo":{"status":"ok","timestamp":1581452086922,"user_tz":-330,"elapsed":10206,"user":{"displayName":"Vasisht Vasisht","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAVwnMADhdoq0kiAbKetXytg58LjCY-cepd5I4m=s64","userId":"18321686459009329525"}},"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["c12296b4353b4fb280abb7392cc5e7c9","f475f271651842889b5fe874f6d630af","311ef3694ee2409b8cb8bb71e60ea772","b1ebb7d82a744aada6987fe0a79ff45c","8f8f9a12ea5a459083e0e1b3ed7540b5","0392135006af404787ea706edbe080b4","b003ff5d8d50470c9efc53b4427b0be8","db93b756642c4453a4d35c450eb91e63"]}},"source":["batch_size=128\n","lr=1e-3\n","log_interval=100\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","\n","print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c12296b4353b4fb280abb7392cc5e7c9","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pT2niN8WtJYR","colab_type":"code","colab":{}},"source":["__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n","           'resnet152', 'resnext50_32x4d', 'resnext101_32x8d']\n","\n","def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n","                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n","\n","\n","def conv1x1(in_planes, out_planes, stride=1):\n","    \"\"\"1x1 convolution\"\"\"\n","    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(BasicBlock, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        if groups != 1 or base_width != 64:\n","            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n","        if dilation > 1:\n","            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n","        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv3x3(inplanes, planes, stride)\n","        self.bn1 = norm_layer(planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(planes, planes)\n","        self.bn2 = norm_layer(planes)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","\n","    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n","                 base_width=64, dilation=1, norm_layer=None):\n","        super(Bottleneck, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        width = int(planes * (base_width / 64.)) * groups\n","        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n","        self.conv1 = conv1x1(inplanes, width)\n","        self.bn1 = norm_layer(width)\n","        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n","        self.bn2 = norm_layer(width)\n","        self.conv3 = conv1x1(width, planes * self.expansion)\n","        self.bn3 = norm_layer(planes * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        identity = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            identity = self.downsample(x)\n","\n","        out += identity\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","\n","    def __init__(self, block, layers, num_classes=10, zero_init_residual=False,\n","                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n","                 norm_layer=None):\n","        super(ResNet, self).__init__()\n","        if norm_layer is None:\n","            norm_layer = nn.BatchNorm2d\n","        self._norm_layer = norm_layer\n","\n","        self.inplanes = 64\n","        self.dilation = 1\n","        if replace_stride_with_dilation is None:\n","            # each element in the tuple indicates if we should replace\n","            # the 2x2 stride with a dilated convolution instead\n","            replace_stride_with_dilation = [False, False, False]\n","        if len(replace_stride_with_dilation) != 3:\n","            raise ValueError(\"replace_stride_with_dilation should be None \"\n","                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n","        self.groups = groups\n","        self.base_width = width_per_group\n","\n","        ## CIFAR10: kernel_size 7 -> 3, stride 2 -> 1, padding 3->1\n","        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=1, padding=1, bias=False)\n","        ## END\n","\n","        self.bn1 = norm_layer(self.inplanes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n","                                       dilate=replace_stride_with_dilation[0])\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n","                                       dilate=replace_stride_with_dilation[1])\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n","                                       dilate=replace_stride_with_dilation[2])\n","        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","        # Zero-initialize the last BN in each residual branch,\n","        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n","        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n","        if zero_init_residual:\n","            for m in self.modules():\n","                if isinstance(m, Bottleneck):\n","                    nn.init.constant_(m.bn3.weight, 0)\n","                elif isinstance(m, BasicBlock):\n","                    nn.init.constant_(m.bn2.weight, 0)\n","\n","    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n","        norm_layer = self._norm_layer\n","        downsample = None\n","        previous_dilation = self.dilation\n","        if dilate:\n","            self.dilation *= stride\n","            stride = 1\n","        if stride != 1 or self.inplanes != planes * block.expansion:\n","            downsample = nn.Sequential(\n","                conv1x1(self.inplanes, planes * block.expansion, stride),\n","                norm_layer(planes * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n","                            self.base_width, previous_dilation, norm_layer))\n","        self.inplanes = planes * block.expansion\n","        for _ in range(1, blocks):\n","            layers.append(block(self.inplanes, planes, groups=self.groups,\n","                                base_width=self.base_width, dilation=self.dilation,\n","                                norm_layer=norm_layer))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu(x)\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.reshape(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","def _resnet(arch, block, layers, pretrained, progress, device, **kwargs):\n","    model = ResNet(block, layers, **kwargs)\n","    if pretrained:        \n","        model_save_name = 'resnet50.pt'\n","        colab='Colab Notebooks'\n","        path = F\"/content/gdrive/My Drive/{colab}/KnowledgeDistillation/{model_save_name}\"\n","        state_dict = torch.load(path, map_location=device)\n","        model.load_state_dict(state_dict)\n","    return model\n","\n","\n","\n","def resnet50(pretrained=False, progress=True, device='cpu', **kwargs):\n","    \"\"\"Constructs a ResNet-50 model.\n","\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","        progress (bool): If True, displays a progress bar of the download to stderr\n","    \"\"\"\n","    return _resnet('resnet50', Bottleneck, [3, 4, 6, 3], pretrained, progress, device,\n","                   **kwargs)\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wEHY07SVtbcl","colab_type":"code","colab":{}},"source":["def train(model, epochs):\n","    model.train()\n","    for epoch in range(epochs):\n","\n","        for batch_idx, (data, target) in enumerate(trainloader):\n","            data, target = data.to(device), target.to(device)\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            #loss = nn.NLLLoss(output,target)\n","            loss.backward()\n","\n","            optimizer.step()\n","            if batch_idx % 100 == 0:\n","                done = batch_idx * len(data)\n","                percentage = 100. * batch_idx / len(trainloader)\n","                print(f'Train Epoch: {epoch} [{done:5}/{len(trainloader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')\n","\n","        test(model, trainloader)\n","        test(model, testloader)\n","\n","\n","def test(model, loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, target).item() # sum up batch loss\n","            #test_loss += nn.NLLLoss(output, target).item()\n","            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n","            correct += pred.eq(target.data.view_as(pred)).sum().item()\n","\n","        test_loss /= len(loader.dataset)\n","        accuracy = 100. * correct / len(loader.dataset)\n","        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loader.dataset)} ({accuracy:.2f}%)')\n","    return accuracy\n","\n","\n","\n","\n","\n","\n","def distill_training(teacher=None, learner=None, data_loader=None,\n","                     test_loader=None, optimizer=None,\n","                     criterion=None, n_epochs=0):\n","    \"\"\"\n","    :param teacher: network to provide soft labels in training\n","    :param learner: network to distill knowledge into\n","    :param data_loader: data loader for training data set\n","    :param test_loaderL data loader for validation data\n","    :param optimizer: optimizer for training\n","    :param criterion: objective function, should allow for soft labels.\n","                      We suggest softCrossEntropy\n","    :param n_epochs: epochs for training\n","    :param verbose: verbose == True will print loss at each batch\n","    :return: None, teacher model is trained in place\n","    \"\"\"\n","    losses = []\n","    for epoch in range(n_epochs):\n","        teacher.eval()\n","        learner.train()\n","        print(\"[{}/{}] \".format(epoch, n_epochs))\n","        for i, batch in enumerate(data_loader):\n","            with torch.set_grad_enabled(False):\n","                data, labels = batch\n","                data, labels = data.to(device), labels.to(device)\n","                soft_lables = teacher(data)\n","\n","            with torch.set_grad_enabled(True):\n","                optimizer.zero_grad()\n","                outputs = learner(data)\n","                loss = criterion(outputs, torch.max(soft_lables.type(torch.cuda.LongTensor), 1)[1])#, labels)\n","                loss.backward()\n","                optimizer.step()\n","                losses.append(loss.item())\n","\n","            if i%100==0:\n","                done= i * len(data)\n","                percentage = 100. * i / len(data_loader)\n","                print(f'Train Epoch: {epoch} [{done:5}/{len(data_loader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')\n","\n","        # evaluate performance on testset at the end of each epoch\n","       \n","\n","        train_acc = test(learner, data_loader)\n","        test_acc = test(learner, test_loader)\n","    return train_acc, test_acc\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAxYo3Yis6Qt","colab_type":"code","outputId":"8fc95ca2-e637-445b-b599-b94a3d34016d","executionInfo":{"status":"ok","timestamp":1581452134836,"user_tz":-330,"elapsed":58074,"user":{"displayName":"Vasisht Vasisht","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAVwnMADhdoq0kiAbKetXytg58LjCY-cepd5I4m=s64","userId":"18321686459009329525"}},"colab":{"base_uri":"https://localhost:8080/","height":159}},"source":["drive.mount('/content/gdrive')\n","teacher = resnet50(pretrained=True)\n","teacher=teacher.cuda()\n","criterion = nn.CrossEntropyLoss()\n","test(teacher,testloader)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n","Mounted at /content/gdrive\n","Test set: Average loss: 0.0026, Accuracy: 9438/10000 (94.38%)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["94.38"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"d5u0abqT1tV2","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import torch\n","import torch.nn.functional as F\n","\n","class BinActive(torch.autograd.Function):\n","    '''\n","    Binarize the input activations and calculate the mean across channel dimension.\n","    '''\n","    def forward(self, input):\n","        self.save_for_backward(input)\n","        size = input.size()\n","        mean = torch.mean(input.abs(), 1, keepdim=True)\n","        input = input.sign()\n","        return input, mean\n","\n","    def backward(self, grad_output, grad_output_mean):\n","        input, = self.saved_tensors\n","        grad_input = grad_output.clone()\n","        grad_input[input.ge(1)] = 0\n","        grad_input[input.le(-1)] = 0\n","        return grad_input\n","\n","class BinConv2d(nn.Module):\n","    def __init__(self, input_channels, output_channels,\n","            kernel_size=-1, stride=-1, padding=-1, dropout=0):\n","        super(BinConv2d, self).__init__()\n","        self.layer_type = 'BinConv2d'\n","        self.kernel_size = kernel_size\n","        self.stride = stride\n","        self.padding = padding\n","        self.dropout_ratio = 0\n","        dropout=0\n","        self.bn = nn.BatchNorm2d(input_channels, eps=1e-4, momentum=0.1, affine=True)\n","        self.bn.weight.data = self.bn.weight.data.zero_().add(1.0)\n","        if dropout!=0:\n","            self.dropout = nn.Dropout(dropout)\n","        self.conv = nn.Conv2d(input_channels, output_channels,\n","                kernel_size=kernel_size, stride=stride, padding=padding)\n","        self.relu = nn.ReLU(inplace=True)\n","    \n","    def forward(self, x):\n","        x = self.bn(x)\n","        x, mean = BinActive()(x)\n","        x = self.conv(x)\n","        x = self.relu(x)\n","        return x\n","\n","cfg = {\n","    'VGG11': ['M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG13': [64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n","    'VGG16': [64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n","    'VGG19': [64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n","}\n","\n","class Bin_VGG_train(nn.Module):\n","    def __init__(self, vgg_name):\n","        super(Bin_VGG_train, self).__init__()\n","        self.features = self._make_layers(cfg[vgg_name])\n","        self.classifier = nn.Linear(512, 10)\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n","                m.weight.data.normal_(0, math.sqrt(2./n))\n","                m.bias.data.zero_()\n","\n","    def forward(self, x):\n","        out = self.features(x)\n","        out = out.view(out.size(0), -1)\n","        out = self.classifier(out)\n","        return out\n","\n","    def _make_layers(self, cfg):\n","        layers = OrderedDict([\n","            ('conv0', nn.Conv2d(3, 64, kernel_size=3, padding=1, stride=1)),\n","            ('bn0', nn.BatchNorm2d(64)),\n","            ('relu0', nn.ReLU(inplace=True))\n","            ])\n","        in_channels = 64\n","        cnt = 1\n","        for x in cfg:\n","            if x == 'M':\n","                layers['pool'+str(cnt)] = nn.MaxPool2d(kernel_size=2, stride=2)\n","                cnt += 1\n","            else:\n","                layers['conv'+str(cnt)] = BinConv2d(input_channels=in_channels, output_channels=x, stride=1, kernel_size=3, padding=1)\n","                cnt += 1\n","                layers['bn'+str(cnt)] = nn.BatchNorm2d(x)\n","                cnt += 1\n","                layers['relu'+str(cnt)] = nn.ReLU(inplace=True)\n","                cnt += 1\n","                in_channels = x\n","        layers['pool'+str(cnt)] = nn.AvgPool2d(kernel_size=1, stride=1)\n","        return nn.Sequential(layers)\n","\n","\n","import torch.nn as nn\n","import numpy\n","\n","class BinOp():\n","    def __init__(self, model):\n","        # count the number of Conv2d\n","        count_Conv2d = 0\n","        for m in model.modules():\n","            if isinstance(m, nn.Conv2d):\n","                count_Conv2d = count_Conv2d + 1\n","\n","        start_range = 1\n","        end_range = count_Conv2d-2\n","        self.bin_range = numpy.linspace(start_range,\n","                end_range, end_range-start_range+1)\\\n","                        .astype('int').tolist()\n","        self.num_of_params = len(self.bin_range)\n","        self.saved_params = []\n","        self.target_params = []\n","        self.target_modules = []\n","        index = -1\n","        for m in model.modules():\n","            if isinstance(m, nn.Conv2d):\n","                index = index + 1\n","                if index in self.bin_range:\n","                    tmp = m.weight.data.clone()\n","                    self.saved_params.append(tmp)\n","                    self.target_modules.append(m.weight)\n","\n","    def binarization(self):\n","        self.meancenterConvParams()\n","        self.clampConvParams()\n","        self.save_params()\n","        self.binarizeConvParams()\n","\n","    def meancenterConvParams(self):\n","        for index in range(self.num_of_params):\n","            s = self.target_modules[index].data.size()\n","            negMean = self.target_modules[index].data.mean(1, keepdim=True).\\\n","                    mul(-1).expand_as(self.target_modules[index].data)\n","            self.target_modules[index].data = self.target_modules[index].data.add(negMean)\n","\n","    def clampConvParams(self):\n","        for index in range(self.num_of_params):\n","            self.target_modules[index].data = \\\n","                    self.target_modules[index].data.clamp(-1.0, 1.0)\n","\n","    def save_params(self):\n","        for index in range(self.num_of_params):\n","            self.saved_params[index].copy_(self.target_modules[index].data)\n","\n","    def binarizeConvParams(self):\n","        for index in range(self.num_of_params):\n","            n = self.target_modules[index].data[0].nelement()\n","            s = self.target_modules[index].data.size()\n","            m = self.target_modules[index].data.norm(1, 3, keepdim=True)\\\n","                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n)\n","            self.target_modules[index].data = \\\n","                    self.target_modules[index].data.sign().mul(m.expand(s))\n","\n","    def restore(self):\n","        for index in range(self.num_of_params):\n","            self.target_modules[index].data.copy_(self.saved_params[index])\n","\n","    def updateBinaryGradWeight(self):\n","        for index in range(self.num_of_params):\n","            weight = self.target_modules[index].data\n","            n = weight[0].nelement()\n","            s = weight.size()\n","            m = weight.norm(1, 3, keepdim=True)\\\n","                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n","            m[weight.lt(-1.0)] = 0 \n","            m[weight.gt(1.0)] = 0\n","            # m = m.add(1.0/n).mul(1.0-1.0/s[1]).mul(n)\n","            # self.target_modules[index].grad.data = \\\n","            #         self.target_modules[index].grad.data.mul(m)\n","            m = m.mul(self.target_modules[index].grad.data)\n","            m_add = weight.sign().mul(self.target_modules[index].grad.data)\n","            m_add = m_add.sum(3, keepdim=True)\\\n","                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n","            m_add = m_add.mul(weight.sign())\n","            self.target_modules[index].grad.data = m.add(m_add).mul(1.0-1.0/s[1]).mul(n)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uFhia9TYtgeI","colab_type":"code","outputId":"06cfc982-e838-4ac3-99be-7bbd310dea28","executionInfo":{"status":"ok","timestamp":1581452295689,"user_tz":-330,"elapsed":218901,"user":{"displayName":"Vasisht Vasisht","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAVwnMADhdoq0kiAbKetXytg58LjCY-cepd5I4m=s64","userId":"18321686459009329525"}},"colab":{"base_uri":"https://localhost:8080/","height":278}},"source":["learner = Bin_VGG_train('VGG16')\n","\n","learner.cuda()\n","learner = torch.nn.DataParallel(learner, device_ids=range(torch.cuda.device_count()))\n","\n","\n","optimizer = optim.Adam(learner.parameters(), lr=1e-3,weight_decay=0.0000)\n","criterion = nn.CrossEntropyLoss()\n","\n","# define the binarization operator\n","bin_op = BinOp(learner)\n","\n","distill_training(teacher, learner, trainloader, testloader, optimizer, criterion, 2)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["[0/2] \n","Train Epoch: 0 [    0/50000 (  0%)]  Loss: 2.861181\n","Train Epoch: 0 [12800/50000 ( 26%)]  Loss: 1.992234\n","Train Epoch: 0 [25600/50000 ( 51%)]  Loss: 1.722363\n","Train Epoch: 0 [38400/50000 ( 77%)]  Loss: 1.903023\n","Test set: Average loss: 0.0133, Accuracy: 18243/50000 (36.49%)\n","Test set: Average loss: 0.0165, Accuracy: 3861/10000 (38.61%)\n","[1/2] \n","Train Epoch: 1 [    0/50000 (  0%)]  Loss: 1.536093\n","Train Epoch: 1 [12800/50000 ( 26%)]  Loss: 1.554250\n","Train Epoch: 1 [25600/50000 ( 51%)]  Loss: 1.564918\n","Train Epoch: 1 [38400/50000 ( 77%)]  Loss: 1.446706\n","Test set: Average loss: 0.0116, Accuracy: 22521/50000 (45.04%)\n","Test set: Average loss: 0.0147, Accuracy: 4583/10000 (45.83%)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(45.042, 45.83)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"wFVtujUS2GtG","colab_type":"code","colab":{}},"source":["def softmax_by_row(logits, T = 1.0):\n","    mx = np.max(logits, axis=-1, keepdims=True)\n","    exp = np.exp((logits - mx)/T)\n","    denominator = np.sum(exp, axis=-1, keepdims=True)\n","    return exp/denominator\n","\n","def classifier_performance(model, train_loader, test_loader):\n","\n","    output_train_benign = []\n","    train_label = []\n","    for num, data in enumerate(train_loader):\n","        images,labels = data\n","        image_tensor= images.to(device)\n","        img_variable = Variable(image_tensor, requires_grad=True)\n","        output = model.forward(img_variable)\n","\n","        train_label.append(labels.numpy())\n","        output_train_benign.append(softmax_by_row(output.data.cpu().numpy(),T = 1))\n","\n","\n","    train_label = np.concatenate(train_label)\n","    output_train_benign=np.concatenate(output_train_benign)\n","\n","    test_label = []\n","    output_test_benign = []\n","\n","    for num, data in enumerate(test_loader):\n","        images,labels = data\n","\n","        image_tensor= images.to(device)\n","        img_variable = Variable(image_tensor, requires_grad=True)\n","\n","        output = model.forward(img_variable)\n","\n","        test_label.append(labels.numpy())\n","        output_test_benign.append(softmax_by_row(output.data.cpu().numpy(),T = 1))\n","\n","\n","    test_label = np.concatenate(test_label)\n","    output_test_benign=np.concatenate(output_test_benign)\n","\n","\n","    train_acc1 = np.sum(np.argmax(output_train_benign,axis=1) == train_label.flatten())/len(train_label)\n","    test_acc1 = np.sum(np.argmax(output_test_benign,axis=1) == test_label.flatten())/len(test_label)\n","\n","    print('Accuracy: ', (train_acc1, test_acc1))\n","\n","    return output_train_benign, output_test_benign, train_label, test_label\n","\n","\n","\n","\n","def inference_via_confidence(confidence_mtx1, confidence_mtx2, label_vec1, label_vec2):\n","    \n","    #----------------First step: obtain confidence lists for both training dataset and test dataset--------------\n","    confidence1 = []\n","    confidence2 = []\n","    acc1 = 0\n","    acc2 = 0\n","    for num in range(confidence_mtx1.shape[0]):\n","        confidence1.append(confidence_mtx1[num,label_vec1[num]])\n","        if np.argmax(confidence_mtx1[num,:]) == label_vec1[num]:\n","            acc1 += 1\n","            \n","    for num in range(confidence_mtx2.shape[0]):\n","        confidence2.append(confidence_mtx2[num,label_vec2[num]])\n","        if np.argmax(confidence_mtx2[num,:]) == label_vec2[num]:\n","            acc2 += 1\n","    confidence1 = np.array(confidence1)\n","    confidence2 = np.array(confidence2)\n","    \n","    print('model accuracy for training and test-', (acc1/confidence_mtx1.shape[0], acc2/confidence_mtx2.shape[0]) )\n","    \n","    \n","    #sort_confidence = np.sort(confidence1)\n","    sort_confidence = np.sort(np.concatenate((confidence1, confidence2)))\n","    max_accuracy = 0.5\n","    best_precision = 0.5\n","    best_recall = 0.5\n","    for num in range(len(sort_confidence)):\n","        delta = sort_confidence[num]\n","        ratio1 = np.sum(confidence1>=delta)/confidence_mtx1.shape[0]\n","        ratio2 = np.sum(confidence2>=delta)/confidence_mtx2.shape[0]\n","        accuracy_now = 0.5*(ratio1+1-ratio2)\n","        if accuracy_now > max_accuracy:\n","            max_accuracy = accuracy_now\n","            best_precision = ratio1/(ratio1+ratio2)\n","            best_recall = ratio1\n","    print('membership inference accuracy is:', max_accuracy)\n","    return max_accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i5pT47242KWY","colab_type":"code","outputId":"be3caf67-c9ff-45e9-aff5-ab366830e753","executionInfo":{"status":"ok","timestamp":1581452345262,"user_tz":-330,"elapsed":268451,"user":{"displayName":"Vasisht Vasisht","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAVwnMADhdoq0kiAbKetXytg58LjCY-cepd5I4m=s64","userId":"18321686459009329525"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["from torch.autograd import Variable\n","import os\n","import numpy as np\n","import math \n","import scipy\n","import sys  \n","\n","##teacher\n","output_train, output_test, train_label, test_label = classifier_performance(teacher, trainloader, testloader)\n","inference_accuracy=inference_via_confidence(output_train, output_test, train_label, test_label)\n","print(\"Maximum Accuracy:\",inference_accuracy)\n","\n","##learner\n","output_train, output_test, train_label, test_label = classifier_performance(learner, trainloader, testloader)\n","inference_accuracy=inference_via_confidence(output_train, output_test, train_label, test_label)\n","print(\"Maximum Accuracy:\",inference_accuracy)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Accuracy:  (0.9999, 0.9438)\n","model accuracy for training and test- (0.9999, 0.9438)\n","membership inference accuracy is: 0.5687599999999999\n","Maximum Accuracy: 0.5687599999999999\n","Accuracy:  (0.45224, 0.4583)\n","model accuracy for training and test- (0.45224, 0.4583)\n","membership inference accuracy is: 0.50244\n","Maximum Accuracy: 0.50244\n"],"name":"stdout"}]}]}