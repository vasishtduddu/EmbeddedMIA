{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AdvReg_AlexNet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhnG_uaW7tW_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import time\n",
        "import random\n",
        "import uuid\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch.optim as optim\n",
        "from collections import OrderedDict\n",
        "import numpy as np\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as datasets\n",
        "use_cuda = torch.cuda.is_available()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Pxtf1y7XLj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\n",
        "       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
        "    maxk = max(topk)\n",
        "    batch_size = target.size(0)\n",
        "\n",
        "    _, pred = output.topk(maxk, 1, True, True)\n",
        "    pred = pred.t()\n",
        "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "    res = []\n",
        "    for k in topk:\n",
        "        correct_k = correct[:k].view(-1).float().sum(0)\n",
        "        res.append(correct_k.mul_(100.0 / batch_size))\n",
        "    return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImjIoRyR2QBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=5),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class InferenceAttack_HZ(nn.Module):\n",
        "    def __init__(self,num_classes):\n",
        "        self.num_classes=num_classes\n",
        "        super(InferenceAttack_HZ, self).__init__()\n",
        "        self.features=nn.Sequential(\n",
        "            nn.Linear(10,1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(1024,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512,64),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "        self.labels=nn.Sequential(\n",
        "           nn.Linear(num_classes,128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,64),\n",
        "            nn.ReLU(),\n",
        "            )\n",
        "        self.combine=nn.Sequential(\n",
        "            nn.Linear(64*2,256),\n",
        "            \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256,128),\n",
        "            \n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128,64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64,1),\n",
        "            )\n",
        "        for key in self.state_dict():\n",
        "            print (key)\n",
        "            if key.split('.')[-1] == 'weight':    \n",
        "                nn.init.normal(self.state_dict()[key], std=0.01)\n",
        "                print (key)\n",
        "                \n",
        "            elif key.split('.')[-1] == 'bias':\n",
        "                self.state_dict()[key][...] = 0\n",
        "        self.output= nn.Sigmoid()\n",
        " \n",
        "    def forward(self,x,l):       \n",
        "        out_x = self.features(x)\n",
        "        out_l = self.labels(l)      \n",
        "        is_member =self.combine( torch.cat((out_x  ,out_l),1))     \n",
        "        return self.output(is_member)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Md2tk-H4k1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "52ab6a35-ca34-4bc9-f6bb-4f4d2e7567f7"
      },
      "source": [
        "batch_privacy=100\n",
        "train_batch=100\n",
        "test_batch=100\n",
        "lr=0.05\n",
        "state={}\n",
        "state['lr']=lr\n",
        "\n",
        "\n",
        "model = AlexNet(10)\n",
        "model = model.cuda()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "criterion_attack = nn.MSELoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
        "inferenece_model = InferenceAttack_HZ(10).cuda()\n",
        "private_train_criterion = nn.MSELoss()\n",
        "optimizer_mem = optim.Adam(inferenece_model.parameters(), lr=0.00001)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "features.0.weight\n",
            "features.0.weight\n",
            "features.0.bias\n",
            "features.2.weight\n",
            "features.2.weight\n",
            "features.2.bias\n",
            "features.4.weight\n",
            "features.4.weight\n",
            "features.4.bias\n",
            "labels.0.weight\n",
            "labels.0.weight\n",
            "labels.0.bias\n",
            "labels.2.weight\n",
            "labels.2.weight\n",
            "labels.2.bias\n",
            "combine.0.weight\n",
            "combine.0.weight\n",
            "combine.0.bias\n",
            "combine.2.weight\n",
            "combine.2.weight\n",
            "combine.2.bias\n",
            "combine.4.weight\n",
            "combine.4.weight\n",
            "combine.4.bias\n",
            "combine.6.weight\n",
            "combine.6.weight\n",
            "combine.6.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:61: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hCbzfiB49lW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "23f73afd-81b2-4296-f200-089881743efe"
      },
      "source": [
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=1)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n",
        "\n",
        "\n",
        "trainset_private = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "trainloader_private = data.DataLoader(trainset, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "\n",
        "\n",
        "r = np.arange(50000)\n",
        "np.random.shuffle(r)\n",
        "\n",
        "private_trainset_intrain = []\n",
        "private_trainset_intest = []\n",
        "\n",
        "private_testset_intrain =[] \n",
        "private_testset_intest =[] \n",
        "\n",
        "\n",
        "for i in range(25000):\n",
        "    private_trainset_intrain.append(trainset[r[i]])\n",
        "\n",
        "\n",
        "for i in range(25000,50000):\n",
        "    private_testset_intrain.append(trainset[r[i]])\n",
        "\n",
        "    \n",
        "r = np.arange(10000)\n",
        "np.random.shuffle(r)\n",
        "  \n",
        "for i in range(5000):\n",
        "    private_trainset_intest.append(testset[r[i]])\n",
        "\n",
        "\n",
        "for i in range(5000,10000):\n",
        "    private_testset_intest.append(testset[r[i]])\n",
        "\n",
        "\n",
        "private_trainloader_intrain = data.DataLoader(private_trainset_intrain, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "private_trainloader_intest = data.DataLoader(private_trainset_intest, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "\n",
        "\n",
        "private_testloader_intrain = data.DataLoader(private_testset_intrain, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "private_testloader_intest = data.DataLoader(private_testset_intest, batch_size=batch_privacy, shuffle=True, num_workers=1)\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvR5h0D-6ne-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#privacy_train = train_inference_model\n",
        "def train_inference_model(trainloader, model,inference_model, criterion, optimizer, epoch, use_cuda,num_batchs=1000):\n",
        "    global best_acc\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    mtop1_a = AverageMeter()\n",
        "    mtop5_a = AverageMeter()\n",
        "    \n",
        "    inference_model.train()\n",
        "    model.eval()\n",
        "    # switch to evaluate mode\n",
        "\n",
        "    end = time.time()\n",
        "    first_id = -1\n",
        "    for batch_idx,((tr_input, tr_target) ,(te_input, te_target)) in trainloader:\n",
        "        # measure data loading time\n",
        "        if first_id == -1:\n",
        "            first_id = batch_idx\n",
        "        \n",
        "        data_time.update(time.time() - end)\n",
        "        tr_input = tr_input.cuda()\n",
        "        te_input = te_input.cuda()\n",
        "        tr_target = tr_target.cuda()\n",
        "        te_target = te_target.cuda()\n",
        "        \n",
        "        \n",
        "        v_tr_input = torch.autograd.Variable(tr_input)\n",
        "        v_te_input = torch.autograd.Variable(te_input)\n",
        "        v_tr_target = torch.autograd.Variable(tr_target)\n",
        "        v_te_target = torch.autograd.Variable(te_target)\n",
        "        \n",
        "        # compute output\n",
        "        model_input =torch.cat((v_tr_input,v_te_input))\n",
        "        \n",
        "        pred_outputs = model(model_input)\n",
        "        \n",
        "        infer_input= torch.cat((v_tr_target,v_te_target))\n",
        "        \n",
        "        mtop1, mtop5 =accuracy(pred_outputs.data, infer_input.data, topk=(1, 5))\n",
        "        \n",
        "        mtop1_a.update(mtop1.item(), model_input.size(0))\n",
        "        mtop5_a.update(mtop5.item(), model_input.size(0))\n",
        "\n",
        "        \n",
        "        \n",
        "        one_hot_tr = torch.from_numpy((np.zeros((infer_input.size(0),10))-1)).cuda().type(torch.cuda.FloatTensor)\n",
        "        target_one_hot_tr = one_hot_tr.scatter_(1, infer_input.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
        "\n",
        "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
        "        \n",
        "\n",
        "        attack_model_input = pred_outputs#torch.cat((pred_outputs,infer_input_one_hot),1)\n",
        "        member_output = inference_model(attack_model_input,infer_input_one_hot)\n",
        "        \n",
        "        \n",
        "        \n",
        "        is_member_labels = torch.from_numpy(np.reshape(np.concatenate((np.zeros(v_tr_input.size(0)),np.ones(v_te_input.size(0)))),[-1,1])).cuda()\n",
        "        \n",
        "        v_is_member_labels = torch.autograd.Variable(is_member_labels).type(torch.cuda.FloatTensor)\n",
        "\n",
        "        loss = criterion(member_output, v_is_member_labels)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1=np.mean((member_output.data.cpu().numpy() >0.5)==v_is_member_labels.data.cpu().numpy())\n",
        "        losses.update(loss.item(), model_input.size(0))\n",
        "        top1.update(prec1, model_input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "        if batch_idx-first_id > num_batchs:\n",
        "            break\n",
        "\n",
        "        # plot progress\n",
        "        if batch_idx%100==0:\n",
        "            print  ('({batch}/{size}) | Loss: {loss:.4f} | '.format(\n",
        "                    batch=batch_idx ,\n",
        "                    size=500,\n",
        "                    loss=losses.avg,\n",
        "                    ))\n",
        "\n",
        "    return (losses.avg, top1.avg)\n",
        "\n",
        "#train_privatly=train_model_advreg\n",
        "def train_model_advreg(trainloader, model,inference_model, criterion, optimizer, epoch, use_cuda,num_batchs=10000,alpha=0.9):\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "    inference_model.eval()\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "    end = time.time()\n",
        "    first_id = -1\n",
        "    for batch_idx, (inputs, targets) in (trainloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "        if first_id == -1:\n",
        "            first_id = batch_idx\n",
        "        \n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n",
        "        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n",
        "\n",
        "        # compute output\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        \n",
        "        one_hot_tr = torch.from_numpy((np.zeros((outputs.size(0),10))-1)).cuda().type(torch.cuda.FloatTensor)\n",
        "        target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n",
        "\n",
        "        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n",
        "        \n",
        "        inference_output = inference_model ( outputs,infer_input_one_hot)\n",
        "        #print (inference_output.mean())\n",
        "        \n",
        "\n",
        "        loss = criterion(outputs, targets) + (alpha)*(((inference_output-1.0).pow(2).mean()))\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        # plot progress\n",
        "        if batch_idx%100==0:\n",
        "            print  ('({batch}/{size}) | Loss: {loss:.4f} |'.format(\n",
        "                    batch=batch_idx + 1,\n",
        "                    size=500,\n",
        "                    loss=losses.avg,\n",
        "                    ))\n",
        "        if batch_idx-first_id >= num_batchs:\n",
        "            break\n",
        "\n",
        "    return (losses.avg, top1.avg)\n",
        "\n",
        "\n",
        "def test(testloader, model, criterion, epoch, use_cuda):\n",
        "    global best_acc\n",
        "    batch_time = AverageMeter()\n",
        "    data_time = AverageMeter()\n",
        "    losses = AverageMeter()\n",
        "    top1 = AverageMeter()\n",
        "    top5 = AverageMeter()\n",
        "\n",
        "    # switch to evaluate mode\n",
        "    model.eval()\n",
        "\n",
        "    end = time.time()\n",
        "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "        # measure data loading time\n",
        "        data_time.update(time.time() - end)\n",
        "\n",
        "        if use_cuda:\n",
        "            inputs, targets = inputs.cuda(), targets.cuda()\n",
        "        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n",
        "\n",
        "        # compute output\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # measure accuracy and record loss\n",
        "        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n",
        "        losses.update(loss.item(), inputs.size(0))\n",
        "        top1.update(prec1.item(), inputs.size(0))\n",
        "        top5.update(prec5.item(), inputs.size(0))\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "    return (losses.avg, top1.avg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNMVIcCl5FVB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "075bc147-f733-427b-d776-89252021289e"
      },
      "source": [
        "epochs=200\n",
        "\n",
        "for epoch in range(0, epochs):\n",
        "\n",
        "    print('\\nEpoch: [%d | %d]' % (epoch + 1, epochs))\n",
        "\n",
        "    train_enum = enumerate(trainloader)\n",
        "    train_private_enum = enumerate(zip(trainloader_private,testloader))\n",
        "    for i in range(500//2):\n",
        "        \n",
        "        if epoch>3:\n",
        "            privacy_loss, privacy_acc = train_inference_model(train_private_enum,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda,1)\n",
        "            train_loss, train_acc = train_model_advreg(train_enum, model,inferenece_model, criterion, optimizer, epoch, use_cuda,1,1)\n",
        "            \n",
        "            if i%100 ==0:\n",
        "                print('Privacy Accuracy',privacy_acc)\n",
        "                print('Training Accuracy',train_acc)\n",
        "            if  (i+1)%50 ==0:\n",
        "                train_private_enum = enumerate(zip(trainloader_private,testloader))\n",
        "        else:\n",
        "            train_loss, train_acc = train_model_advreg(train_enum, model,inferenece_model, criterion, optimizer, epoch, use_cuda,1000,0)\n",
        "            break\n",
        "        \n",
        "        \n",
        "    test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n",
        "    train_loss, train_acc = test(trainloader, model, criterion, epoch, use_cuda)\n",
        "    print ('Train Accuracy',train_acc)\n",
        "    print ('Test Accuracy',test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: [1 | 200]\n",
            "(1/500) | Loss: 0.7008 |\n",
            "(101/500) | Loss: 0.8107 |\n",
            "(201/500) | Loss: 0.8078 |\n",
            "(301/500) | Loss: 0.8058 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:173: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy 73.492\n",
            "Test Accuracy 70.42\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [2 | 200]\n",
            "(1/500) | Loss: 0.7243 |\n",
            "(101/500) | Loss: 0.7824 |\n",
            "(201/500) | Loss: 0.7908 |\n",
            "(301/500) | Loss: 0.7948 |\n",
            "Train Accuracy 73.626\n",
            "Test Accuracy 70.96\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [3 | 200]\n",
            "(1/500) | Loss: 0.7718 |\n",
            "(101/500) | Loss: 0.7646 |\n",
            "(201/500) | Loss: 0.7837 |\n",
            "(301/500) | Loss: 0.7890 |\n",
            "Train Accuracy 73.136\n",
            "Test Accuracy 69.81\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [4 | 200]\n",
            "(1/500) | Loss: 0.8477 |\n",
            "(101/500) | Loss: 0.7771 |\n",
            "(201/500) | Loss: 0.7846 |\n",
            "(301/500) | Loss: 0.7926 |\n",
            "Train Accuracy 72.788\n",
            "Test Accuracy 70.18\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [5 | 200]\n",
            "(0/500) | Loss: 0.2561 | \n",
            "(1/500) | Loss: 0.9386 |\n",
            "Privacy Accuracy 0.5016666666666667\n",
            "Training Accuracy 70.703125\n",
            "(0/500) | Loss: 0.2494 | \n",
            "(101/500) | Loss: 1.0966 |\n",
            "(0/500) | Loss: 0.2479 | \n",
            "(201/500) | Loss: 0.9392 |\n",
            "Privacy Accuracy 0.565\n",
            "Training Accuracy 72.265625\n",
            "(0/500) | Loss: 0.2502 | \n",
            "(301/500) | Loss: 1.3055 |\n",
            "(0/500) | Loss: 0.2505 | \n",
            "Privacy Accuracy 0.54\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.408\n",
            "Test Accuracy 68.31\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [6 | 200]\n",
            "(0/500) | Loss: 0.2500 | \n",
            "(1/500) | Loss: 1.1209 |\n",
            "Privacy Accuracy 0.5466666666666666\n",
            "Training Accuracy 71.484375\n",
            "(0/500) | Loss: 0.2486 | \n",
            "(101/500) | Loss: 1.1354 |\n",
            "(0/500) | Loss: 0.2485 | \n",
            "(201/500) | Loss: 0.8974 |\n",
            "Privacy Accuracy 0.5466666666666666\n",
            "Training Accuracy 74.609375\n",
            "(0/500) | Loss: 0.2499 | \n",
            "(301/500) | Loss: 1.1073 |\n",
            "(0/500) | Loss: 0.2507 | \n",
            "Privacy Accuracy 0.5233333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 72.962\n",
            "Test Accuracy 70.61\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [7 | 200]\n",
            "(0/500) | Loss: 0.2480 | \n",
            "(1/500) | Loss: 1.0580 |\n",
            "Privacy Accuracy 0.51\n",
            "Training Accuracy 73.4375\n",
            "(0/500) | Loss: 0.2512 | \n",
            "(101/500) | Loss: 1.1664 |\n",
            "(0/500) | Loss: 0.2495 | \n",
            "(201/500) | Loss: 1.0344 |\n",
            "Privacy Accuracy 0.5366666666666666\n",
            "Training Accuracy 73.046875\n",
            "(0/500) | Loss: 0.2512 | \n",
            "(301/500) | Loss: 1.0666 |\n",
            "(0/500) | Loss: 0.2499 | \n",
            "Privacy Accuracy 0.5433333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.264\n",
            "Test Accuracy 68.23\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [8 | 200]\n",
            "(0/500) | Loss: 0.2486 | \n",
            "(1/500) | Loss: 1.0732 |\n",
            "Privacy Accuracy 0.5033333333333333\n",
            "Training Accuracy 74.21875\n",
            "(0/500) | Loss: 0.2509 | \n",
            "(101/500) | Loss: 0.9820 |\n",
            "(0/500) | Loss: 0.2510 | \n",
            "(201/500) | Loss: 1.2683 |\n",
            "Privacy Accuracy 0.5033333333333333\n",
            "Training Accuracy 64.0625\n",
            "(0/500) | Loss: 0.2498 | \n",
            "(301/500) | Loss: 1.0562 |\n",
            "(0/500) | Loss: 0.2505 | \n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 72.616\n",
            "Test Accuracy 70.14\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [9 | 200]\n",
            "(0/500) | Loss: 0.2502 | \n",
            "(1/500) | Loss: 1.1187 |\n",
            "Privacy Accuracy 0.5333333333333333\n",
            "Training Accuracy 70.703125\n",
            "(0/500) | Loss: 0.2466 | \n",
            "(101/500) | Loss: 1.0756 |\n",
            "(0/500) | Loss: 0.2514 | \n",
            "(201/500) | Loss: 1.0507 |\n",
            "Privacy Accuracy 0.48833333333333334\n",
            "Training Accuracy 67.578125\n",
            "(0/500) | Loss: 0.2532 | \n",
            "(301/500) | Loss: 1.3012 |\n",
            "(0/500) | Loss: 0.2494 | \n",
            "Privacy Accuracy 0.5333333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 73.26\n",
            "Test Accuracy 70.14\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [10 | 200]\n",
            "(0/500) | Loss: 0.2505 | \n",
            "(1/500) | Loss: 1.2082 |\n",
            "Privacy Accuracy 0.535\n",
            "Training Accuracy 69.53125\n",
            "(0/500) | Loss: 0.2501 | \n",
            "(101/500) | Loss: 0.9952 |\n",
            "(0/500) | Loss: 0.2493 | \n",
            "(201/500) | Loss: 0.9403 |\n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 71.09375\n",
            "(0/500) | Loss: 0.2507 | \n",
            "(301/500) | Loss: 1.0998 |\n",
            "(0/500) | Loss: 0.2510 | \n",
            "Privacy Accuracy 0.5283333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.958\n",
            "Test Accuracy 69.42\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [11 | 200]\n",
            "(0/500) | Loss: 0.2511 | \n",
            "(1/500) | Loss: 1.0774 |\n",
            "Privacy Accuracy 0.5066666666666667\n",
            "Training Accuracy 76.171875\n",
            "(0/500) | Loss: 0.2534 | \n",
            "(101/500) | Loss: 1.0042 |\n",
            "(0/500) | Loss: 0.2524 | \n",
            "(201/500) | Loss: 1.1296 |\n",
            "Privacy Accuracy 0.5166666666666667\n",
            "Training Accuracy 69.140625\n",
            "(0/500) | Loss: 0.2506 | \n",
            "(301/500) | Loss: 1.1392 |\n",
            "(0/500) | Loss: 0.2503 | \n",
            "Privacy Accuracy 0.5166666666666667\n",
            "Training Accuracy 0\n",
            "Train Accuracy 73.0\n",
            "Test Accuracy 70.31\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [12 | 200]\n",
            "(0/500) | Loss: 0.2506 | \n",
            "(1/500) | Loss: 1.3344 |\n",
            "Privacy Accuracy 0.5333333333333333\n",
            "Training Accuracy 66.015625\n",
            "(0/500) | Loss: 0.2512 | \n",
            "(101/500) | Loss: 1.2367 |\n",
            "(0/500) | Loss: 0.2507 | \n",
            "(201/500) | Loss: 1.2155 |\n",
            "Privacy Accuracy 0.5366666666666666\n",
            "Training Accuracy 67.578125\n",
            "(0/500) | Loss: 0.2482 | \n",
            "(301/500) | Loss: 0.9637 |\n",
            "(0/500) | Loss: 0.2516 | \n",
            "Privacy Accuracy 0.49\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.7\n",
            "Test Accuracy 70.14\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [13 | 200]\n",
            "(0/500) | Loss: 0.2501 | \n",
            "(1/500) | Loss: 1.1869 |\n",
            "Privacy Accuracy 0.525\n",
            "Training Accuracy 67.96875\n",
            "(0/500) | Loss: 0.2523 | \n",
            "(101/500) | Loss: 1.1967 |\n",
            "(0/500) | Loss: 0.2509 | \n",
            "(201/500) | Loss: 0.8337 |\n",
            "Privacy Accuracy 0.5366666666666666\n",
            "Training Accuracy 75.78125\n",
            "(0/500) | Loss: 0.2501 | \n",
            "(301/500) | Loss: 1.2572 |\n",
            "(0/500) | Loss: 0.2492 | \n",
            "Privacy Accuracy 0.525\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.886\n",
            "Test Accuracy 69.05\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [14 | 200]\n",
            "(0/500) | Loss: 0.2517 | \n",
            "(1/500) | Loss: 0.9832 |\n",
            "Privacy Accuracy 0.5116666666666667\n",
            "Training Accuracy 74.21875\n",
            "(0/500) | Loss: 0.2525 | \n",
            "(101/500) | Loss: 0.9732 |\n",
            "(0/500) | Loss: 0.2489 | \n",
            "(201/500) | Loss: 1.3407 |\n",
            "Privacy Accuracy 0.5516666666666666\n",
            "Training Accuracy 64.453125\n",
            "(0/500) | Loss: 0.2496 | \n",
            "(301/500) | Loss: 1.0716 |\n",
            "(0/500) | Loss: 0.2502 | \n",
            "Privacy Accuracy 0.5283333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 72.504\n",
            "Test Accuracy 69.13\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [15 | 200]\n",
            "(0/500) | Loss: 0.2465 | \n",
            "(1/500) | Loss: 0.9865 |\n",
            "Privacy Accuracy 0.5566666666666666\n",
            "Training Accuracy 71.09375\n",
            "(0/500) | Loss: 0.2489 | \n",
            "(101/500) | Loss: 1.1513 |\n",
            "(0/500) | Loss: 0.2509 | \n",
            "(201/500) | Loss: 1.3428 |\n",
            "Privacy Accuracy 0.53\n",
            "Training Accuracy 69.140625\n",
            "(0/500) | Loss: 0.2511 | \n",
            "(301/500) | Loss: 0.8624 |\n",
            "(0/500) | Loss: 0.2511 | \n",
            "Privacy Accuracy 0.5\n",
            "Training Accuracy 0\n",
            "Train Accuracy 74.29\n",
            "Test Accuracy 70.65\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [16 | 200]\n",
            "(0/500) | Loss: 0.2502 | \n",
            "(1/500) | Loss: 1.0004 |\n",
            "Privacy Accuracy 0.51\n",
            "Training Accuracy 75.0\n",
            "(0/500) | Loss: 0.2455 | \n",
            "(101/500) | Loss: 1.1962 |\n",
            "(0/500) | Loss: 0.2532 | \n",
            "(201/500) | Loss: 1.0140 |\n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 72.265625\n",
            "(0/500) | Loss: 0.2496 | \n",
            "(301/500) | Loss: 1.1493 |\n",
            "(0/500) | Loss: 0.2508 | \n",
            "Privacy Accuracy 0.49166666666666664\n",
            "Training Accuracy 0\n",
            "Train Accuracy 72.812\n",
            "Test Accuracy 70.23\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [17 | 200]\n",
            "(0/500) | Loss: 0.2479 | \n",
            "(1/500) | Loss: 1.0396 |\n",
            "Privacy Accuracy 0.5216666666666666\n",
            "Training Accuracy 67.1875\n",
            "(0/500) | Loss: 0.2471 | \n",
            "(101/500) | Loss: 1.1072 |\n",
            "(0/500) | Loss: 0.2501 | \n",
            "(201/500) | Loss: 1.0242 |\n",
            "Privacy Accuracy 0.4866666666666667\n",
            "Training Accuracy 74.21875\n",
            "(0/500) | Loss: 0.2470 | \n",
            "(301/500) | Loss: 0.9987 |\n",
            "(0/500) | Loss: 0.2524 | \n",
            "Privacy Accuracy 0.51\n",
            "Training Accuracy 0\n",
            "Train Accuracy 73.398\n",
            "Test Accuracy 70.25\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [18 | 200]\n",
            "(0/500) | Loss: 0.2492 | \n",
            "(1/500) | Loss: 1.0783 |\n",
            "Privacy Accuracy 0.54\n",
            "Training Accuracy 73.828125\n",
            "(0/500) | Loss: 0.2493 | \n",
            "(101/500) | Loss: 0.9919 |\n",
            "(0/500) | Loss: 0.2528 | \n",
            "(201/500) | Loss: 1.2540 |\n",
            "Privacy Accuracy 0.5016666666666667\n",
            "Training Accuracy 73.4375\n",
            "(0/500) | Loss: 0.2507 | \n",
            "(301/500) | Loss: 0.8838 |\n",
            "(0/500) | Loss: 0.2513 | \n",
            "Privacy Accuracy 0.5283333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 72.856\n",
            "Test Accuracy 69.69\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [19 | 200]\n",
            "(0/500) | Loss: 0.2514 | \n",
            "(1/500) | Loss: 1.0300 |\n",
            "Privacy Accuracy 0.5366666666666666\n",
            "Training Accuracy 72.65625\n",
            "(0/500) | Loss: 0.2491 | \n",
            "(101/500) | Loss: 1.0605 |\n",
            "(0/500) | Loss: 0.2497 | \n",
            "(201/500) | Loss: 0.9235 |\n",
            "Privacy Accuracy 0.515\n",
            "Training Accuracy 75.78125\n",
            "(0/500) | Loss: 0.2509 | \n",
            "(301/500) | Loss: 0.9844 |\n",
            "(0/500) | Loss: 0.2499 | \n",
            "Privacy Accuracy 0.505\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.922\n",
            "Test Accuracy 69.72\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [20 | 200]\n",
            "(0/500) | Loss: 0.2509 | \n",
            "(1/500) | Loss: 1.1291 |\n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 70.3125\n",
            "(0/500) | Loss: 0.2524 | \n",
            "(101/500) | Loss: 0.9335 |\n",
            "(0/500) | Loss: 0.2495 | \n",
            "(201/500) | Loss: 1.0540 |\n",
            "Privacy Accuracy 0.53\n",
            "Training Accuracy 69.921875\n",
            "(0/500) | Loss: 0.2513 | \n",
            "(301/500) | Loss: 0.9291 |\n",
            "(0/500) | Loss: 0.2522 | \n",
            "Privacy Accuracy 0.5166666666666667\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.37\n",
            "Test Accuracy 68.64\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [21 | 200]\n",
            "(0/500) | Loss: 0.2506 | \n",
            "(1/500) | Loss: 1.0326 |\n",
            "Privacy Accuracy 0.5433333333333333\n",
            "Training Accuracy 72.65625\n",
            "(0/500) | Loss: 0.2522 | \n",
            "(101/500) | Loss: 1.0682 |\n",
            "(0/500) | Loss: 0.2487 | \n",
            "(201/500) | Loss: 1.2601 |\n",
            "Privacy Accuracy 0.5283333333333333\n",
            "Training Accuracy 69.140625\n",
            "(0/500) | Loss: 0.2518 | \n",
            "(301/500) | Loss: 0.9549 |\n",
            "(0/500) | Loss: 0.2507 | \n",
            "Privacy Accuracy 0.5016666666666667\n",
            "Training Accuracy 0\n",
            "Train Accuracy 74.346\n",
            "Test Accuracy 71.42\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [22 | 200]\n",
            "(0/500) | Loss: 0.2491 | \n",
            "(1/500) | Loss: 0.9248 |\n",
            "Privacy Accuracy 0.5233333333333333\n",
            "Training Accuracy 72.65625\n",
            "(0/500) | Loss: 0.2467 | \n",
            "(101/500) | Loss: 0.9583 |\n",
            "(0/500) | Loss: 0.2515 | \n",
            "(201/500) | Loss: 1.0273 |\n",
            "Privacy Accuracy 0.5233333333333333\n",
            "Training Accuracy 76.953125\n",
            "(0/500) | Loss: 0.2502 | \n",
            "(301/500) | Loss: 1.1065 |\n",
            "(0/500) | Loss: 0.2505 | \n",
            "Privacy Accuracy 0.53\n",
            "Training Accuracy 0\n",
            "Train Accuracy 72.202\n",
            "Test Accuracy 68.47\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [23 | 200]\n",
            "(0/500) | Loss: 0.2474 | \n",
            "(1/500) | Loss: 1.1495 |\n",
            "Privacy Accuracy 0.5383333333333333\n",
            "Training Accuracy 72.65625\n",
            "(0/500) | Loss: 0.2515 | \n",
            "(101/500) | Loss: 1.0904 |\n",
            "(0/500) | Loss: 0.2500 | \n",
            "(201/500) | Loss: 1.0344 |\n",
            "Privacy Accuracy 0.5483333333333333\n",
            "Training Accuracy 75.390625\n",
            "(0/500) | Loss: 0.2472 | \n",
            "(301/500) | Loss: 0.9605 |\n",
            "(0/500) | Loss: 0.2525 | \n",
            "Privacy Accuracy 0.5083333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 70.67\n",
            "Test Accuracy 69.2\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [24 | 200]\n",
            "(0/500) | Loss: 0.2526 | \n",
            "(1/500) | Loss: 1.0838 |\n",
            "Privacy Accuracy 0.48833333333333334\n",
            "Training Accuracy 72.265625\n",
            "(0/500) | Loss: 0.2505 | \n",
            "(101/500) | Loss: 1.1651 |\n",
            "(0/500) | Loss: 0.2540 | \n",
            "(201/500) | Loss: 1.0225 |\n",
            "Privacy Accuracy 0.5033333333333333\n",
            "Training Accuracy 69.140625\n",
            "(0/500) | Loss: 0.2478 | \n",
            "(301/500) | Loss: 1.0058 |\n",
            "(0/500) | Loss: 0.2520 | \n",
            "Privacy Accuracy 0.5216666666666666\n",
            "Training Accuracy 0\n",
            "Train Accuracy 72.938\n",
            "Test Accuracy 69.65\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [25 | 200]\n",
            "(0/500) | Loss: 0.2519 | \n",
            "(1/500) | Loss: 0.9678 |\n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 73.828125\n",
            "(0/500) | Loss: 0.2531 | \n",
            "(101/500) | Loss: 1.1230 |\n",
            "(0/500) | Loss: 0.2534 | \n",
            "(201/500) | Loss: 1.0225 |\n",
            "Privacy Accuracy 0.505\n",
            "Training Accuracy 73.4375\n",
            "(0/500) | Loss: 0.2486 | \n",
            "(301/500) | Loss: 1.1739 |\n",
            "(0/500) | Loss: 0.2490 | \n",
            "Privacy Accuracy 0.53\n",
            "Training Accuracy 0\n",
            "Train Accuracy 73.236\n",
            "Test Accuracy 70.5\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [26 | 200]\n",
            "(0/500) | Loss: 0.2460 | \n",
            "(1/500) | Loss: 0.9901 |\n",
            "Privacy Accuracy 0.5283333333333333\n",
            "Training Accuracy 70.3125\n",
            "(0/500) | Loss: 0.2501 | \n",
            "(101/500) | Loss: 0.9503 |\n",
            "(0/500) | Loss: 0.2498 | \n",
            "(201/500) | Loss: 1.0916 |\n",
            "Privacy Accuracy 0.5133333333333333\n",
            "Training Accuracy 69.53125\n",
            "(0/500) | Loss: 0.2486 | \n",
            "(301/500) | Loss: 1.1294 |\n",
            "(0/500) | Loss: 0.2502 | \n",
            "Privacy Accuracy 0.5483333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 73.09\n",
            "Test Accuracy 70.14\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [27 | 200]\n",
            "(0/500) | Loss: 0.2505 | \n",
            "(1/500) | Loss: 0.9533 |\n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 74.21875\n",
            "(0/500) | Loss: 0.2476 | \n",
            "(101/500) | Loss: 1.1698 |\n",
            "(0/500) | Loss: 0.2464 | \n",
            "(201/500) | Loss: 1.0377 |\n",
            "Privacy Accuracy 0.555\n",
            "Training Accuracy 75.0\n",
            "(0/500) | Loss: 0.2470 | \n",
            "(301/500) | Loss: 1.1120 |\n",
            "(0/500) | Loss: 0.2477 | \n",
            "Privacy Accuracy 0.49666666666666665\n",
            "Training Accuracy 0\n",
            "Train Accuracy 73.54\n",
            "Test Accuracy 70.95\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [28 | 200]\n",
            "(0/500) | Loss: 0.2481 | \n",
            "(1/500) | Loss: 1.1027 |\n",
            "Privacy Accuracy 0.52\n",
            "Training Accuracy 71.484375\n",
            "(0/500) | Loss: 0.2522 | \n",
            "(101/500) | Loss: 1.1814 |\n",
            "(0/500) | Loss: 0.2486 | \n",
            "(201/500) | Loss: 1.1430 |\n",
            "Privacy Accuracy 0.545\n",
            "Training Accuracy 70.703125\n",
            "(0/500) | Loss: 0.2531 | \n",
            "(301/500) | Loss: 0.9657 |\n",
            "(0/500) | Loss: 0.2538 | \n",
            "Privacy Accuracy 0.54\n",
            "Training Accuracy 0\n",
            "Train Accuracy 69.554\n",
            "Test Accuracy 65.31\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [29 | 200]\n",
            "(0/500) | Loss: 0.2514 | \n",
            "(1/500) | Loss: 1.2758 |\n",
            "Privacy Accuracy 0.52\n",
            "Training Accuracy 67.96875\n",
            "(0/500) | Loss: 0.2485 | \n",
            "(101/500) | Loss: 1.2616 |\n",
            "(0/500) | Loss: 0.2476 | \n",
            "(201/500) | Loss: 0.9251 |\n",
            "Privacy Accuracy 0.5316666666666666\n",
            "Training Accuracy 75.390625\n",
            "(0/500) | Loss: 0.2506 | \n",
            "(301/500) | Loss: 1.0476 |\n",
            "(0/500) | Loss: 0.2528 | \n",
            "Privacy Accuracy 0.51\n",
            "Training Accuracy 0\n",
            "Train Accuracy 73.312\n",
            "Test Accuracy 70.8\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [30 | 200]\n",
            "(0/500) | Loss: 0.2524 | \n",
            "(1/500) | Loss: 0.9255 |\n",
            "Privacy Accuracy 0.5033333333333333\n",
            "Training Accuracy 73.046875\n",
            "(0/500) | Loss: 0.2486 | \n",
            "(101/500) | Loss: 1.0448 |\n",
            "(0/500) | Loss: 0.2485 | \n",
            "(201/500) | Loss: 1.1862 |\n",
            "Privacy Accuracy 0.5066666666666667\n",
            "Training Accuracy 67.578125\n",
            "(0/500) | Loss: 0.2530 | \n",
            "(301/500) | Loss: 1.0015 |\n",
            "(0/500) | Loss: 0.2484 | \n",
            "Privacy Accuracy 0.5333333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.928\n",
            "Test Accuracy 68.84\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [31 | 200]\n",
            "(0/500) | Loss: 0.2509 | \n",
            "(1/500) | Loss: 1.1807 |\n",
            "Privacy Accuracy 0.555\n",
            "Training Accuracy 70.3125\n",
            "(0/500) | Loss: 0.2497 | \n",
            "(101/500) | Loss: 1.1572 |\n",
            "(0/500) | Loss: 0.2509 | \n",
            "(201/500) | Loss: 1.1144 |\n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 73.828125\n",
            "(0/500) | Loss: 0.2516 | \n",
            "(301/500) | Loss: 1.3223 |\n",
            "(0/500) | Loss: 0.2479 | \n",
            "Privacy Accuracy 0.5416666666666666\n",
            "Training Accuracy 0\n",
            "Train Accuracy 74.234\n",
            "Test Accuracy 71.72\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [32 | 200]\n",
            "(0/500) | Loss: 0.2506 | \n",
            "(1/500) | Loss: 0.9623 |\n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 72.65625\n",
            "(0/500) | Loss: 0.2481 | \n",
            "(101/500) | Loss: 0.9770 |\n",
            "(0/500) | Loss: 0.2472 | \n",
            "(201/500) | Loss: 1.2752 |\n",
            "Privacy Accuracy 0.57\n",
            "Training Accuracy 67.1875\n",
            "(0/500) | Loss: 0.2487 | \n",
            "(301/500) | Loss: 1.1150 |\n",
            "(0/500) | Loss: 0.2509 | \n",
            "Privacy Accuracy 0.5183333333333333\n",
            "Training Accuracy 0\n",
            "Train Accuracy 71.772\n",
            "Test Accuracy 69.27\n",
            "Privacy Accuracy 0\n",
            "\n",
            "Epoch: [33 | 200]\n",
            "(0/500) | Loss: 0.2474 | \n",
            "(1/500) | Loss: 0.9531 |\n",
            "Privacy Accuracy 0.5533333333333333\n",
            "Training Accuracy 74.609375\n",
            "(0/500) | Loss: 0.2497 | \n",
            "(101/500) | Loss: 1.0982 |\n",
            "(0/500) | Loss: 0.2494 | \n",
            "(201/500) | Loss: 1.1226 |\n",
            "Privacy Accuracy 0.5133333333333333\n",
            "Training Accuracy 69.140625\n",
            "(0/500) | Loss: 0.2473 | \n",
            "(301/500) | Loss: 1.1116 |\n",
            "(0/500) | Loss: 0.2502 | \n",
            "Privacy Accuracy 0.5033333333333333\n",
            "Training Accuracy 0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}