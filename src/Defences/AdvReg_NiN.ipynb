{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AdvReg_NiN.ipynb","provenance":[],"authorship_tag":"ABX9TyP54nhAtYDYTI61DugXFsfs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"rhnG_uaW7tW_","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","\n","import os\n","import shutil\n","import time\n","import random\n","import uuid\n","import torch\n","from torch.optim.optimizer import Optimizer, required\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import argparse\n","import torch.optim as optim\n","from collections import OrderedDict\n","import numpy as np\n","from torchvision import datasets, transforms\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.utils.data as data\n","import torchvision.datasets as datasets\n","use_cuda = torch.cuda.is_available()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o7Pxtf1y7XLj","colab_type":"code","colab":{}},"source":["class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\n","       Imported from https://github.com/pytorch/examples/blob/master/imagenet/main.py#L247-L262\n","    \"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def accuracy(output, target, topk=(1,)):\n","    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n","    maxk = max(topk)\n","    batch_size = target.size(0)\n","\n","    _, pred = output.topk(maxk, 1, True, True)\n","    pred = pred.t()\n","    correct = pred.eq(target.view(1, -1).expand_as(pred))\n","\n","    res = []\n","    for k in topk:\n","        correct_k = correct[:k].view(-1).float().sum(0)\n","        res.append(correct_k.mul_(100.0 / batch_size))\n","    return res"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ImjIoRyR2QBY","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.classifier = nn.Sequential(\n","                nn.Conv2d(3, 192, kernel_size=5, stride=1, padding=2),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(192, 160, kernel_size=1, stride=1, padding=0),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(160,  96, kernel_size=1, stride=1, padding=0),\n","                nn.ReLU(inplace=True),\n","                nn.MaxPool2d(kernel_size=3, stride=2, padding=1),\n","                nn.Dropout(0.5),\n","\n","                nn.Conv2d(96, 192, kernel_size=5, stride=1, padding=2),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                nn.ReLU(inplace=True),\n","                nn.AvgPool2d(kernel_size=3, stride=2, padding=1),\n","                nn.Dropout(0.5),\n","\n","                nn.Conv2d(192, 192, kernel_size=3, stride=1, padding=1),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(192, 192, kernel_size=1, stride=1, padding=0),\n","                nn.ReLU(inplace=True),\n","                nn.Conv2d(192,  10, kernel_size=1, stride=1, padding=0),\n","                nn.ReLU(inplace=True),\n","                nn.AvgPool2d(kernel_size=8, stride=1, padding=0),\n","\n","                )\n","\n","    def forward(self, x):\n","        x = self.classifier(x)\n","        x = x.view(x.size(0), 10)\n","        return x\n","\n","\n","\n","class InferenceAttack_HZ(nn.Module):\n","    def __init__(self,num_classes):\n","        self.num_classes=num_classes\n","        super(InferenceAttack_HZ, self).__init__()\n","        self.features=nn.Sequential(\n","            nn.Linear(10,1024),\n","            nn.ReLU(),\n","            nn.Linear(1024,512),\n","            nn.ReLU(),\n","            nn.Linear(512,64),\n","            nn.ReLU(),\n","            )\n","        self.labels=nn.Sequential(\n","           nn.Linear(num_classes,128),\n","            nn.ReLU(),\n","            nn.Linear(128,64),\n","            nn.ReLU(),\n","            )\n","        self.combine=nn.Sequential(\n","            nn.Linear(64*2,256),\n","            \n","            nn.ReLU(),\n","            nn.Linear(256,128),\n","            \n","            nn.ReLU(),\n","            nn.Linear(128,64),\n","            nn.ReLU(),\n","            nn.Linear(64,1),\n","            )\n","        for key in self.state_dict():\n","            print (key)\n","            if key.split('.')[-1] == 'weight':    \n","                nn.init.normal(self.state_dict()[key], std=0.01)\n","                print (key)\n","                \n","            elif key.split('.')[-1] == 'bias':\n","                self.state_dict()[key][...] = 0\n","        self.output= nn.Sigmoid()\n"," \n","    def forward(self,x,l):       \n","        out_x = self.features(x)\n","        out_l = self.labels(l)      \n","        is_member =self.combine( torch.cat((out_x  ,out_l),1))     \n","        return self.output(is_member)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Md2tk-H4k1M","colab_type":"code","outputId":"a7d46b72-a159-4237-9d43-cf2c57fa5e4c","executionInfo":{"status":"ok","timestamp":1584012933678,"user_tz":-330,"elapsed":1566,"user":{"displayName":"Vasisht Vasisht","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdnsVWWQG2LPrqHSKgFAow9xj3qikoca93I6gg=s64","userId":"18321686459009329525"}},"colab":{"base_uri":"https://localhost:8080/","height":503}},"source":["batch_privacy=100\n","train_batch=100\n","test_batch=100\n","lr=1e-5\n","state={}\n","state['lr']=lr\n","\n","\n","model = Net()\n","model = model.cuda()\n","criterion = nn.CrossEntropyLoss()\n","criterion_attack = nn.MSELoss()\n","#optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.5, weight_decay=5e-4)\n","optimizer = optim.Adam(model.parameters(), lr=1e-3,weight_decay=5e-5)\n","#optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n","inferenece_model = InferenceAttack_HZ(10).cuda()\n","private_train_criterion = nn.MSELoss()\n","optimizer_mem = optim.Adam(inferenece_model.parameters(), lr=0.00001)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["features.0.weight\n","features.0.weight\n","features.0.bias\n","features.2.weight\n","features.2.weight\n","features.2.bias\n","features.4.weight\n","features.4.weight\n","features.4.bias\n","labels.0.weight\n","labels.0.weight\n","labels.0.bias\n","labels.2.weight\n","labels.2.weight\n","labels.2.bias\n","combine.0.weight\n","combine.0.weight\n","combine.0.bias\n","combine.2.weight\n","combine.2.weight\n","combine.2.bias\n","combine.4.weight\n","combine.4.weight\n","combine.4.bias\n","combine.6.weight\n","combine.6.weight\n","combine.6.bias\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:72: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"9hCbzfiB49lW","colab_type":"code","outputId":"8859b6a4-9eab-475e-e769-669736d3c639","executionInfo":{"status":"ok","timestamp":1584012947642,"user_tz":-330,"elapsed":15515,"user":{"displayName":"Vasisht Vasisht","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdnsVWWQG2LPrqHSKgFAow9xj3qikoca93I6gg=s64","userId":"18321686459009329525"}},"colab":{"base_uri":"https://localhost:8080/","height":86}},"source":["print('==> Preparing data..')\n","transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","transform_test = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","])\n","\n","\n","classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n","trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=1)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=1)\n","\n","\n","trainset_private = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n","trainloader_private = data.DataLoader(trainset, batch_size=batch_privacy, shuffle=True, num_workers=1)\n","\n","\n","r = np.arange(50000)\n","np.random.shuffle(r)\n","\n","private_trainset_intrain = []\n","private_trainset_intest = []\n","\n","private_testset_intrain =[] \n","private_testset_intest =[] \n","\n","\n","for i in range(25000):\n","    private_trainset_intrain.append(trainset[r[i]])\n","\n","\n","for i in range(25000,50000):\n","    private_testset_intrain.append(trainset[r[i]])\n","\n","    \n","r = np.arange(10000)\n","np.random.shuffle(r)\n","  \n","for i in range(5000):\n","    private_trainset_intest.append(testset[r[i]])\n","\n","\n","for i in range(5000,10000):\n","    private_testset_intest.append(testset[r[i]])\n","\n","\n","private_trainloader_intrain = data.DataLoader(private_trainset_intrain, batch_size=batch_privacy, shuffle=True, num_workers=1)\n","private_trainloader_intest = data.DataLoader(private_trainset_intest, batch_size=batch_privacy, shuffle=True, num_workers=1)\n","\n","\n","private_testloader_intrain = data.DataLoader(private_testset_intrain, batch_size=batch_privacy, shuffle=True, num_workers=1)\n","private_testloader_intest = data.DataLoader(private_testset_intest, batch_size=batch_privacy, shuffle=True, num_workers=1)\n","\n"],"execution_count":33,"outputs":[{"output_type":"stream","text":["==> Preparing data..\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KvR5h0D-6ne-","colab_type":"code","colab":{}},"source":["#privacy_train = train_inference_model\n","def train_inference_model(trainloader, model,inference_model, criterion, optimizer, epoch, use_cuda,num_batchs=1000):\n","    global best_acc\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    mtop1_a = AverageMeter()\n","    mtop5_a = AverageMeter()\n","    \n","    inference_model.train()\n","    model.eval()\n","    # switch to evaluate mode\n","\n","    end = time.time()\n","    first_id = -1\n","    for batch_idx,((tr_input, tr_target) ,(te_input, te_target)) in trainloader:\n","        # measure data loading time\n","        if first_id == -1:\n","            first_id = batch_idx\n","        \n","        data_time.update(time.time() - end)\n","        tr_input = tr_input.cuda()\n","        te_input = te_input.cuda()\n","        tr_target = tr_target.cuda()\n","        te_target = te_target.cuda()\n","        \n","        \n","        v_tr_input = torch.autograd.Variable(tr_input)\n","        v_te_input = torch.autograd.Variable(te_input)\n","        v_tr_target = torch.autograd.Variable(tr_target)\n","        v_te_target = torch.autograd.Variable(te_target)\n","        \n","        # compute output\n","        model_input =torch.cat((v_tr_input,v_te_input))\n","        \n","        pred_outputs = model(model_input)\n","        \n","        infer_input= torch.cat((v_tr_target,v_te_target))\n","        \n","        mtop1, mtop5 =accuracy(pred_outputs.data, infer_input.data, topk=(1, 5))\n","        \n","        mtop1_a.update(mtop1.item(), model_input.size(0))\n","        mtop5_a.update(mtop5.item(), model_input.size(0))\n","\n","        \n","        \n","        one_hot_tr = torch.from_numpy((np.zeros((infer_input.size(0),10))-1)).cuda().type(torch.cuda.FloatTensor)\n","        target_one_hot_tr = one_hot_tr.scatter_(1, infer_input.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n","\n","        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n","        \n","\n","        attack_model_input = pred_outputs#torch.cat((pred_outputs,infer_input_one_hot),1)\n","        member_output = inference_model(attack_model_input,infer_input_one_hot)\n","        \n","        \n","        \n","        is_member_labels = torch.from_numpy(np.reshape(np.concatenate((np.zeros(v_tr_input.size(0)),np.ones(v_te_input.size(0)))),[-1,1])).cuda()\n","        \n","        v_is_member_labels = torch.autograd.Variable(is_member_labels).type(torch.cuda.FloatTensor)\n","\n","        loss = criterion(member_output, v_is_member_labels)\n","\n","        # measure accuracy and record loss\n","        prec1=np.mean((member_output.data.cpu().numpy() >0.5)==v_is_member_labels.data.cpu().numpy())\n","        losses.update(loss.item(), model_input.size(0))\n","        top1.update(prec1, model_input.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","        if batch_idx-first_id > num_batchs:\n","            break\n","\n","        # plot progress\n","        if batch_idx%100==0:\n","            print  ('({batch}/{size}) | Loss: {loss:.4f} | '.format(\n","                    batch=batch_idx ,\n","                    size=500,\n","                    loss=losses.avg,\n","                    ))\n","\n","    return (losses.avg, top1.avg)\n","\n","#train_privatly=train_model_advreg\n","def train_model_advreg(trainloader, model,inference_model, criterion, optimizer, epoch, use_cuda,num_batchs=10000,alpha=0.1):\n","    # switch to train mode\n","    model.train()\n","    inference_model.eval()\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","    end = time.time()\n","    first_id = -1\n","    for batch_idx, (inputs, targets) in (trainloader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","        if first_id == -1:\n","            first_id = batch_idx\n","        \n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda(async=True)\n","        inputs, targets = torch.autograd.Variable(inputs), torch.autograd.Variable(targets)\n","\n","        # compute output\n","        outputs = model(inputs)\n","        \n","        \n","        one_hot_tr = torch.from_numpy((np.zeros((outputs.size(0),10))-1)).cuda().type(torch.cuda.FloatTensor)\n","        target_one_hot_tr = one_hot_tr.scatter_(1, targets.type(torch.cuda.LongTensor).view([-1,1]).data,1)\n","\n","        infer_input_one_hot = torch.autograd.Variable(target_one_hot_tr)\n","        \n","        inference_output = inference_model ( outputs,infer_input_one_hot)\n","        #print (inference_output.mean())\n","        \n","\n","        loss = criterion(outputs, targets) + (alpha)*(((inference_output-1.0).pow(2).mean()))\n","\n","        # measure accuracy and record loss\n","        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n","        losses.update(loss.item(), inputs.size(0))\n","        top1.update(prec1.item(), inputs.size(0))\n","        top5.update(prec5.item(), inputs.size(0))\n","\n","        # compute gradient and do SGD step\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","        # plot progress\n","        if batch_idx%100==0:\n","            print  ('({batch}/{size}) | Loss: {loss:.4f} |'.format(\n","                    batch=batch_idx + 1,\n","                    size=500,\n","                    loss=losses.avg,\n","                    ))\n","        if batch_idx-first_id >= num_batchs:\n","            break\n","\n","    return (losses.avg, top1.avg)\n","\n","\n","def test(testloader, model, criterion, epoch, use_cuda):\n","    global best_acc\n","    batch_time = AverageMeter()\n","    data_time = AverageMeter()\n","    losses = AverageMeter()\n","    top1 = AverageMeter()\n","    top5 = AverageMeter()\n","\n","    # switch to evaluate mode\n","    model.eval()\n","\n","    end = time.time()\n","    for batch_idx, (inputs, targets) in enumerate(testloader):\n","        # measure data loading time\n","        data_time.update(time.time() - end)\n","\n","        if use_cuda:\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","        inputs, targets = torch.autograd.Variable(inputs, volatile=True), torch.autograd.Variable(targets)\n","\n","        # compute output\n","        outputs = model(inputs)\n","        loss = criterion(outputs, targets)\n","\n","        # measure accuracy and record loss\n","        prec1, prec5 = accuracy(outputs.data, targets.data, topk=(1, 5))\n","        losses.update(loss.item(), inputs.size(0))\n","        top1.update(prec1.item(), inputs.size(0))\n","        top5.update(prec5.item(), inputs.size(0))\n","\n","        # measure elapsed time\n","        batch_time.update(time.time() - end)\n","        end = time.time()\n","\n","    return (losses.avg, top1.avg)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TNMVIcCl5FVB","colab_type":"code","outputId":"f22b310c-94e2-4b8a-da15-d4db99f4336f","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1584016618764,"user_tz":-330,"elapsed":889301,"user":{"displayName":"Vasisht Vasisht","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdnsVWWQG2LPrqHSKgFAow9xj3qikoca93I6gg=s64","userId":"18321686459009329525"}}},"source":["epochs=200\n","\n","for epoch in range(0, epochs):\n","\n","    print('\\nEpoch: [%d | %d]' % (epoch + 1, epochs))\n","\n","    train_enum = enumerate(trainloader)\n","    train_private_enum = enumerate(zip(trainloader_private,testloader))\n","    for i in range(500//2):\n","        \n","        if epoch>3:\n","            privacy_loss, privacy_acc = train_inference_model(train_private_enum,model,inferenece_model,criterion_attack,optimizer_mem,epoch,use_cuda,1)\n","            train_loss, train_acc = train_model_advreg(train_enum, model,inferenece_model, criterion, optimizer, epoch, use_cuda,1,1)\n","            \n","            if i%100 ==0:\n","                print('Privacy Accuracy',privacy_acc)\n","                print('Training Accuracy',train_acc)\n","            if  (i+1)%50 ==0:\n","                train_private_enum = enumerate(zip(trainloader_private,testloader))\n","        else:\n","            train_loss, train_acc = train_model_advreg(train_enum, model,inferenece_model, criterion, optimizer, epoch, use_cuda,1000,0)\n","            break\n","        \n","        \n","    test_loss, test_acc = test(testloader, model, criterion, epoch, use_cuda)\n","    train_loss, train_acc = test(trainloader, model, criterion, epoch, use_cuda)\n","    print ('Train Accuracy',train_acc)\n","    print ('Test Accuracy',test_acc)"],"execution_count":35,"outputs":[{"output_type":"stream","text":["\n","Epoch: [1 | 200]\n","(1/500) | Loss: 2.3053 |\n","(101/500) | Loss: 2.2157 |\n","(201/500) | Loss: 2.1192 |\n","(301/500) | Loss: 2.0549 |\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:173: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["Train Accuracy 30.824\n","Test Accuracy 30.01\n","\n","Epoch: [2 | 200]\n","(1/500) | Loss: 2.0152 |\n","(101/500) | Loss: 1.7980 |\n","(201/500) | Loss: 1.7633 |\n","(301/500) | Loss: 1.7333 |\n","Train Accuracy 42.858\n","Test Accuracy 43.78\n","\n","Epoch: [3 | 200]\n","(1/500) | Loss: 1.6996 |\n","(101/500) | Loss: 1.5907 |\n","(201/500) | Loss: 1.5748 |\n","(301/500) | Loss: 1.5533 |\n","Train Accuracy 49.806\n","Test Accuracy 48.84\n","\n","Epoch: [4 | 200]\n","(1/500) | Loss: 1.3952 |\n","(101/500) | Loss: 1.4711 |\n","(201/500) | Loss: 1.4475 |\n","(301/500) | Loss: 1.4272 |\n","Train Accuracy 54.172\n","Test Accuracy 52.85\n","\n","Epoch: [5 | 200]\n","(0/500) | Loss: 0.2500 | \n","(1/500) | Loss: 1.6710 |\n","Privacy Accuracy 0.5033333333333333\n","Training Accuracy 50.0\n","(0/500) | Loss: 0.2500 | \n","(101/500) | Loss: 1.5854 |\n","(0/500) | Loss: 0.2500 | \n","(201/500) | Loss: 1.2952 |\n","Privacy Accuracy 0.5466666666666666\n","Training Accuracy 59.375\n","(0/500) | Loss: 0.2500 | \n","(301/500) | Loss: 1.4706 |\n","(0/500) | Loss: 0.2499 | \n","Privacy Accuracy 0.6\n","Training Accuracy 0\n","Train Accuracy 62.16\n","Test Accuracy 61.72\n","\n","Epoch: [6 | 200]\n","(0/500) | Loss: 0.2495 | \n","(1/500) | Loss: 1.4373 |\n","Privacy Accuracy 0.5283333333333333\n","Training Accuracy 61.328125\n","(0/500) | Loss: 0.2479 | \n","(101/500) | Loss: 1.2301 |\n","(0/500) | Loss: 0.2465 | \n","(201/500) | Loss: 1.3467 |\n","Privacy Accuracy 0.5333333333333333\n","Training Accuracy 56.640625\n","(0/500) | Loss: 0.2444 | \n","(301/500) | Loss: 1.2975 |\n","(0/500) | Loss: 0.2429 | \n","Privacy Accuracy 0.5516666666666666\n","Training Accuracy 0\n","Train Accuracy 63.862\n","Test Accuracy 61.93\n","\n","Epoch: [7 | 200]\n","(0/500) | Loss: 0.2409 | \n","(1/500) | Loss: 1.1597 |\n","Privacy Accuracy 0.6083333333333333\n","Training Accuracy 63.28125\n","(0/500) | Loss: 0.2460 | \n","(101/500) | Loss: 1.3882 |\n","(0/500) | Loss: 0.2442 | \n","(201/500) | Loss: 1.4892 |\n","Privacy Accuracy 0.6083333333333333\n","Training Accuracy 59.765625\n","(0/500) | Loss: 0.2339 | \n","(301/500) | Loss: 1.2774 |\n","(0/500) | Loss: 0.2295 | \n","Privacy Accuracy 0.63\n","Training Accuracy 0\n","Train Accuracy 61.018\n","Test Accuracy 60.21\n","\n","Epoch: [8 | 200]\n","(0/500) | Loss: 0.2229 | \n","(1/500) | Loss: 1.7781 |\n","Privacy Accuracy 0.6416666666666667\n","Training Accuracy 56.640625\n","(0/500) | Loss: 0.2269 | \n","(101/500) | Loss: 1.3328 |\n","(0/500) | Loss: 0.2430 | \n","(201/500) | Loss: 1.5528 |\n","Privacy Accuracy 0.5833333333333334\n","Training Accuracy 62.890625\n","(0/500) | Loss: 0.2331 | \n","(301/500) | Loss: 1.4006 |\n","(0/500) | Loss: 0.2359 | \n","Privacy Accuracy 0.5733333333333334\n","Training Accuracy 0\n","Train Accuracy 64.976\n","Test Accuracy 64.82\n","\n","Epoch: [9 | 200]\n","(0/500) | Loss: 0.2318 | \n","(1/500) | Loss: 1.3870 |\n","Privacy Accuracy 0.61\n","Training Accuracy 59.375\n","(0/500) | Loss: 0.2335 | \n","(101/500) | Loss: 1.5188 |\n","(0/500) | Loss: 0.2345 | \n","(201/500) | Loss: 1.6558 |\n","Privacy Accuracy 0.555\n","Training Accuracy 57.8125\n","(0/500) | Loss: 0.2246 | \n","(301/500) | Loss: 1.1766 |\n","(0/500) | Loss: 0.2240 | \n","Privacy Accuracy 0.6516666666666666\n","Training Accuracy 0\n","Train Accuracy 67.004\n","Test Accuracy 65.58\n","\n","Epoch: [10 | 200]\n","(0/500) | Loss: 0.2230 | \n","(1/500) | Loss: 1.0602 |\n","Privacy Accuracy 0.6266666666666667\n","Training Accuracy 67.96875\n","(0/500) | Loss: 0.2258 | \n","(101/500) | Loss: 1.3538 |\n","(0/500) | Loss: 0.2225 | \n","(201/500) | Loss: 1.2605 |\n","Privacy Accuracy 0.6766666666666666\n","Training Accuracy 64.0625\n","(0/500) | Loss: 0.2344 | \n","(301/500) | Loss: 1.5000 |\n","(0/500) | Loss: 0.2642 | \n","Privacy Accuracy 0.5283333333333333\n","Training Accuracy 0\n","Train Accuracy 66.758\n","Test Accuracy 65.29\n","\n","Epoch: [11 | 200]\n","(0/500) | Loss: 0.2200 | \n","(1/500) | Loss: 1.2193 |\n","Privacy Accuracy 0.6366666666666667\n","Training Accuracy 59.765625\n","(0/500) | Loss: 0.2272 | \n","(101/500) | Loss: 1.3175 |\n","(0/500) | Loss: 0.2183 | \n","(201/500) | Loss: 1.2439 |\n","Privacy Accuracy 0.665\n","Training Accuracy 70.3125\n","(0/500) | Loss: 0.2350 | \n","(301/500) | Loss: 1.7402 |\n","(0/500) | Loss: 0.2492 | \n","Privacy Accuracy 0.5633333333333334\n","Training Accuracy 0\n","Train Accuracy 65.822\n","Test Accuracy 64.66\n","\n","Epoch: [12 | 200]\n","(0/500) | Loss: 0.2172 | \n","(1/500) | Loss: 1.4678 |\n","Privacy Accuracy 0.655\n","Training Accuracy 64.84375\n","(0/500) | Loss: 0.2221 | \n","(101/500) | Loss: 1.6858 |\n","(0/500) | Loss: 0.2352 | \n","(201/500) | Loss: 1.4518 |\n","Privacy Accuracy 0.5933333333333334\n","Training Accuracy 67.578125\n","(0/500) | Loss: 0.2286 | \n","(301/500) | Loss: 1.3033 |\n","(0/500) | Loss: 0.2257 | \n","Privacy Accuracy 0.635\n","Training Accuracy 0\n","Train Accuracy 63.716\n","Test Accuracy 62.61\n","\n","Epoch: [13 | 200]\n","(0/500) | Loss: 0.2087 | \n","(1/500) | Loss: 1.6320 |\n","Privacy Accuracy 0.655\n","Training Accuracy 62.109375\n","(0/500) | Loss: 0.2255 | \n","(101/500) | Loss: 1.4912 |\n","(0/500) | Loss: 0.2347 | \n","(201/500) | Loss: 1.4217 |\n","Privacy Accuracy 0.5783333333333334\n","Training Accuracy 62.109375\n","(0/500) | Loss: 0.2254 | \n","(301/500) | Loss: 1.4540 |\n","(0/500) | Loss: 0.2241 | \n","Privacy Accuracy 0.67\n","Training Accuracy 0\n","Train Accuracy 66.178\n","Test Accuracy 63.97\n","\n","Epoch: [14 | 200]\n","(0/500) | Loss: 0.2172 | \n","(1/500) | Loss: 1.3888 |\n","Privacy Accuracy 0.6483333333333333\n","Training Accuracy 66.40625\n","(0/500) | Loss: 0.2187 | \n","(101/500) | Loss: 1.0710 |\n","(0/500) | Loss: 0.2447 | \n","(201/500) | Loss: 1.2710 |\n","Privacy Accuracy 0.5883333333333334\n","Training Accuracy 71.09375\n","(0/500) | Loss: 0.2260 | \n","(301/500) | Loss: 1.4787 |\n","(0/500) | Loss: 0.2465 | \n","Privacy Accuracy 0.5816666666666667\n","Training Accuracy 0\n","Train Accuracy 65.666\n","Test Accuracy 64.01\n","\n","Epoch: [15 | 200]\n","(0/500) | Loss: 0.2308 | \n","(1/500) | Loss: 1.9775 |\n","Privacy Accuracy 0.6233333333333333\n","Training Accuracy 64.0625\n","(0/500) | Loss: 0.2569 | \n","(101/500) | Loss: 1.7169 |\n","(0/500) | Loss: 0.2363 | \n","(201/500) | Loss: 1.4944 |\n","Privacy Accuracy 0.5983333333333334\n","Training Accuracy 68.75\n","(0/500) | Loss: 0.2595 | \n","(301/500) | Loss: 1.6381 |\n","(0/500) | Loss: 0.2196 | \n","Privacy Accuracy 0.6066666666666667\n","Training Accuracy 0\n","Train Accuracy 64.812\n","Test Accuracy 61.89\n","\n","Epoch: [16 | 200]\n","(0/500) | Loss: 0.2199 | \n","(1/500) | Loss: 1.5959 |\n","Privacy Accuracy 0.6333333333333333\n","Training Accuracy 62.109375\n","(0/500) | Loss: 0.2725 | \n","(101/500) | Loss: 1.3158 |\n","(0/500) | Loss: 0.2278 | \n","(201/500) | Loss: 1.5744 |\n","Privacy Accuracy 0.6133333333333333\n","Training Accuracy 66.40625\n","(0/500) | Loss: 0.2449 | \n","(301/500) | Loss: 1.7114 |\n","(0/500) | Loss: 0.2839 | \n","Privacy Accuracy 0.6\n","Training Accuracy 0\n","Train Accuracy 69.144\n","Test Accuracy 68.5\n","\n","Epoch: [17 | 200]\n","(0/500) | Loss: 0.2286 | \n","(1/500) | Loss: 1.2885 |\n","Privacy Accuracy 0.5983333333333334\n","Training Accuracy 69.921875\n","(0/500) | Loss: 0.2471 | \n","(101/500) | Loss: 1.1648 |\n","(0/500) | Loss: 0.2516 | \n","(201/500) | Loss: 1.3730 |\n","Privacy Accuracy 0.5816666666666667\n","Training Accuracy 63.671875\n","(0/500) | Loss: 0.2231 | \n","(301/500) | Loss: 1.1915 |\n","(0/500) | Loss: 0.2506 | \n","Privacy Accuracy 0.5966666666666667\n","Training Accuracy 0\n","Train Accuracy 68.034\n","Test Accuracy 66.12\n","\n","Epoch: [18 | 200]\n","(0/500) | Loss: 0.2288 | \n","(1/500) | Loss: 1.5204 |\n","Privacy Accuracy 0.62\n","Training Accuracy 66.40625\n","(0/500) | Loss: 0.2671 | \n","(101/500) | Loss: 1.7326 |\n","(0/500) | Loss: 0.2233 | \n","(201/500) | Loss: 2.2900 |\n","Privacy Accuracy 0.66\n","Training Accuracy 60.9375\n","(0/500) | Loss: 0.2314 | \n","(301/500) | Loss: 1.2578 |\n","(0/500) | Loss: 0.2127 | \n","Privacy Accuracy 0.6516666666666666\n","Training Accuracy 0\n","Train Accuracy 71.172\n","Test Accuracy 70.06\n","\n","Epoch: [19 | 200]\n","(0/500) | Loss: 0.2113 | \n","(1/500) | Loss: 1.3447 |\n","Privacy Accuracy 0.6416666666666667\n","Training Accuracy 69.140625\n","(0/500) | Loss: 0.2365 | \n","(101/500) | Loss: 1.4324 |\n","(0/500) | Loss: 0.2059 | \n","(201/500) | Loss: 1.7076 |\n","Privacy Accuracy 0.6766666666666666\n","Training Accuracy 67.96875\n","(0/500) | Loss: 0.2527 | \n","(301/500) | Loss: 1.5846 |\n","(0/500) | Loss: 0.2448 | \n","Privacy Accuracy 0.6133333333333333\n","Training Accuracy 0\n","Train Accuracy 75.582\n","Test Accuracy 73.32\n","\n","Epoch: [20 | 200]\n","(0/500) | Loss: 0.2376 | \n","(1/500) | Loss: 1.3974 |\n","Privacy Accuracy 0.6166666666666667\n","Training Accuracy 67.578125\n","(0/500) | Loss: 0.2416 | \n","(101/500) | Loss: 1.3107 |\n","(0/500) | Loss: 0.2288 | \n","(201/500) | Loss: 1.6667 |\n","Privacy Accuracy 0.6066666666666667\n","Training Accuracy 63.671875\n","(0/500) | Loss: 0.2437 | \n","(301/500) | Loss: 1.9284 |\n","(0/500) | Loss: 0.2674 | \n","Privacy Accuracy 0.5816666666666667\n","Training Accuracy 0\n","Train Accuracy 75.678\n","Test Accuracy 73.7\n","\n","Epoch: [21 | 200]\n","(0/500) | Loss: 0.2249 | \n","(1/500) | Loss: 1.1252 |\n","Privacy Accuracy 0.645\n","Training Accuracy 69.53125\n","(0/500) | Loss: 0.2295 | \n","(101/500) | Loss: 1.6520 |\n","(0/500) | Loss: 0.2349 | \n","(201/500) | Loss: 1.5169 |\n","Privacy Accuracy 0.605\n","Training Accuracy 72.265625\n","(0/500) | Loss: 0.2476 | \n","(301/500) | Loss: 1.0450 |\n","(0/500) | Loss: 0.2338 | \n","Privacy Accuracy 0.62\n","Training Accuracy 0\n","Train Accuracy 72.012\n","Test Accuracy 69.46\n","\n","Epoch: [22 | 200]\n","(0/500) | Loss: 0.2303 | \n","(1/500) | Loss: 1.6383 |\n","Privacy Accuracy 0.6416666666666667\n","Training Accuracy 67.578125\n","(0/500) | Loss: 0.2621 | \n","(101/500) | Loss: 0.9692 |\n","(0/500) | Loss: 0.2223 | \n","(201/500) | Loss: 1.4793 |\n","Privacy Accuracy 0.6383333333333333\n","Training Accuracy 69.53125\n","(0/500) | Loss: 0.2648 | \n","(301/500) | Loss: 1.5292 |\n","(0/500) | Loss: 0.2745 | \n","Privacy Accuracy 0.61\n","Training Accuracy 0\n","Train Accuracy 69.522\n","Test Accuracy 66.63\n","\n","Epoch: [23 | 200]\n","(0/500) | Loss: 0.2170 | \n","(1/500) | Loss: 1.3055 |\n","Privacy Accuracy 0.6566666666666666\n","Training Accuracy 69.53125\n","(0/500) | Loss: 0.2343 | \n","(101/500) | Loss: 1.0781 |\n","(0/500) | Loss: 0.2480 | \n","(201/500) | Loss: 1.5413 |\n","Privacy Accuracy 0.62\n","Training Accuracy 69.140625\n","(0/500) | Loss: 0.2412 | \n","(301/500) | Loss: 1.5362 |\n","(0/500) | Loss: 0.2348 | \n","Privacy Accuracy 0.63\n","Training Accuracy 0\n","Train Accuracy 68.696\n","Test Accuracy 66.88\n","\n","Epoch: [24 | 200]\n","(0/500) | Loss: 0.2149 | \n","(1/500) | Loss: 1.3407 |\n","Privacy Accuracy 0.6666666666666666\n","Training Accuracy 69.140625\n","(0/500) | Loss: 0.2357 | \n","(101/500) | Loss: 1.3660 |\n","(0/500) | Loss: 0.2567 | \n","(201/500) | Loss: 1.4127 |\n","Privacy Accuracy 0.61\n","Training Accuracy 73.046875\n","(0/500) | Loss: 0.2098 | \n","(301/500) | Loss: 1.3077 |\n","(0/500) | Loss: 0.2299 | \n","Privacy Accuracy 0.6383333333333333\n","Training Accuracy 0\n","Train Accuracy 73.98\n","Test Accuracy 70.52\n","\n","Epoch: [25 | 200]\n","(0/500) | Loss: 0.2283 | \n","(1/500) | Loss: 1.1823 |\n","Privacy Accuracy 0.6166666666666667\n","Training Accuracy 73.828125\n","(0/500) | Loss: 0.2875 | \n","(101/500) | Loss: 1.2216 |\n","(0/500) | Loss: 0.2365 | \n","(201/500) | Loss: 1.1858 |\n","Privacy Accuracy 0.63\n","Training Accuracy 74.609375\n","(0/500) | Loss: 0.2216 | \n","(301/500) | Loss: 1.7416 |\n","(0/500) | Loss: 0.2149 | \n","Privacy Accuracy 0.675\n","Training Accuracy 0\n","Train Accuracy 70.446\n","Test Accuracy 68.58\n","\n","Epoch: [26 | 200]\n","(0/500) | Loss: 0.2226 | \n","(1/500) | Loss: 1.2092 |\n","Privacy Accuracy 0.6316666666666667\n","Training Accuracy 73.046875\n","(0/500) | Loss: 0.3229 | \n","(101/500) | Loss: 0.6475 |\n","(0/500) | Loss: 0.2243 | \n","(201/500) | Loss: 1.2442 |\n","Privacy Accuracy 0.6516666666666666\n","Training Accuracy 71.484375\n","(0/500) | Loss: 0.2929 | \n","(301/500) | Loss: 1.2358 |\n","(0/500) | Loss: 0.2084 | \n","Privacy Accuracy 0.6283333333333333\n","Training Accuracy 0\n","Train Accuracy 73.032\n","Test Accuracy 71.09\n","\n","Epoch: [27 | 200]\n","(0/500) | Loss: 0.2228 | \n","(1/500) | Loss: 1.2767 |\n","Privacy Accuracy 0.61\n","Training Accuracy 72.265625\n","(0/500) | Loss: 0.2245 | \n","(101/500) | Loss: 1.2842 |\n","(0/500) | Loss: 0.2412 | \n","(201/500) | Loss: 1.3271 |\n","Privacy Accuracy 0.6183333333333333\n","Training Accuracy 76.953125\n","(0/500) | Loss: 0.2262 | \n","(301/500) | Loss: 1.0500 |\n","(0/500) | Loss: 0.2522 | \n","Privacy Accuracy 0.5866666666666667\n","Training Accuracy 0\n","Train Accuracy 77.236\n","Test Accuracy 75.0\n","\n","Epoch: [28 | 200]\n","(0/500) | Loss: 0.2208 | \n","(1/500) | Loss: 0.9432 |\n","Privacy Accuracy 0.5933333333333334\n","Training Accuracy 73.046875\n","(0/500) | Loss: 0.2379 | \n","(101/500) | Loss: 1.3226 |\n","(0/500) | Loss: 0.2304 | \n","(201/500) | Loss: 1.3960 |\n","Privacy Accuracy 0.6333333333333333\n","Training Accuracy 77.734375\n","(0/500) | Loss: 0.2557 | \n","(301/500) | Loss: 1.1480 |\n","(0/500) | Loss: 0.2374 | \n","Privacy Accuracy 0.58\n","Training Accuracy 0\n","Train Accuracy 77.806\n","Test Accuracy 75.14\n","\n","Epoch: [29 | 200]\n","(0/500) | Loss: 0.2360 | \n","(1/500) | Loss: 1.1475 |\n","Privacy Accuracy 0.5916666666666667\n","Training Accuracy 72.265625\n","(0/500) | Loss: 0.2443 | \n","(101/500) | Loss: 1.0829 |\n","(0/500) | Loss: 0.2377 | \n","(201/500) | Loss: 1.3644 |\n","Privacy Accuracy 0.6283333333333333\n","Training Accuracy 71.875\n","(0/500) | Loss: 0.2414 | \n","(301/500) | Loss: 1.4310 |\n","(0/500) | Loss: 0.2285 | \n","Privacy Accuracy 0.6333333333333333\n","Training Accuracy 0\n","Train Accuracy 80.08\n","Test Accuracy 77.68\n","\n","Epoch: [30 | 200]\n","(0/500) | Loss: 0.2196 | \n","(1/500) | Loss: 0.9808 |\n","Privacy Accuracy 0.6583333333333333\n","Training Accuracy 76.171875\n","(0/500) | Loss: 0.2494 | \n","(101/500) | Loss: 1.5773 |\n","(0/500) | Loss: 0.2219 | \n","(201/500) | Loss: 1.3898 |\n","Privacy Accuracy 0.62\n","Training Accuracy 68.359375\n","(0/500) | Loss: 0.2176 | \n","(301/500) | Loss: 1.5104 |\n","(0/500) | Loss: 0.2426 | \n","Privacy Accuracy 0.5816666666666667\n","Training Accuracy 0\n","Train Accuracy 74.812\n","Test Accuracy 72.32\n","\n","Epoch: [31 | 200]\n","(0/500) | Loss: 0.2227 | \n","(1/500) | Loss: 1.0905 |\n","Privacy Accuracy 0.6283333333333333\n","Training Accuracy 74.21875\n","(0/500) | Loss: 0.2478 | \n","(101/500) | Loss: 1.5609 |\n","(0/500) | Loss: 0.2308 | \n","(201/500) | Loss: 1.4905 |\n","Privacy Accuracy 0.63\n","Training Accuracy 70.703125\n","(0/500) | Loss: 0.3106 | \n","(301/500) | Loss: 1.1628 |\n","(0/500) | Loss: 0.2456 | \n","Privacy Accuracy 0.5833333333333334\n","Training Accuracy 0\n","Train Accuracy 71.71\n","Test Accuracy 68.44\n","\n","Epoch: [32 | 200]\n","(0/500) | Loss: 0.2308 | \n","(1/500) | Loss: 1.1489 |\n","Privacy Accuracy 0.6016666666666667\n","Training Accuracy 72.65625\n","(0/500) | Loss: 0.2307 | \n","(101/500) | Loss: 1.4557 |\n","(0/500) | Loss: 0.2221 | \n","(201/500) | Loss: 0.8901 |\n","Privacy Accuracy 0.6033333333333334\n","Training Accuracy 79.6875\n","(0/500) | Loss: 0.2520 | \n","(301/500) | Loss: 1.4309 |\n","(0/500) | Loss: 0.2512 | \n","Privacy Accuracy 0.5733333333333334\n","Training Accuracy 0\n","Train Accuracy 73.42\n","Test Accuracy 71.11\n","\n","Epoch: [33 | 200]\n","(0/500) | Loss: 0.2258 | \n","(1/500) | Loss: 1.2648 |\n","Privacy Accuracy 0.6483333333333333\n","Training Accuracy 73.828125\n","(0/500) | Loss: 0.2386 | \n","(101/500) | Loss: 1.3993 |\n","(0/500) | Loss: 0.3022 | \n","(201/500) | Loss: 1.0583 |\n","Privacy Accuracy 0.5533333333333333\n","Training Accuracy 76.171875\n","(0/500) | Loss: 0.2394 | \n","(301/500) | Loss: 1.1067 |\n","(0/500) | Loss: 0.2365 | \n","Privacy Accuracy 0.6\n","Training Accuracy 0\n","Train Accuracy 78.83\n","Test Accuracy 75.5\n","\n","Epoch: [34 | 200]\n","(0/500) | Loss: 0.2194 | \n","(1/500) | Loss: 1.6181 |\n","Privacy Accuracy 0.64\n","Training Accuracy 71.484375\n","(0/500) | Loss: 0.2254 | \n","(101/500) | Loss: 0.9665 |\n","(0/500) | Loss: 0.2220 | \n","(201/500) | Loss: 0.8334 |\n","Privacy Accuracy 0.625\n","Training Accuracy 76.5625\n","(0/500) | Loss: 0.2409 | \n","(301/500) | Loss: 1.0833 |\n","(0/500) | Loss: 0.2468 | \n","Privacy Accuracy 0.5833333333333334\n","Training Accuracy 0\n","Train Accuracy 75.152\n","Test Accuracy 72.56\n","\n","Epoch: [35 | 200]\n","(0/500) | Loss: 0.2211 | \n","(1/500) | Loss: 1.3216 |\n","Privacy Accuracy 0.6433333333333333\n","Training Accuracy 71.484375\n","(0/500) | Loss: 0.2353 | \n","(101/500) | Loss: 1.2315 |\n","(0/500) | Loss: 0.2394 | \n","(201/500) | Loss: 1.1147 |\n","Privacy Accuracy 0.5716666666666667\n","Training Accuracy 76.953125\n","(0/500) | Loss: 0.2442 | \n","(301/500) | Loss: 1.0604 |\n","(0/500) | Loss: 0.3105 | \n","Privacy Accuracy 0.53\n","Training Accuracy 0\n","Train Accuracy 81.032\n","Test Accuracy 77.6\n","\n","Epoch: [36 | 200]\n","(0/500) | Loss: 0.2192 | \n","(1/500) | Loss: 0.7717 |\n","Privacy Accuracy 0.6116666666666667\n","Training Accuracy 75.78125\n","(0/500) | Loss: 0.2356 | \n","(101/500) | Loss: 0.8755 |\n","(0/500) | Loss: 0.2379 | \n","(201/500) | Loss: 1.3790 |\n","Privacy Accuracy 0.5983333333333334\n","Training Accuracy 75.390625\n","(0/500) | Loss: 0.2317 | \n","(301/500) | Loss: 1.1267 |\n","(0/500) | Loss: 0.2349 | \n","Privacy Accuracy 0.6266666666666667\n","Training Accuracy 0\n","Train Accuracy 75.894\n","Test Accuracy 73.7\n","\n","Epoch: [37 | 200]\n","(0/500) | Loss: 0.2413 | \n","(1/500) | Loss: 1.1307 |\n","Privacy Accuracy 0.6083333333333333\n","Training Accuracy 76.171875\n","(0/500) | Loss: 0.2555 | \n","(101/500) | Loss: 1.1616 |\n","(0/500) | Loss: 0.2419 | \n","(201/500) | Loss: 1.2112 |\n","Privacy Accuracy 0.57\n","Training Accuracy 75.78125\n","(0/500) | Loss: 0.2412 | \n","(301/500) | Loss: 1.7936 |\n","(0/500) | Loss: 0.2361 | \n","Privacy Accuracy 0.62\n","Training Accuracy 0\n","Train Accuracy 75.844\n","Test Accuracy 72.8\n","\n","Epoch: [38 | 200]\n","(0/500) | Loss: 0.2328 | \n","(1/500) | Loss: 1.2263 |\n","Privacy Accuracy 0.6266666666666667\n","Training Accuracy 75.0\n","(0/500) | Loss: 0.2497 | \n","(101/500) | Loss: 1.0028 |\n","(0/500) | Loss: 0.2357 | \n","(201/500) | Loss: 0.9061 |\n","Privacy Accuracy 0.595\n","Training Accuracy 76.5625\n","(0/500) | Loss: 0.2308 | \n","(301/500) | Loss: 1.0755 |\n","(0/500) | Loss: 0.2572 | \n","Privacy Accuracy 0.6116666666666667\n","Training Accuracy 0\n","Train Accuracy 77.828\n","Test Accuracy 75.5\n","\n","Epoch: [39 | 200]\n","(0/500) | Loss: 0.2311 | \n","(1/500) | Loss: 1.3430 |\n","Privacy Accuracy 0.6166666666666667\n","Training Accuracy 70.703125\n","(0/500) | Loss: 0.2430 | \n","(101/500) | Loss: 1.7413 |\n","(0/500) | Loss: 0.2474 | \n","(201/500) | Loss: 1.0498 |\n","Privacy Accuracy 0.6066666666666667\n","Training Accuracy 76.5625\n","(0/500) | Loss: 0.2454 | \n","(301/500) | Loss: 1.6144 |\n","(0/500) | Loss: 0.2317 | \n","Privacy Accuracy 0.5766666666666667\n","Training Accuracy 0\n","Train Accuracy 77.458\n","Test Accuracy 73.97\n","\n","Epoch: [40 | 200]\n","(0/500) | Loss: 0.2511 | \n","(1/500) | Loss: 1.0395 |\n","Privacy Accuracy 0.595\n","Training Accuracy 74.609375\n","(0/500) | Loss: 0.2287 | \n","(101/500) | Loss: 1.3829 |\n","(0/500) | Loss: 0.2221 | \n","(201/500) | Loss: 1.4584 |\n","Privacy Accuracy 0.5966666666666667\n","Training Accuracy 71.484375\n","(0/500) | Loss: 0.2359 | \n","(301/500) | Loss: 1.4255 |\n","(0/500) | Loss: 0.2397 | \n","Privacy Accuracy 0.6\n","Training Accuracy 0\n","Train Accuracy 80.862\n","Test Accuracy 77.11\n","\n","Epoch: [41 | 200]\n","(0/500) | Loss: 0.2314 | \n","(1/500) | Loss: 0.9807 |\n","Privacy Accuracy 0.6166666666666667\n","Training Accuracy 80.46875\n","(0/500) | Loss: 0.2479 | \n","(101/500) | Loss: 1.0643 |\n","(0/500) | Loss: 0.2444 | \n","(201/500) | Loss: 1.2472 |\n","Privacy Accuracy 0.5983333333333334\n","Training Accuracy 66.40625\n","(0/500) | Loss: 0.2312 | \n","(301/500) | Loss: 0.9066 |\n","(0/500) | Loss: 0.2383 | \n","Privacy Accuracy 0.575\n","Training Accuracy 0\n","Train Accuracy 80.746\n","Test Accuracy 77.66\n","\n","Epoch: [42 | 200]\n","(0/500) | Loss: 0.2247 | \n","(1/500) | Loss: 0.9055 |\n","Privacy Accuracy 0.605\n","Training Accuracy 82.421875\n","(0/500) | Loss: 0.2286 | \n","(101/500) | Loss: 0.9218 |\n","(0/500) | Loss: 0.2190 | \n","(201/500) | Loss: 1.1051 |\n","Privacy Accuracy 0.6416666666666667\n","Training Accuracy 78.125\n","(0/500) | Loss: 0.2503 | \n","(301/500) | Loss: 0.9511 |\n","(0/500) | Loss: 0.2359 | \n","Privacy Accuracy 0.5933333333333334\n","Training Accuracy 0\n","Train Accuracy 77.344\n","Test Accuracy 73.54\n","\n","Epoch: [43 | 200]\n","(0/500) | Loss: 0.2361 | \n","(1/500) | Loss: 1.2517 |\n","Privacy Accuracy 0.585\n","Training Accuracy 71.875\n","(0/500) | Loss: 0.2281 | \n","(101/500) | Loss: 0.9019 |\n","(0/500) | Loss: 0.2508 | \n","(201/500) | Loss: 1.2635 |\n","Privacy Accuracy 0.58\n","Training Accuracy 71.875\n","(0/500) | Loss: 0.2466 | \n","(301/500) | Loss: 1.0170 |\n","(0/500) | Loss: 0.2389 | \n","Privacy Accuracy 0.6216666666666667\n","Training Accuracy 0\n","Train Accuracy 79.396\n","Test Accuracy 75.51\n","\n","Epoch: [44 | 200]\n","(0/500) | Loss: 0.2302 | \n","(1/500) | Loss: 0.8940 |\n","Privacy Accuracy 0.6133333333333333\n","Training Accuracy 76.953125\n","(0/500) | Loss: 0.2522 | \n","(101/500) | Loss: 1.3107 |\n","(0/500) | Loss: 0.2395 | \n","(201/500) | Loss: 1.4627 |\n","Privacy Accuracy 0.565\n","Training Accuracy 73.4375\n","(0/500) | Loss: 0.2434 | \n","(301/500) | Loss: 1.4612 |\n","(0/500) | Loss: 0.2289 | \n","Privacy Accuracy 0.605\n","Training Accuracy 0\n","Train Accuracy 82.634\n","Test Accuracy 78.98\n","\n","Epoch: [45 | 200]\n","(0/500) | Loss: 0.2265 | \n","(1/500) | Loss: 0.8786 |\n","Privacy Accuracy 0.615\n","Training Accuracy 78.515625\n","(0/500) | Loss: 0.2330 | \n","(101/500) | Loss: 1.0436 |\n","(0/500) | Loss: 0.2359 | \n","(201/500) | Loss: 1.0422 |\n","Privacy Accuracy 0.6033333333333334\n","Training Accuracy 82.03125\n","(0/500) | Loss: 0.2487 | \n","(301/500) | Loss: 1.3737 |\n","(0/500) | Loss: 0.2433 | \n","Privacy Accuracy 0.5816666666666667\n","Training Accuracy 0\n","Train Accuracy 79.586\n","Test Accuracy 76.13\n","\n","Epoch: [46 | 200]\n","(0/500) | Loss: 0.2477 | \n","(1/500) | Loss: 1.1361 |\n","Privacy Accuracy 0.57\n","Training Accuracy 81.640625\n","(0/500) | Loss: 0.2322 | \n","(101/500) | Loss: 1.1530 |\n","(0/500) | Loss: 0.2295 | \n","(201/500) | Loss: 0.9705 |\n","Privacy Accuracy 0.615\n","Training Accuracy 74.609375\n","(0/500) | Loss: 0.2372 | \n","(301/500) | Loss: 0.8902 |\n","(0/500) | Loss: 0.2457 | \n","Privacy Accuracy 0.5783333333333334\n","Training Accuracy 0\n","Train Accuracy 81.23\n","Test Accuracy 77.55\n","\n","Epoch: [47 | 200]\n","(0/500) | Loss: 0.2454 | \n","(1/500) | Loss: 1.0585 |\n","Privacy Accuracy 0.58\n","Training Accuracy 79.296875\n","(0/500) | Loss: 0.2404 | \n","(101/500) | Loss: 0.8095 |\n","(0/500) | Loss: 0.2403 | \n","(201/500) | Loss: 0.7583 |\n","Privacy Accuracy 0.5966666666666667\n","Training Accuracy 78.90625\n","(0/500) | Loss: 0.2329 | \n","(301/500) | Loss: 0.8700 |\n","(0/500) | Loss: 0.2447 | \n","Privacy Accuracy 0.5733333333333334\n","Training Accuracy 0\n","Train Accuracy 81.164\n","Test Accuracy 77.14\n","\n","Epoch: [48 | 200]\n","(0/500) | Loss: 0.2380 | \n","(1/500) | Loss: 0.9477 |\n","Privacy Accuracy 0.5766666666666667\n","Training Accuracy 74.609375\n","(0/500) | Loss: 0.2520 | \n","(101/500) | Loss: 0.9083 |\n","(0/500) | Loss: 0.2506 | \n","(201/500) | Loss: 0.9419 |\n","Privacy Accuracy 0.6016666666666667\n","Training Accuracy 80.859375\n","(0/500) | Loss: 0.2435 | \n","(301/500) | Loss: 0.9440 |\n","(0/500) | Loss: 0.2465 | \n","Privacy Accuracy 0.5866666666666667\n","Training Accuracy 0\n","Train Accuracy 80.886\n","Test Accuracy 77.81\n","\n","Epoch: [49 | 200]\n","(0/500) | Loss: 0.2490 | \n","(1/500) | Loss: 1.2811 |\n","Privacy Accuracy 0.5633333333333334\n","Training Accuracy 76.953125\n","(0/500) | Loss: 0.2336 | \n","(101/500) | Loss: 0.8317 |\n","(0/500) | Loss: 0.2218 | \n","(201/500) | Loss: 0.8892 |\n","Privacy Accuracy 0.615\n","Training Accuracy 82.421875\n","(0/500) | Loss: 0.2400 | \n","(301/500) | Loss: 0.8494 |\n","(0/500) | Loss: 0.2346 | \n","Privacy Accuracy 0.5683333333333334\n","Training Accuracy 0\n","Train Accuracy 78.504\n","Test Accuracy 75.33\n","\n","Epoch: [50 | 200]\n","(0/500) | Loss: 0.2350 | \n","(1/500) | Loss: 1.0653 |\n","Privacy Accuracy 0.5816666666666667\n","Training Accuracy 71.09375\n","(0/500) | Loss: 0.2495 | \n","(101/500) | Loss: 0.9660 |\n","(0/500) | Loss: 0.2436 | \n","(201/500) | Loss: 0.9957 |\n","Privacy Accuracy 0.5933333333333334\n","Training Accuracy 78.90625\n","(0/500) | Loss: 0.2500 | \n","(301/500) | Loss: 0.8645 |\n","(0/500) | Loss: 0.2402 | \n","Privacy Accuracy 0.5816666666666667\n","Training Accuracy 0\n","Train Accuracy 84.952\n","Test Accuracy 80.7\n","\n","Epoch: [51 | 200]\n","(0/500) | Loss: 0.2445 | \n","(1/500) | Loss: 0.7506 |\n","Privacy Accuracy 0.5516666666666666\n","Training Accuracy 83.203125\n","(0/500) | Loss: 0.2367 | \n","(101/500) | Loss: 1.0843 |\n","(0/500) | Loss: 0.2702 | \n","(201/500) | Loss: 0.8221 |\n","Privacy Accuracy 0.59\n","Training Accuracy 85.9375\n","(0/500) | Loss: 0.2523 | \n","(301/500) | Loss: 0.9113 |\n","(0/500) | Loss: 0.2393 | \n","Privacy Accuracy 0.58\n","Training Accuracy 0\n","Train Accuracy 77.294\n","Test Accuracy 73.15\n","\n","Epoch: [52 | 200]\n","(0/500) | Loss: 0.2522 | \n","(1/500) | Loss: 1.1951 |\n","Privacy Accuracy 0.5533333333333333\n","Training Accuracy 75.78125\n","(0/500) | Loss: 0.2358 | \n","(101/500) | Loss: 0.9134 |\n","(0/500) | Loss: 0.2335 | \n","(201/500) | Loss: 1.1153 |\n","Privacy Accuracy 0.5966666666666667\n","Training Accuracy 78.515625\n","(0/500) | Loss: 0.2347 | \n","(301/500) | Loss: 0.8294 |\n","(0/500) | Loss: 0.2578 | \n","Privacy Accuracy 0.5883333333333334\n","Training Accuracy 0\n","Train Accuracy 83.562\n","Test Accuracy 79.94\n","\n","Epoch: [53 | 200]\n","(0/500) | Loss: 0.2320 | \n","(1/500) | Loss: 1.1112 |\n","Privacy Accuracy 0.5716666666666665\n","Training Accuracy 81.25\n","(0/500) | Loss: 0.2433 | \n","(101/500) | Loss: 1.2311 |\n","(0/500) | Loss: 0.2362 | \n","(201/500) | Loss: 1.0036 |\n","Privacy Accuracy 0.6016666666666667\n","Training Accuracy 80.46875\n","(0/500) | Loss: 0.2505 | \n","(301/500) | Loss: 1.0204 |\n","(0/500) | Loss: 0.2339 | \n","Privacy Accuracy 0.6016666666666667\n","Training Accuracy 0\n","Train Accuracy 84.726\n","Test Accuracy 81.26\n","\n","Epoch: [54 | 200]\n","(0/500) | Loss: 0.2386 | \n","(1/500) | Loss: 0.6166 |\n","Privacy Accuracy 0.605\n","Training Accuracy 87.5\n","(0/500) | Loss: 0.2358 | \n","(101/500) | Loss: 0.9504 |\n","(0/500) | Loss: 0.2631 | \n","(201/500) | Loss: 0.9155 |\n","Privacy Accuracy 0.55\n","Training Accuracy 78.90625\n","(0/500) | Loss: 0.2607 | \n","(301/500) | Loss: 0.9552 |\n","(0/500) | Loss: 0.2447 | \n","Privacy Accuracy 0.58\n","Training Accuracy 0\n","Train Accuracy 84.122\n","Test Accuracy 80.07\n","\n","Epoch: [55 | 200]\n","(0/500) | Loss: 0.2450 | \n","(1/500) | Loss: 0.8114 |\n","Privacy Accuracy 0.5866666666666667\n","Training Accuracy 83.59375\n","(0/500) | Loss: 0.2419 | \n","(101/500) | Loss: 1.2139 |\n","(0/500) | Loss: 0.2446 | \n","(201/500) | Loss: 0.8294 |\n","Privacy Accuracy 0.5883333333333334\n","Training Accuracy 82.8125\n","(0/500) | Loss: 0.2442 | \n","(301/500) | Loss: 1.0943 |\n","(0/500) | Loss: 0.2615 | \n","Privacy Accuracy 0.5366666666666666\n","Training Accuracy 0\n","Train Accuracy 81.078\n","Test Accuracy 77.41\n","\n","Epoch: [56 | 200]\n","(0/500) | Loss: 0.2438 | \n","(1/500) | Loss: 0.8111 |\n","Privacy Accuracy 0.5933333333333334\n","Training Accuracy 82.8125\n","(0/500) | Loss: 0.2402 | \n","(101/500) | Loss: 0.8734 |\n","(0/500) | Loss: 0.2506 | \n","(201/500) | Loss: 0.8508 |\n","Privacy Accuracy 0.5616666666666666\n","Training Accuracy 81.640625\n","(0/500) | Loss: 0.2480 | \n","(301/500) | Loss: 1.1409 |\n","(0/500) | Loss: 0.2410 | \n","Privacy Accuracy 0.6083333333333333\n","Training Accuracy 0\n","Train Accuracy 83.15\n","Test Accuracy 78.4\n","\n","Epoch: [57 | 200]\n","(0/500) | Loss: 0.2476 | \n","(1/500) | Loss: 0.8948 |\n","Privacy Accuracy 0.5683333333333334\n","Training Accuracy 83.59375\n","(0/500) | Loss: 0.2457 | \n","(101/500) | Loss: 0.6089 |\n","(0/500) | Loss: 0.2401 | \n","(201/500) | Loss: 0.7381 |\n","Privacy Accuracy 0.5816666666666667\n","Training Accuracy 86.328125\n","(0/500) | Loss: 0.2474 | \n","(301/500) | Loss: 0.8008 |\n","(0/500) | Loss: 0.2590 | \n","Privacy Accuracy 0.5733333333333334\n","Training Accuracy 0\n","Train Accuracy 84.692\n","Test Accuracy 80.7\n","\n","Epoch: [58 | 200]\n","(0/500) | Loss: 0.2370 | \n","(1/500) | Loss: 0.8081 |\n","Privacy Accuracy 0.6183333333333333\n","Training Accuracy 83.59375\n","(0/500) | Loss: 0.2385 | \n","(101/500) | Loss: 1.1418 |\n","(0/500) | Loss: 0.2442 | \n","(201/500) | Loss: 0.7634 |\n","Privacy Accuracy 0.5766666666666667\n","Training Accuracy 82.421875\n","(0/500) | Loss: 0.2665 | \n","(301/500) | Loss: 0.9631 |\n","(0/500) | Loss: 0.2474 | \n","Privacy Accuracy 0.585\n","Training Accuracy 0\n","Train Accuracy 81.17\n","Test Accuracy 77.58\n","\n","Epoch: [59 | 200]\n","(0/500) | Loss: 0.2379 | \n","(1/500) | Loss: 0.9409 |\n","Privacy Accuracy 0.5666666666666667\n","Training Accuracy 80.46875\n","(0/500) | Loss: 0.2510 | \n","(101/500) | Loss: 1.0419 |\n","(0/500) | Loss: 0.2504 | \n","(201/500) | Loss: 1.2678 |\n","Privacy Accuracy 0.5716666666666667\n","Training Accuracy 78.515625\n","(0/500) | Loss: 0.2496 | \n","(301/500) | Loss: 1.1045 |\n","(0/500) | Loss: 0.2320 | \n","Privacy Accuracy 0.61\n","Training Accuracy 0\n","Train Accuracy 85.27\n","Test Accuracy 81.18\n","\n","Epoch: [60 | 200]\n","(0/500) | Loss: 0.2397 | \n","(1/500) | Loss: 0.7227 |\n","Privacy Accuracy 0.595\n","Training Accuracy 85.546875\n","(0/500) | Loss: 0.2442 | \n","(101/500) | Loss: 0.7956 |\n","(0/500) | Loss: 0.2563 | \n","(201/500) | Loss: 0.9159 |\n","Privacy Accuracy 0.595\n","Training Accuracy 80.078125\n","(0/500) | Loss: 0.2383 | \n","(301/500) | Loss: 0.8678 |\n","(0/500) | Loss: 0.2554 | \n","Privacy Accuracy 0.58\n","Training Accuracy 0\n","Train Accuracy 85.276\n","Test Accuracy 82.15\n","\n","Epoch: [61 | 200]\n","(0/500) | Loss: 0.2398 | \n","(1/500) | Loss: 0.7966 |\n","Privacy Accuracy 0.5983333333333334\n","Training Accuracy 82.03125\n","(0/500) | Loss: 0.2608 | \n","(101/500) | Loss: 1.0195 |\n","(0/500) | Loss: 0.2487 | \n","(201/500) | Loss: 0.8794 |\n","Privacy Accuracy 0.5733333333333334\n","Training Accuracy 81.25\n","(0/500) | Loss: 0.2469 | \n","(301/500) | Loss: 0.8885 |\n","(0/500) | Loss: 0.2392 | \n","Privacy Accuracy 0.6266666666666667\n","Training Accuracy 0\n","Train Accuracy 83.436\n","Test Accuracy 78.72\n","\n","Epoch: [62 | 200]\n","(0/500) | Loss: 0.2384 | \n","(1/500) | Loss: 0.9503 |\n","Privacy Accuracy 0.5933333333333334\n","Training Accuracy 80.46875\n","(0/500) | Loss: 0.2453 | \n","(101/500) | Loss: 1.2191 |\n","(0/500) | Loss: 0.2601 | \n","(201/500) | Loss: 0.9047 |\n","Privacy Accuracy 0.59\n","Training Accuracy 82.421875\n","(0/500) | Loss: 0.2443 | \n","(301/500) | Loss: 0.9219 |\n","(0/500) | Loss: 0.2411 | \n","Privacy Accuracy 0.59\n","Training Accuracy 0\n","Train Accuracy 82.858\n","Test Accuracy 77.97\n","\n","Epoch: [63 | 200]\n","(0/500) | Loss: 0.2451 | \n","(1/500) | Loss: 0.9564 |\n","Privacy Accuracy 0.5916666666666667\n","Training Accuracy 80.46875\n","(0/500) | Loss: 0.2559 | \n","(101/500) | Loss: 0.8336 |\n","(0/500) | Loss: 0.2405 | \n","(201/500) | Loss: 0.6069 |\n","Privacy Accuracy 0.5983333333333334\n","Training Accuracy 85.546875\n","(0/500) | Loss: 0.2521 | \n","(301/500) | Loss: 0.8511 |\n","(0/500) | Loss: 0.2458 | \n","Privacy Accuracy 0.5333333333333333\n","Training Accuracy 0\n","Train Accuracy 83.104\n","Test Accuracy 79.25\n","\n","Epoch: [64 | 200]\n","(0/500) | Loss: 0.2438 | \n","(1/500) | Loss: 0.8650 |\n","Privacy Accuracy 0.5633333333333334\n","Training Accuracy 78.125\n","(0/500) | Loss: 0.2436 | \n","(101/500) | Loss: 0.7848 |\n","(0/500) | Loss: 0.2481 | \n","(201/500) | Loss: 0.7993 |\n","Privacy Accuracy 0.5733333333333334\n","Training Accuracy 80.859375\n","(0/500) | Loss: 0.2389 | \n","(301/500) | Loss: 1.0445 |\n","(0/500) | Loss: 0.2508 | \n","Privacy Accuracy 0.5466666666666666\n","Training Accuracy 0\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-8e1a8a33f4c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Train Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Test Accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-34-2f956af4f54f>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(testloader, model, criterion, epoch, use_cuda)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;31m# measure data loading time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mdata_time\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    806\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"bZvgZ9_0vnuJ","colab_type":"code","colab":{}},"source":["def softmax_by_row(logits, T = 1.0):\n","    mx = np.max(logits, axis=-1, keepdims=True)\n","    exp = np.exp((logits - mx)/T)\n","    denominator = np.sum(exp, axis=-1, keepdims=True)\n","    return exp/denominator\n","\n","def classifier_performance(model, train_loader, test_loader):\n","\n","    output_train_benign = []\n","    train_label = []\n","    for num, data in enumerate(train_loader):\n","        images,labels = data\n","        image_tensor= images.to(device)\n","        img_variable = Variable(image_tensor, requires_grad=True)\n","        output = model.forward(img_variable)\n","\n","        train_label.append(labels.numpy())\n","        output_train_benign.append(softmax_by_row(output.data.cpu().numpy(),T = 1))\n","\n","\n","    train_label = np.concatenate(train_label)\n","    output_train_benign=np.concatenate(output_train_benign)\n","\n","    test_label = []\n","    output_test_benign = []\n","\n","    for num, data in enumerate(test_loader):\n","        images,labels = data\n","\n","        image_tensor= images.to(device)\n","        img_variable = Variable(image_tensor, requires_grad=True)\n","\n","        output = model.forward(img_variable)\n","\n","        test_label.append(labels.numpy())\n","        output_test_benign.append(softmax_by_row(output.data.cpu().numpy(),T = 1))\n","\n","\n","    test_label = np.concatenate(test_label)\n","    output_test_benign=np.concatenate(output_test_benign)\n","\n","\n","    train_acc1 = np.sum(np.argmax(output_train_benign,axis=1) == train_label.flatten())/len(train_label)\n","    test_acc1 = np.sum(np.argmax(output_test_benign,axis=1) == test_label.flatten())/len(test_label)\n","\n","    print('Accuracy: ', (train_acc1, test_acc1))\n","\n","    return output_train_benign, output_test_benign, train_label, test_label\n","\n","\n","\n","\n","def inference_via_confidence(confidence_mtx1, confidence_mtx2, label_vec1, label_vec2):\n","    \n","    #----------------First step: obtain confidence lists for both training dataset and test dataset--------------\n","    confidence1 = []\n","    confidence2 = []\n","    acc1 = 0\n","    acc2 = 0\n","    for num in range(confidence_mtx1.shape[0]):\n","        confidence1.append(confidence_mtx1[num,label_vec1[num]])\n","        if np.argmax(confidence_mtx1[num,:]) == label_vec1[num]:\n","            acc1 += 1\n","            \n","    for num in range(confidence_mtx2.shape[0]):\n","        confidence2.append(confidence_mtx2[num,label_vec2[num]])\n","        if np.argmax(confidence_mtx2[num,:]) == label_vec2[num]:\n","            acc2 += 1\n","    confidence1 = np.array(confidence1)\n","    confidence2 = np.array(confidence2)\n","    \n","    print('model accuracy for training and test-', (acc1/confidence_mtx1.shape[0], acc2/confidence_mtx2.shape[0]) )\n","    \n","    \n","    #sort_confidence = np.sort(confidence1)\n","    sort_confidence = np.sort(np.concatenate((confidence1, confidence2)))\n","    max_accuracy = 0.5\n","    best_precision = 0.5\n","    best_recall = 0.5\n","    for num in range(len(sort_confidence)):\n","        delta = sort_confidence[num]\n","        ratio1 = np.sum(confidence1>=delta)/confidence_mtx1.shape[0]\n","        ratio2 = np.sum(confidence2>=delta)/confidence_mtx2.shape[0]\n","        accuracy_now = 0.5*(ratio1+1-ratio2)\n","        if accuracy_now > max_accuracy:\n","            max_accuracy = accuracy_now\n","            best_precision = ratio1/(ratio1+ratio2)\n","            best_recall = ratio1\n","    print('membership inference accuracy is:', max_accuracy)\n","    return max_accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dfhyR7UgvtC7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":86},"outputId":"38181887-e670-45a3-b751-089ca87b96a3","executionInfo":{"status":"ok","timestamp":1584016662997,"user_tz":-330,"elapsed":20915,"user":{"displayName":"Vasisht Vasisht","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhdnsVWWQG2LPrqHSKgFAow9xj3qikoca93I6gg=s64","userId":"18321686459009329525"}}},"source":["from torch.autograd import Variable\n","import os\n","import numpy as np\n","import math \n","import scipy\n","import sys  \n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","output_train, output_test, train_label, test_label = classifier_performance(model, trainloader, testloader)\n","inference_accuracy=inference_via_confidence(output_train, output_test, train_label, test_label)\n","print(\"Maximum Accuracy:\",inference_accuracy)"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Accuracy:  (0.87484, 0.8366)\n","model accuracy for training and test- (0.87484, 0.8366)\n","membership inference accuracy is: 0.51922\n","Maximum Accuracy: 0.51922\n"],"name":"stdout"}]}]}