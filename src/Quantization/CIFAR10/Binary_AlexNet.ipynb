{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Binary_AlexNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P8mK1gLddEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojn0VPRecnMr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class BinActive(torch.autograd.Function):\n",
        "    '''\n",
        "    Binarize the input activations and calculate the mean across channel dimension.\n",
        "    '''\n",
        "    def forward(self, input):\n",
        "        self.save_for_backward(input)\n",
        "        size = input.size()\n",
        "        mean = torch.mean(input.abs(), 1, keepdim=True)\n",
        "        input = input.sign()\n",
        "        return input, mean\n",
        "\n",
        "    def backward(self, grad_output, grad_output_mean):\n",
        "        input, = self.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input.ge(1)] = 0\n",
        "        grad_input[input.le(-1)] = 0\n",
        "        return grad_input\n",
        "\n",
        "class BinConv2d(nn.Module):\n",
        "    def __init__(self, input_channels, output_channels,\n",
        "            kernel_size=-1, stride=-1, padding=-1, dropout=0):\n",
        "        super(BinConv2d, self).__init__()\n",
        "        self.layer_type = 'BinConv2d'\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.dropout_ratio = 0\n",
        "        dropout=0\n",
        "        self.bn = nn.BatchNorm2d(input_channels, eps=1e-4, momentum=0.1, affine=True)\n",
        "        self.bn.weight.data = self.bn.weight.data.zero_().add(1.0)\n",
        "        if dropout!=0:\n",
        "            self.dropout = nn.Dropout(dropout)\n",
        "        self.conv = nn.Conv2d(input_channels, output_channels,\n",
        "                kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.bn(x)\n",
        "        x, mean = BinActive()(x)\n",
        "        x = self.conv(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Net, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.BatchNorm2d(64, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            BinConv2d(64, 192, stride=1, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm2d(192, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            BinConv2d(192, 384, stride=1, kernel_size=3, padding=2),\n",
        "            nn.BatchNorm2d(384, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            BinConv2d(384, 256, stride=1, kernel_size=3, padding=2),\n",
        "            nn.BatchNorm2d(256, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            BinConv2d(256, 256, stride=1, kernel_size=3, padding=2),\n",
        "            nn.BatchNorm2d(256, eps=1e-4, momentum=0.1, affine=False),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOxdhLbLdZms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import numpy\n",
        "\n",
        "class BinOp():\n",
        "    def __init__(self, model):\n",
        "        # count the number of Conv2d\n",
        "        count_Conv2d = 0\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                count_Conv2d = count_Conv2d + 1\n",
        "\n",
        "        start_range = 1\n",
        "        end_range = count_Conv2d-2\n",
        "        self.bin_range = numpy.linspace(start_range,\n",
        "                end_range, end_range-start_range+1)\\\n",
        "                        .astype('int').tolist()\n",
        "        self.num_of_params = len(self.bin_range)\n",
        "        self.saved_params = []\n",
        "        self.target_params = []\n",
        "        self.target_modules = []\n",
        "        index = -1\n",
        "        for m in model.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                index = index + 1\n",
        "                if index in self.bin_range:\n",
        "                    tmp = m.weight.data.clone()\n",
        "                    self.saved_params.append(tmp)\n",
        "                    self.target_modules.append(m.weight)\n",
        "\n",
        "    def binarization(self):\n",
        "        self.meancenterConvParams()\n",
        "        self.clampConvParams()\n",
        "        self.save_params()\n",
        "        self.binarizeConvParams()\n",
        "\n",
        "    def meancenterConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            s = self.target_modules[index].data.size()\n",
        "            negMean = self.target_modules[index].data.mean(1, keepdim=True).\\\n",
        "                    mul(-1).expand_as(self.target_modules[index].data)\n",
        "            self.target_modules[index].data = self.target_modules[index].data.add(negMean)\n",
        "\n",
        "    def clampConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.target_modules[index].data = \\\n",
        "                    self.target_modules[index].data.clamp(-1.0, 1.0)\n",
        "\n",
        "    def save_params(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.saved_params[index].copy_(self.target_modules[index].data)\n",
        "\n",
        "    def binarizeConvParams(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            n = self.target_modules[index].data[0].nelement()\n",
        "            s = self.target_modules[index].data.size()\n",
        "            m = self.target_modules[index].data.norm(1, 3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n)\n",
        "            self.target_modules[index].data = \\\n",
        "                    self.target_modules[index].data.sign().mul(m.expand(s))\n",
        "\n",
        "    def restore(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            self.target_modules[index].data.copy_(self.saved_params[index])\n",
        "\n",
        "    def updateBinaryGradWeight(self):\n",
        "        for index in range(self.num_of_params):\n",
        "            weight = self.target_modules[index].data\n",
        "            n = weight[0].nelement()\n",
        "            s = weight.size()\n",
        "            m = weight.norm(1, 3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n",
        "            m[weight.lt(-1.0)] = 0 \n",
        "            m[weight.gt(1.0)] = 0\n",
        "            # m = m.add(1.0/n).mul(1.0-1.0/s[1]).mul(n)\n",
        "            # self.target_modules[index].grad.data = \\\n",
        "            #         self.target_modules[index].grad.data.mul(m)\n",
        "            m = m.mul(self.target_modules[index].grad.data)\n",
        "            m_add = weight.sign().mul(self.target_modules[index].grad.data)\n",
        "            m_add = m_add.sum(3, keepdim=True)\\\n",
        "                    .sum(2, keepdim=True).sum(1, keepdim=True).div(n).expand(s)\n",
        "            m_add = m_add.mul(weight.sign())\n",
        "            self.target_modules[index].grad.data = m.add(m_add).mul(1.0-1.0/s[1]).mul(n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em143EF9edj6",
        "colab_type": "code",
        "outputId": "644a31f9-e0c8-4d73-e6a2-91b64c30365e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwrC2SJ9eOim",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epochs):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(trainloader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            #loss = nn.NLLLoss(output,target)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            if batch_idx % 100 == 0:\n",
        "                done = batch_idx * len(data)\n",
        "                percentage = 100. * batch_idx / len(trainloader)\n",
        "                print(f'Train Epoch: {epoch} [{done:5}/{len(trainloader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')\n",
        "\n",
        "        test(trainloader)\n",
        "        test(testloader)\n",
        "\n",
        "\n",
        "def test(loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item() # sum up batch loss\n",
        "            #test_loss += nn.NLLLoss(output, target).item()\n",
        "            pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= len(loader.dataset)\n",
        "        accuracy = 100. * correct / len(loader.dataset)\n",
        "        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loader.dataset)} ({accuracy:.2f}%)')\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkoGwyFedx5Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "26125ceb-7486-44c8-b633-d0fe1f7b7e33"
      },
      "source": [
        "model = Net()\n",
        "\n",
        "model.cuda()\n",
        "model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n",
        "print(model)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4,weight_decay=0.0000)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# define the binarization operator\n",
        "bin_op = BinOp(model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DataParallel(\n",
            "  (module): Net(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "      (1): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (4): BinConv2d(\n",
            "        (bn): BatchNorm2d(64, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): BatchNorm2d(192, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (8): BinConv2d(\n",
            "        (bn): BatchNorm2d(192, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (9): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "      (10): ReLU(inplace=True)\n",
            "      (11): BinConv2d(\n",
            "        (bn): BatchNorm2d(384, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (12): BatchNorm2d(256, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): BinConv2d(\n",
            "        (bn): BatchNorm2d(256, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2))\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (15): BatchNorm2d(256, eps=0.0001, momentum=0.1, affine=False, track_running_stats=True)\n",
            "      (16): ReLU(inplace=True)\n",
            "      (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): Linear(in_features=4096, out_features=10, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcfB-qK3diJC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b7aabc3-7c75-4612-8f2d-ebab9eed81b2"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "train(125)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [    0/50000 (  0%)]  Loss: 2.346761\n",
            "Train Epoch: 0 [12800/50000 ( 26%)]  Loss: 1.926266\n",
            "Train Epoch: 0 [25600/50000 ( 51%)]  Loss: 1.885543\n",
            "Train Epoch: 0 [38400/50000 ( 77%)]  Loss: 1.695635\n",
            "Test set: Average loss: 0.0135, Accuracy: 17439/50000 (34.88%)\n",
            "Test set: Average loss: 0.0169, Accuracy: 3617/10000 (36.17%)\n",
            "Train Epoch: 1 [    0/50000 (  0%)]  Loss: 1.828619\n",
            "Train Epoch: 1 [12800/50000 ( 26%)]  Loss: 1.763135\n",
            "Train Epoch: 1 [25600/50000 ( 51%)]  Loss: 1.675170\n",
            "Train Epoch: 1 [38400/50000 ( 77%)]  Loss: 1.648822\n",
            "Test set: Average loss: 0.0126, Accuracy: 19804/50000 (39.61%)\n",
            "Test set: Average loss: 0.0156, Accuracy: 4154/10000 (41.54%)\n",
            "Train Epoch: 2 [    0/50000 (  0%)]  Loss: 1.501599\n",
            "Train Epoch: 2 [12800/50000 ( 26%)]  Loss: 1.517566\n",
            "Train Epoch: 2 [25600/50000 ( 51%)]  Loss: 1.694481\n",
            "Train Epoch: 2 [38400/50000 ( 77%)]  Loss: 1.630272\n",
            "Test set: Average loss: 0.0123, Accuracy: 21223/50000 (42.45%)\n",
            "Test set: Average loss: 0.0152, Accuracy: 4426/10000 (44.26%)\n",
            "Train Epoch: 3 [    0/50000 (  0%)]  Loss: 1.482632\n",
            "Train Epoch: 3 [12800/50000 ( 26%)]  Loss: 1.509774\n",
            "Train Epoch: 3 [25600/50000 ( 51%)]  Loss: 1.607969\n",
            "Train Epoch: 3 [38400/50000 ( 77%)]  Loss: 1.573090\n",
            "Test set: Average loss: 0.0117, Accuracy: 22209/50000 (44.42%)\n",
            "Test set: Average loss: 0.0148, Accuracy: 4518/10000 (45.18%)\n",
            "Train Epoch: 4 [    0/50000 (  0%)]  Loss: 1.538904\n",
            "Train Epoch: 4 [12800/50000 ( 26%)]  Loss: 1.573854\n",
            "Train Epoch: 4 [25600/50000 ( 51%)]  Loss: 1.506782\n",
            "Train Epoch: 4 [38400/50000 ( 77%)]  Loss: 1.384800\n",
            "Test set: Average loss: 0.0114, Accuracy: 23353/50000 (46.71%)\n",
            "Test set: Average loss: 0.0144, Accuracy: 4745/10000 (47.45%)\n",
            "Train Epoch: 5 [    0/50000 (  0%)]  Loss: 1.485137\n",
            "Train Epoch: 5 [12800/50000 ( 26%)]  Loss: 1.445732\n",
            "Train Epoch: 5 [25600/50000 ( 51%)]  Loss: 1.566089\n",
            "Train Epoch: 5 [38400/50000 ( 77%)]  Loss: 1.400355\n",
            "Test set: Average loss: 0.0111, Accuracy: 24070/50000 (48.14%)\n",
            "Test set: Average loss: 0.0139, Accuracy: 4898/10000 (48.98%)\n",
            "Train Epoch: 6 [    0/50000 (  0%)]  Loss: 1.410617\n",
            "Train Epoch: 6 [12800/50000 ( 26%)]  Loss: 1.602641\n",
            "Train Epoch: 6 [25600/50000 ( 51%)]  Loss: 1.363793\n",
            "Train Epoch: 6 [38400/50000 ( 77%)]  Loss: 1.374451\n",
            "Test set: Average loss: 0.0111, Accuracy: 24103/50000 (48.21%)\n",
            "Test set: Average loss: 0.0139, Accuracy: 4916/10000 (49.16%)\n",
            "Train Epoch: 7 [    0/50000 (  0%)]  Loss: 1.327962\n",
            "Train Epoch: 7 [12800/50000 ( 26%)]  Loss: 1.259157\n",
            "Train Epoch: 7 [25600/50000 ( 51%)]  Loss: 1.158507\n",
            "Train Epoch: 7 [38400/50000 ( 77%)]  Loss: 1.471694\n",
            "Test set: Average loss: 0.0108, Accuracy: 25044/50000 (50.09%)\n",
            "Test set: Average loss: 0.0136, Accuracy: 5131/10000 (51.31%)\n",
            "Train Epoch: 8 [    0/50000 (  0%)]  Loss: 1.281064\n",
            "Train Epoch: 8 [12800/50000 ( 26%)]  Loss: 1.395380\n",
            "Train Epoch: 8 [25600/50000 ( 51%)]  Loss: 1.413245\n",
            "Train Epoch: 8 [38400/50000 ( 77%)]  Loss: 1.364599\n",
            "Test set: Average loss: 0.0107, Accuracy: 25295/50000 (50.59%)\n",
            "Test set: Average loss: 0.0136, Accuracy: 5183/10000 (51.83%)\n",
            "Train Epoch: 9 [    0/50000 (  0%)]  Loss: 1.446778\n",
            "Train Epoch: 9 [12800/50000 ( 26%)]  Loss: 1.205966\n",
            "Train Epoch: 9 [25600/50000 ( 51%)]  Loss: 1.332203\n",
            "Train Epoch: 9 [38400/50000 ( 77%)]  Loss: 1.474646\n",
            "Test set: Average loss: 0.0104, Accuracy: 26037/50000 (52.07%)\n",
            "Test set: Average loss: 0.0130, Accuracy: 5325/10000 (53.25%)\n",
            "Train Epoch: 10 [    0/50000 (  0%)]  Loss: 1.530147\n",
            "Train Epoch: 10 [12800/50000 ( 26%)]  Loss: 1.370293\n",
            "Train Epoch: 10 [25600/50000 ( 51%)]  Loss: 1.436183\n",
            "Train Epoch: 10 [38400/50000 ( 77%)]  Loss: 1.444681\n",
            "Test set: Average loss: 0.0103, Accuracy: 26202/50000 (52.40%)\n",
            "Test set: Average loss: 0.0128, Accuracy: 5363/10000 (53.63%)\n",
            "Train Epoch: 11 [    0/50000 (  0%)]  Loss: 1.332167\n",
            "Train Epoch: 11 [12800/50000 ( 26%)]  Loss: 1.484209\n",
            "Train Epoch: 11 [25600/50000 ( 51%)]  Loss: 1.465831\n",
            "Train Epoch: 11 [38400/50000 ( 77%)]  Loss: 1.305787\n",
            "Test set: Average loss: 0.0101, Accuracy: 26555/50000 (53.11%)\n",
            "Test set: Average loss: 0.0128, Accuracy: 5385/10000 (53.85%)\n",
            "Train Epoch: 12 [    0/50000 (  0%)]  Loss: 1.380785\n",
            "Train Epoch: 12 [12800/50000 ( 26%)]  Loss: 1.305335\n",
            "Train Epoch: 12 [25600/50000 ( 51%)]  Loss: 1.252715\n",
            "Train Epoch: 12 [38400/50000 ( 77%)]  Loss: 1.414409\n",
            "Test set: Average loss: 0.0100, Accuracy: 27027/50000 (54.05%)\n",
            "Test set: Average loss: 0.0126, Accuracy: 5449/10000 (54.49%)\n",
            "Train Epoch: 13 [    0/50000 (  0%)]  Loss: 1.208195\n",
            "Train Epoch: 13 [12800/50000 ( 26%)]  Loss: 1.097216\n",
            "Train Epoch: 13 [25600/50000 ( 51%)]  Loss: 1.304714\n",
            "Train Epoch: 13 [38400/50000 ( 77%)]  Loss: 1.456459\n",
            "Test set: Average loss: 0.0100, Accuracy: 27119/50000 (54.24%)\n",
            "Test set: Average loss: 0.0125, Accuracy: 5508/10000 (55.08%)\n",
            "Train Epoch: 14 [    0/50000 (  0%)]  Loss: 1.040485\n",
            "Train Epoch: 14 [12800/50000 ( 26%)]  Loss: 1.141915\n",
            "Train Epoch: 14 [25600/50000 ( 51%)]  Loss: 1.240699\n",
            "Train Epoch: 14 [38400/50000 ( 77%)]  Loss: 1.379954\n",
            "Test set: Average loss: 0.0098, Accuracy: 27296/50000 (54.59%)\n",
            "Test set: Average loss: 0.0125, Accuracy: 5514/10000 (55.14%)\n",
            "Train Epoch: 15 [    0/50000 (  0%)]  Loss: 1.174325\n",
            "Train Epoch: 15 [12800/50000 ( 26%)]  Loss: 1.360094\n",
            "Train Epoch: 15 [25600/50000 ( 51%)]  Loss: 1.193203\n",
            "Train Epoch: 15 [38400/50000 ( 77%)]  Loss: 1.246328\n",
            "Test set: Average loss: 0.0098, Accuracy: 27435/50000 (54.87%)\n",
            "Test set: Average loss: 0.0124, Accuracy: 5537/10000 (55.37%)\n",
            "Train Epoch: 16 [    0/50000 (  0%)]  Loss: 1.128607\n",
            "Train Epoch: 16 [12800/50000 ( 26%)]  Loss: 1.297393\n",
            "Train Epoch: 16 [25600/50000 ( 51%)]  Loss: 1.293353\n",
            "Train Epoch: 16 [38400/50000 ( 77%)]  Loss: 1.207303\n",
            "Test set: Average loss: 0.0096, Accuracy: 27849/50000 (55.70%)\n",
            "Test set: Average loss: 0.0122, Accuracy: 5586/10000 (55.86%)\n",
            "Train Epoch: 17 [    0/50000 (  0%)]  Loss: 1.274779\n",
            "Train Epoch: 17 [12800/50000 ( 26%)]  Loss: 1.260201\n",
            "Train Epoch: 17 [25600/50000 ( 51%)]  Loss: 1.205472\n",
            "Train Epoch: 17 [38400/50000 ( 77%)]  Loss: 1.257582\n",
            "Test set: Average loss: 0.0095, Accuracy: 28193/50000 (56.39%)\n",
            "Test set: Average loss: 0.0120, Accuracy: 5687/10000 (56.87%)\n",
            "Train Epoch: 18 [    0/50000 (  0%)]  Loss: 1.209281\n",
            "Train Epoch: 18 [12800/50000 ( 26%)]  Loss: 1.320339\n",
            "Train Epoch: 18 [25600/50000 ( 51%)]  Loss: 1.081225\n",
            "Train Epoch: 18 [38400/50000 ( 77%)]  Loss: 1.379258\n",
            "Test set: Average loss: 0.0095, Accuracy: 28161/50000 (56.32%)\n",
            "Test set: Average loss: 0.0121, Accuracy: 5650/10000 (56.50%)\n",
            "Train Epoch: 19 [    0/50000 (  0%)]  Loss: 1.403371\n",
            "Train Epoch: 19 [12800/50000 ( 26%)]  Loss: 1.173059\n",
            "Train Epoch: 19 [25600/50000 ( 51%)]  Loss: 1.210906\n",
            "Train Epoch: 19 [38400/50000 ( 77%)]  Loss: 1.212522\n",
            "Test set: Average loss: 0.0094, Accuracy: 28500/50000 (57.00%)\n",
            "Test set: Average loss: 0.0117, Accuracy: 5784/10000 (57.84%)\n",
            "Train Epoch: 20 [    0/50000 (  0%)]  Loss: 1.256900\n",
            "Train Epoch: 20 [12800/50000 ( 26%)]  Loss: 1.261412\n",
            "Train Epoch: 20 [25600/50000 ( 51%)]  Loss: 1.132829\n",
            "Train Epoch: 20 [38400/50000 ( 77%)]  Loss: 1.261608\n",
            "Test set: Average loss: 0.0093, Accuracy: 28927/50000 (57.85%)\n",
            "Test set: Average loss: 0.0119, Accuracy: 5740/10000 (57.40%)\n",
            "Train Epoch: 21 [    0/50000 (  0%)]  Loss: 1.130152\n",
            "Train Epoch: 21 [12800/50000 ( 26%)]  Loss: 1.307679\n",
            "Train Epoch: 21 [25600/50000 ( 51%)]  Loss: 1.242157\n",
            "Train Epoch: 21 [38400/50000 ( 77%)]  Loss: 1.203381\n",
            "Test set: Average loss: 0.0092, Accuracy: 29039/50000 (58.08%)\n",
            "Test set: Average loss: 0.0117, Accuracy: 5820/10000 (58.20%)\n",
            "Train Epoch: 22 [    0/50000 (  0%)]  Loss: 1.197875\n",
            "Train Epoch: 22 [12800/50000 ( 26%)]  Loss: 1.127777\n",
            "Train Epoch: 22 [25600/50000 ( 51%)]  Loss: 1.099596\n",
            "Train Epoch: 22 [38400/50000 ( 77%)]  Loss: 1.218491\n",
            "Test set: Average loss: 0.0092, Accuracy: 29035/50000 (58.07%)\n",
            "Test set: Average loss: 0.0118, Accuracy: 5768/10000 (57.68%)\n",
            "Train Epoch: 23 [    0/50000 (  0%)]  Loss: 0.959279\n",
            "Train Epoch: 23 [12800/50000 ( 26%)]  Loss: 1.230520\n",
            "Train Epoch: 23 [25600/50000 ( 51%)]  Loss: 1.063139\n",
            "Train Epoch: 23 [38400/50000 ( 77%)]  Loss: 1.248715\n",
            "Test set: Average loss: 0.0090, Accuracy: 29276/50000 (58.55%)\n",
            "Test set: Average loss: 0.0114, Accuracy: 5928/10000 (59.28%)\n",
            "Train Epoch: 24 [    0/50000 (  0%)]  Loss: 1.083069\n",
            "Train Epoch: 24 [12800/50000 ( 26%)]  Loss: 1.019647\n",
            "Train Epoch: 24 [25600/50000 ( 51%)]  Loss: 1.012220\n",
            "Train Epoch: 24 [38400/50000 ( 77%)]  Loss: 1.250834\n",
            "Test set: Average loss: 0.0089, Accuracy: 29683/50000 (59.37%)\n",
            "Test set: Average loss: 0.0113, Accuracy: 5964/10000 (59.64%)\n",
            "Train Epoch: 25 [    0/50000 (  0%)]  Loss: 1.113485\n",
            "Train Epoch: 25 [12800/50000 ( 26%)]  Loss: 1.065619\n",
            "Train Epoch: 25 [25600/50000 ( 51%)]  Loss: 1.023666\n",
            "Train Epoch: 25 [38400/50000 ( 77%)]  Loss: 1.063910\n",
            "Test set: Average loss: 0.0089, Accuracy: 29580/50000 (59.16%)\n",
            "Test set: Average loss: 0.0114, Accuracy: 5911/10000 (59.11%)\n",
            "Train Epoch: 26 [    0/50000 (  0%)]  Loss: 1.067258\n",
            "Train Epoch: 26 [12800/50000 ( 26%)]  Loss: 1.032276\n",
            "Train Epoch: 26 [25600/50000 ( 51%)]  Loss: 1.165910\n",
            "Train Epoch: 26 [38400/50000 ( 77%)]  Loss: 1.197135\n",
            "Test set: Average loss: 0.0089, Accuracy: 29734/50000 (59.47%)\n",
            "Test set: Average loss: 0.0113, Accuracy: 5970/10000 (59.70%)\n",
            "Train Epoch: 27 [    0/50000 (  0%)]  Loss: 1.079468\n",
            "Train Epoch: 27 [12800/50000 ( 26%)]  Loss: 1.176466\n",
            "Train Epoch: 27 [25600/50000 ( 51%)]  Loss: 1.049984\n",
            "Train Epoch: 27 [38400/50000 ( 77%)]  Loss: 1.325067\n",
            "Test set: Average loss: 0.0088, Accuracy: 29781/50000 (59.56%)\n",
            "Test set: Average loss: 0.0112, Accuracy: 5992/10000 (59.92%)\n",
            "Train Epoch: 28 [    0/50000 (  0%)]  Loss: 1.198396\n",
            "Train Epoch: 28 [12800/50000 ( 26%)]  Loss: 1.209702\n",
            "Train Epoch: 28 [25600/50000 ( 51%)]  Loss: 1.122866\n",
            "Train Epoch: 28 [38400/50000 ( 77%)]  Loss: 1.246204\n",
            "Test set: Average loss: 0.0088, Accuracy: 30001/50000 (60.00%)\n",
            "Test set: Average loss: 0.0112, Accuracy: 6037/10000 (60.37%)\n",
            "Train Epoch: 29 [    0/50000 (  0%)]  Loss: 1.130638\n",
            "Train Epoch: 29 [12800/50000 ( 26%)]  Loss: 1.070367\n",
            "Train Epoch: 29 [25600/50000 ( 51%)]  Loss: 1.258520\n",
            "Train Epoch: 29 [38400/50000 ( 77%)]  Loss: 1.100373\n",
            "Test set: Average loss: 0.0088, Accuracy: 29934/50000 (59.87%)\n",
            "Test set: Average loss: 0.0111, Accuracy: 6047/10000 (60.47%)\n",
            "Train Epoch: 30 [    0/50000 (  0%)]  Loss: 1.169035\n",
            "Train Epoch: 30 [12800/50000 ( 26%)]  Loss: 1.103153\n",
            "Train Epoch: 30 [25600/50000 ( 51%)]  Loss: 1.187527\n",
            "Train Epoch: 30 [38400/50000 ( 77%)]  Loss: 1.249404\n",
            "Test set: Average loss: 0.0087, Accuracy: 30080/50000 (60.16%)\n",
            "Test set: Average loss: 0.0113, Accuracy: 5970/10000 (59.70%)\n",
            "Train Epoch: 31 [    0/50000 (  0%)]  Loss: 1.039255\n",
            "Train Epoch: 31 [12800/50000 ( 26%)]  Loss: 1.043600\n",
            "Train Epoch: 31 [25600/50000 ( 51%)]  Loss: 1.163061\n",
            "Train Epoch: 31 [38400/50000 ( 77%)]  Loss: 0.866229\n",
            "Test set: Average loss: 0.0085, Accuracy: 30464/50000 (60.93%)\n",
            "Test set: Average loss: 0.0111, Accuracy: 6092/10000 (60.92%)\n",
            "Train Epoch: 32 [    0/50000 (  0%)]  Loss: 1.100545\n",
            "Train Epoch: 32 [12800/50000 ( 26%)]  Loss: 1.150101\n",
            "Train Epoch: 32 [25600/50000 ( 51%)]  Loss: 1.129426\n",
            "Train Epoch: 32 [38400/50000 ( 77%)]  Loss: 1.129657\n",
            "Test set: Average loss: 0.0085, Accuracy: 30552/50000 (61.10%)\n",
            "Test set: Average loss: 0.0110, Accuracy: 6124/10000 (61.24%)\n",
            "Train Epoch: 33 [    0/50000 (  0%)]  Loss: 1.159651\n",
            "Train Epoch: 33 [12800/50000 ( 26%)]  Loss: 0.838983\n",
            "Train Epoch: 33 [25600/50000 ( 51%)]  Loss: 1.136622\n",
            "Train Epoch: 33 [38400/50000 ( 77%)]  Loss: 1.221408\n",
            "Test set: Average loss: 0.0085, Accuracy: 30621/50000 (61.24%)\n",
            "Test set: Average loss: 0.0109, Accuracy: 6180/10000 (61.80%)\n",
            "Train Epoch: 34 [    0/50000 (  0%)]  Loss: 1.139824\n",
            "Train Epoch: 34 [12800/50000 ( 26%)]  Loss: 1.213746\n",
            "Train Epoch: 34 [25600/50000 ( 51%)]  Loss: 0.979337\n",
            "Train Epoch: 34 [38400/50000 ( 77%)]  Loss: 1.232616\n",
            "Test set: Average loss: 0.0084, Accuracy: 30781/50000 (61.56%)\n",
            "Test set: Average loss: 0.0109, Accuracy: 6124/10000 (61.24%)\n",
            "Train Epoch: 35 [    0/50000 (  0%)]  Loss: 0.885131\n",
            "Train Epoch: 35 [12800/50000 ( 26%)]  Loss: 1.174824\n",
            "Train Epoch: 35 [25600/50000 ( 51%)]  Loss: 0.979129\n",
            "Train Epoch: 35 [38400/50000 ( 77%)]  Loss: 1.055910\n",
            "Test set: Average loss: 0.0084, Accuracy: 30777/50000 (61.55%)\n",
            "Test set: Average loss: 0.0108, Accuracy: 6192/10000 (61.92%)\n",
            "Train Epoch: 36 [    0/50000 (  0%)]  Loss: 1.090147\n",
            "Train Epoch: 36 [12800/50000 ( 26%)]  Loss: 0.904567\n",
            "Train Epoch: 36 [25600/50000 ( 51%)]  Loss: 1.113498\n",
            "Train Epoch: 36 [38400/50000 ( 77%)]  Loss: 1.125462\n",
            "Test set: Average loss: 0.0084, Accuracy: 30849/50000 (61.70%)\n",
            "Test set: Average loss: 0.0108, Accuracy: 6150/10000 (61.50%)\n",
            "Train Epoch: 37 [    0/50000 (  0%)]  Loss: 1.049405\n",
            "Train Epoch: 37 [12800/50000 ( 26%)]  Loss: 0.985949\n",
            "Train Epoch: 37 [25600/50000 ( 51%)]  Loss: 1.139380\n",
            "Train Epoch: 37 [38400/50000 ( 77%)]  Loss: 0.959967\n",
            "Test set: Average loss: 0.0084, Accuracy: 30921/50000 (61.84%)\n",
            "Test set: Average loss: 0.0109, Accuracy: 6179/10000 (61.79%)\n",
            "Train Epoch: 38 [    0/50000 (  0%)]  Loss: 1.000041\n",
            "Train Epoch: 38 [12800/50000 ( 26%)]  Loss: 1.263282\n",
            "Train Epoch: 38 [25600/50000 ( 51%)]  Loss: 0.956478\n",
            "Train Epoch: 38 [38400/50000 ( 77%)]  Loss: 0.995327\n",
            "Test set: Average loss: 0.0083, Accuracy: 31004/50000 (62.01%)\n",
            "Test set: Average loss: 0.0108, Accuracy: 6095/10000 (60.95%)\n",
            "Train Epoch: 39 [    0/50000 (  0%)]  Loss: 1.096886\n",
            "Train Epoch: 39 [12800/50000 ( 26%)]  Loss: 1.111590\n",
            "Train Epoch: 39 [25600/50000 ( 51%)]  Loss: 1.176757\n",
            "Train Epoch: 39 [38400/50000 ( 77%)]  Loss: 0.962864\n",
            "Test set: Average loss: 0.0083, Accuracy: 31166/50000 (62.33%)\n",
            "Test set: Average loss: 0.0107, Accuracy: 6236/10000 (62.36%)\n",
            "Train Epoch: 40 [    0/50000 (  0%)]  Loss: 0.977689\n",
            "Train Epoch: 40 [12800/50000 ( 26%)]  Loss: 0.922844\n",
            "Train Epoch: 40 [25600/50000 ( 51%)]  Loss: 1.120963\n",
            "Train Epoch: 40 [38400/50000 ( 77%)]  Loss: 1.009984\n",
            "Test set: Average loss: 0.0082, Accuracy: 31264/50000 (62.53%)\n",
            "Test set: Average loss: 0.0107, Accuracy: 6183/10000 (61.83%)\n",
            "Train Epoch: 41 [    0/50000 (  0%)]  Loss: 1.063984\n",
            "Train Epoch: 41 [12800/50000 ( 26%)]  Loss: 1.032832\n",
            "Train Epoch: 41 [25600/50000 ( 51%)]  Loss: 0.987173\n",
            "Train Epoch: 41 [38400/50000 ( 77%)]  Loss: 1.035523\n",
            "Test set: Average loss: 0.0082, Accuracy: 31349/50000 (62.70%)\n",
            "Test set: Average loss: 0.0106, Accuracy: 6247/10000 (62.47%)\n",
            "Train Epoch: 42 [    0/50000 (  0%)]  Loss: 0.903309\n",
            "Train Epoch: 42 [12800/50000 ( 26%)]  Loss: 1.083587\n",
            "Train Epoch: 42 [25600/50000 ( 51%)]  Loss: 1.178625\n",
            "Train Epoch: 42 [38400/50000 ( 77%)]  Loss: 1.068447\n",
            "Test set: Average loss: 0.0081, Accuracy: 31388/50000 (62.78%)\n",
            "Test set: Average loss: 0.0106, Accuracy: 6247/10000 (62.47%)\n",
            "Train Epoch: 43 [    0/50000 (  0%)]  Loss: 0.984077\n",
            "Train Epoch: 43 [12800/50000 ( 26%)]  Loss: 1.152232\n",
            "Train Epoch: 43 [25600/50000 ( 51%)]  Loss: 0.932497\n",
            "Train Epoch: 43 [38400/50000 ( 77%)]  Loss: 0.932060\n",
            "Test set: Average loss: 0.0082, Accuracy: 31432/50000 (62.86%)\n",
            "Test set: Average loss: 0.0105, Accuracy: 6301/10000 (63.01%)\n",
            "Train Epoch: 44 [    0/50000 (  0%)]  Loss: 0.994724\n",
            "Train Epoch: 44 [12800/50000 ( 26%)]  Loss: 1.047627\n",
            "Train Epoch: 44 [25600/50000 ( 51%)]  Loss: 1.068406\n",
            "Train Epoch: 44 [38400/50000 ( 77%)]  Loss: 1.097718\n",
            "Test set: Average loss: 0.0081, Accuracy: 31563/50000 (63.13%)\n",
            "Test set: Average loss: 0.0105, Accuracy: 6338/10000 (63.38%)\n",
            "Train Epoch: 45 [    0/50000 (  0%)]  Loss: 0.946308\n",
            "Train Epoch: 45 [12800/50000 ( 26%)]  Loss: 0.981098\n",
            "Train Epoch: 45 [25600/50000 ( 51%)]  Loss: 1.067997\n",
            "Train Epoch: 45 [38400/50000 ( 77%)]  Loss: 1.027874\n",
            "Test set: Average loss: 0.0080, Accuracy: 31776/50000 (63.55%)\n",
            "Test set: Average loss: 0.0105, Accuracy: 6282/10000 (62.82%)\n",
            "Train Epoch: 46 [    0/50000 (  0%)]  Loss: 0.826300\n",
            "Train Epoch: 46 [12800/50000 ( 26%)]  Loss: 1.179658\n",
            "Train Epoch: 46 [25600/50000 ( 51%)]  Loss: 1.052969\n",
            "Train Epoch: 46 [38400/50000 ( 77%)]  Loss: 1.142715\n",
            "Test set: Average loss: 0.0080, Accuracy: 31786/50000 (63.57%)\n",
            "Test set: Average loss: 0.0104, Accuracy: 6321/10000 (63.21%)\n",
            "Train Epoch: 47 [    0/50000 (  0%)]  Loss: 0.991129\n",
            "Train Epoch: 47 [12800/50000 ( 26%)]  Loss: 1.213003\n",
            "Train Epoch: 47 [25600/50000 ( 51%)]  Loss: 1.045486\n",
            "Train Epoch: 47 [38400/50000 ( 77%)]  Loss: 1.006147\n",
            "Test set: Average loss: 0.0081, Accuracy: 31613/50000 (63.23%)\n",
            "Test set: Average loss: 0.0105, Accuracy: 6302/10000 (63.02%)\n",
            "Train Epoch: 48 [    0/50000 (  0%)]  Loss: 1.109902\n",
            "Train Epoch: 48 [12800/50000 ( 26%)]  Loss: 1.212793\n",
            "Train Epoch: 48 [25600/50000 ( 51%)]  Loss: 0.912005\n",
            "Train Epoch: 48 [38400/50000 ( 77%)]  Loss: 1.123085\n",
            "Test set: Average loss: 0.0079, Accuracy: 31904/50000 (63.81%)\n",
            "Test set: Average loss: 0.0104, Accuracy: 6295/10000 (62.95%)\n",
            "Train Epoch: 49 [    0/50000 (  0%)]  Loss: 0.926187\n",
            "Train Epoch: 49 [12800/50000 ( 26%)]  Loss: 0.858419\n",
            "Train Epoch: 49 [25600/50000 ( 51%)]  Loss: 0.916872\n",
            "Train Epoch: 49 [38400/50000 ( 77%)]  Loss: 0.915458\n",
            "Test set: Average loss: 0.0079, Accuracy: 32008/50000 (64.02%)\n",
            "Test set: Average loss: 0.0104, Accuracy: 6334/10000 (63.34%)\n",
            "Train Epoch: 50 [    0/50000 (  0%)]  Loss: 0.904451\n",
            "Train Epoch: 50 [12800/50000 ( 26%)]  Loss: 0.942618\n",
            "Train Epoch: 50 [25600/50000 ( 51%)]  Loss: 0.883013\n",
            "Train Epoch: 50 [38400/50000 ( 77%)]  Loss: 1.090961\n",
            "Test set: Average loss: 0.0079, Accuracy: 32021/50000 (64.04%)\n",
            "Test set: Average loss: 0.0103, Accuracy: 6358/10000 (63.58%)\n",
            "Train Epoch: 51 [    0/50000 (  0%)]  Loss: 1.045205\n",
            "Train Epoch: 51 [12800/50000 ( 26%)]  Loss: 1.059832\n",
            "Train Epoch: 51 [25600/50000 ( 51%)]  Loss: 1.141301\n",
            "Train Epoch: 51 [38400/50000 ( 77%)]  Loss: 1.089335\n",
            "Test set: Average loss: 0.0079, Accuracy: 31921/50000 (63.84%)\n",
            "Test set: Average loss: 0.0103, Accuracy: 6301/10000 (63.01%)\n",
            "Train Epoch: 52 [    0/50000 (  0%)]  Loss: 1.039749\n",
            "Train Epoch: 52 [12800/50000 ( 26%)]  Loss: 1.063170\n",
            "Train Epoch: 52 [25600/50000 ( 51%)]  Loss: 0.912232\n",
            "Train Epoch: 52 [38400/50000 ( 77%)]  Loss: 0.915569\n",
            "Test set: Average loss: 0.0079, Accuracy: 32015/50000 (64.03%)\n",
            "Test set: Average loss: 0.0103, Accuracy: 6366/10000 (63.66%)\n",
            "Train Epoch: 53 [    0/50000 (  0%)]  Loss: 1.075158\n",
            "Train Epoch: 53 [12800/50000 ( 26%)]  Loss: 0.940946\n",
            "Train Epoch: 53 [25600/50000 ( 51%)]  Loss: 1.157747\n",
            "Train Epoch: 53 [38400/50000 ( 77%)]  Loss: 1.170259\n",
            "Test set: Average loss: 0.0079, Accuracy: 31946/50000 (63.89%)\n",
            "Test set: Average loss: 0.0104, Accuracy: 6336/10000 (63.36%)\n",
            "Train Epoch: 54 [    0/50000 (  0%)]  Loss: 1.066205\n",
            "Train Epoch: 54 [12800/50000 ( 26%)]  Loss: 1.024397\n",
            "Train Epoch: 54 [25600/50000 ( 51%)]  Loss: 0.852790\n",
            "Train Epoch: 54 [38400/50000 ( 77%)]  Loss: 0.950637\n",
            "Test set: Average loss: 0.0078, Accuracy: 32302/50000 (64.60%)\n",
            "Test set: Average loss: 0.0103, Accuracy: 6360/10000 (63.60%)\n",
            "Train Epoch: 55 [    0/50000 (  0%)]  Loss: 1.110507\n",
            "Train Epoch: 55 [12800/50000 ( 26%)]  Loss: 1.036702\n",
            "Train Epoch: 55 [25600/50000 ( 51%)]  Loss: 0.984222\n",
            "Train Epoch: 55 [38400/50000 ( 77%)]  Loss: 0.952827\n",
            "Test set: Average loss: 0.0078, Accuracy: 32176/50000 (64.35%)\n",
            "Test set: Average loss: 0.0104, Accuracy: 6413/10000 (64.13%)\n",
            "Train Epoch: 56 [    0/50000 (  0%)]  Loss: 1.188724\n",
            "Train Epoch: 56 [12800/50000 ( 26%)]  Loss: 1.000404\n",
            "Train Epoch: 56 [25600/50000 ( 51%)]  Loss: 1.028348\n",
            "Train Epoch: 56 [38400/50000 ( 77%)]  Loss: 0.988035\n",
            "Test set: Average loss: 0.0077, Accuracy: 32415/50000 (64.83%)\n",
            "Test set: Average loss: 0.0102, Accuracy: 6423/10000 (64.23%)\n",
            "Train Epoch: 57 [    0/50000 (  0%)]  Loss: 0.983033\n",
            "Train Epoch: 57 [12800/50000 ( 26%)]  Loss: 0.942389\n",
            "Train Epoch: 57 [25600/50000 ( 51%)]  Loss: 0.935704\n",
            "Train Epoch: 57 [38400/50000 ( 77%)]  Loss: 1.051824\n",
            "Test set: Average loss: 0.0078, Accuracy: 32320/50000 (64.64%)\n",
            "Test set: Average loss: 0.0103, Accuracy: 6365/10000 (63.65%)\n",
            "Train Epoch: 58 [    0/50000 (  0%)]  Loss: 1.005647\n",
            "Train Epoch: 58 [12800/50000 ( 26%)]  Loss: 1.006882\n",
            "Train Epoch: 58 [25600/50000 ( 51%)]  Loss: 1.072922\n",
            "Train Epoch: 58 [38400/50000 ( 77%)]  Loss: 1.043638\n",
            "Test set: Average loss: 0.0078, Accuracy: 32407/50000 (64.81%)\n",
            "Test set: Average loss: 0.0103, Accuracy: 6356/10000 (63.56%)\n",
            "Train Epoch: 59 [    0/50000 (  0%)]  Loss: 1.221575\n",
            "Train Epoch: 59 [12800/50000 ( 26%)]  Loss: 1.003483\n",
            "Train Epoch: 59 [25600/50000 ( 51%)]  Loss: 1.138196\n",
            "Train Epoch: 59 [38400/50000 ( 77%)]  Loss: 0.862098\n",
            "Test set: Average loss: 0.0077, Accuracy: 32468/50000 (64.94%)\n",
            "Test set: Average loss: 0.0103, Accuracy: 6374/10000 (63.74%)\n",
            "Train Epoch: 60 [    0/50000 (  0%)]  Loss: 1.062384\n",
            "Train Epoch: 60 [12800/50000 ( 26%)]  Loss: 0.999307\n",
            "Train Epoch: 60 [25600/50000 ( 51%)]  Loss: 0.991120\n",
            "Train Epoch: 60 [38400/50000 ( 77%)]  Loss: 0.926649\n",
            "Test set: Average loss: 0.0077, Accuracy: 32579/50000 (65.16%)\n",
            "Test set: Average loss: 0.0101, Accuracy: 6362/10000 (63.62%)\n",
            "Train Epoch: 61 [    0/50000 (  0%)]  Loss: 0.986342\n",
            "Train Epoch: 61 [12800/50000 ( 26%)]  Loss: 0.992192\n",
            "Train Epoch: 61 [25600/50000 ( 51%)]  Loss: 1.010563\n",
            "Train Epoch: 61 [38400/50000 ( 77%)]  Loss: 0.952089\n",
            "Test set: Average loss: 0.0077, Accuracy: 32420/50000 (64.84%)\n",
            "Test set: Average loss: 0.0103, Accuracy: 6358/10000 (63.58%)\n",
            "Train Epoch: 62 [    0/50000 (  0%)]  Loss: 1.165234\n",
            "Train Epoch: 62 [12800/50000 ( 26%)]  Loss: 1.141195\n",
            "Train Epoch: 62 [25600/50000 ( 51%)]  Loss: 1.059924\n",
            "Train Epoch: 62 [38400/50000 ( 77%)]  Loss: 0.980622\n",
            "Test set: Average loss: 0.0077, Accuracy: 32614/50000 (65.23%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6491/10000 (64.91%)\n",
            "Train Epoch: 63 [    0/50000 (  0%)]  Loss: 1.091556\n",
            "Train Epoch: 63 [12800/50000 ( 26%)]  Loss: 1.136913\n",
            "Train Epoch: 63 [25600/50000 ( 51%)]  Loss: 0.883962\n",
            "Train Epoch: 63 [38400/50000 ( 77%)]  Loss: 1.111804\n",
            "Test set: Average loss: 0.0076, Accuracy: 32633/50000 (65.27%)\n",
            "Test set: Average loss: 0.0102, Accuracy: 6489/10000 (64.89%)\n",
            "Train Epoch: 64 [    0/50000 (  0%)]  Loss: 0.826448\n",
            "Train Epoch: 64 [12800/50000 ( 26%)]  Loss: 0.934091\n",
            "Train Epoch: 64 [25600/50000 ( 51%)]  Loss: 0.895227\n",
            "Train Epoch: 64 [38400/50000 ( 77%)]  Loss: 0.889213\n",
            "Test set: Average loss: 0.0076, Accuracy: 32708/50000 (65.42%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6527/10000 (65.27%)\n",
            "Train Epoch: 65 [    0/50000 (  0%)]  Loss: 1.103202\n",
            "Train Epoch: 65 [12800/50000 ( 26%)]  Loss: 0.953661\n",
            "Train Epoch: 65 [25600/50000 ( 51%)]  Loss: 1.005441\n",
            "Train Epoch: 65 [38400/50000 ( 77%)]  Loss: 1.058801\n",
            "Test set: Average loss: 0.0076, Accuracy: 32739/50000 (65.48%)\n",
            "Test set: Average loss: 0.0101, Accuracy: 6406/10000 (64.06%)\n",
            "Train Epoch: 66 [    0/50000 (  0%)]  Loss: 1.057636\n",
            "Train Epoch: 66 [12800/50000 ( 26%)]  Loss: 0.903979\n",
            "Train Epoch: 66 [25600/50000 ( 51%)]  Loss: 1.003013\n",
            "Train Epoch: 66 [38400/50000 ( 77%)]  Loss: 1.001371\n",
            "Test set: Average loss: 0.0076, Accuracy: 32807/50000 (65.61%)\n",
            "Test set: Average loss: 0.0101, Accuracy: 6474/10000 (64.74%)\n",
            "Train Epoch: 67 [    0/50000 (  0%)]  Loss: 1.045060\n",
            "Train Epoch: 67 [12800/50000 ( 26%)]  Loss: 0.995644\n",
            "Train Epoch: 67 [25600/50000 ( 51%)]  Loss: 1.017072\n",
            "Train Epoch: 67 [38400/50000 ( 77%)]  Loss: 1.109493\n",
            "Test set: Average loss: 0.0075, Accuracy: 32855/50000 (65.71%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6543/10000 (65.43%)\n",
            "Train Epoch: 68 [    0/50000 (  0%)]  Loss: 1.156392\n",
            "Train Epoch: 68 [12800/50000 ( 26%)]  Loss: 0.859848\n",
            "Train Epoch: 68 [25600/50000 ( 51%)]  Loss: 0.867010\n",
            "Train Epoch: 68 [38400/50000 ( 77%)]  Loss: 1.039820\n",
            "Test set: Average loss: 0.0076, Accuracy: 32679/50000 (65.36%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6451/10000 (64.51%)\n",
            "Train Epoch: 69 [    0/50000 (  0%)]  Loss: 0.963619\n",
            "Train Epoch: 69 [12800/50000 ( 26%)]  Loss: 1.051263\n",
            "Train Epoch: 69 [25600/50000 ( 51%)]  Loss: 1.029461\n",
            "Train Epoch: 69 [38400/50000 ( 77%)]  Loss: 1.002586\n",
            "Test set: Average loss: 0.0075, Accuracy: 33053/50000 (66.11%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6491/10000 (64.91%)\n",
            "Train Epoch: 70 [    0/50000 (  0%)]  Loss: 0.965037\n",
            "Train Epoch: 70 [12800/50000 ( 26%)]  Loss: 1.089420\n",
            "Train Epoch: 70 [25600/50000 ( 51%)]  Loss: 1.019706\n",
            "Train Epoch: 70 [38400/50000 ( 77%)]  Loss: 0.973446\n",
            "Test set: Average loss: 0.0076, Accuracy: 32765/50000 (65.53%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6516/10000 (65.16%)\n",
            "Train Epoch: 71 [    0/50000 (  0%)]  Loss: 1.068585\n",
            "Train Epoch: 71 [12800/50000 ( 26%)]  Loss: 0.790222\n",
            "Train Epoch: 71 [25600/50000 ( 51%)]  Loss: 1.146344\n",
            "Train Epoch: 71 [38400/50000 ( 77%)]  Loss: 0.802443\n",
            "Test set: Average loss: 0.0075, Accuracy: 33003/50000 (66.01%)\n",
            "Test set: Average loss: 0.0101, Accuracy: 6488/10000 (64.88%)\n",
            "Train Epoch: 72 [    0/50000 (  0%)]  Loss: 1.046202\n",
            "Train Epoch: 72 [12800/50000 ( 26%)]  Loss: 0.997245\n",
            "Train Epoch: 72 [25600/50000 ( 51%)]  Loss: 0.754709\n",
            "Train Epoch: 72 [38400/50000 ( 77%)]  Loss: 0.945580\n",
            "Test set: Average loss: 0.0074, Accuracy: 33212/50000 (66.42%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6468/10000 (64.68%)\n",
            "Train Epoch: 73 [    0/50000 (  0%)]  Loss: 1.069640\n",
            "Train Epoch: 73 [12800/50000 ( 26%)]  Loss: 0.858742\n",
            "Train Epoch: 73 [25600/50000 ( 51%)]  Loss: 0.934347\n",
            "Train Epoch: 73 [38400/50000 ( 77%)]  Loss: 1.114184\n",
            "Test set: Average loss: 0.0075, Accuracy: 33086/50000 (66.17%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6485/10000 (64.85%)\n",
            "Train Epoch: 74 [    0/50000 (  0%)]  Loss: 0.985928\n",
            "Train Epoch: 74 [12800/50000 ( 26%)]  Loss: 0.977279\n",
            "Train Epoch: 74 [25600/50000 ( 51%)]  Loss: 1.034217\n",
            "Train Epoch: 74 [38400/50000 ( 77%)]  Loss: 1.159927\n",
            "Test set: Average loss: 0.0074, Accuracy: 33146/50000 (66.29%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6471/10000 (64.71%)\n",
            "Train Epoch: 75 [    0/50000 (  0%)]  Loss: 0.804602\n",
            "Train Epoch: 75 [12800/50000 ( 26%)]  Loss: 0.978465\n",
            "Train Epoch: 75 [25600/50000 ( 51%)]  Loss: 0.916436\n",
            "Train Epoch: 75 [38400/50000 ( 77%)]  Loss: 0.819233\n",
            "Test set: Average loss: 0.0074, Accuracy: 33133/50000 (66.27%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6502/10000 (65.02%)\n",
            "Train Epoch: 76 [    0/50000 (  0%)]  Loss: 0.947365\n",
            "Train Epoch: 76 [12800/50000 ( 26%)]  Loss: 0.873999\n",
            "Train Epoch: 76 [25600/50000 ( 51%)]  Loss: 0.814669\n",
            "Train Epoch: 76 [38400/50000 ( 77%)]  Loss: 1.060480\n",
            "Test set: Average loss: 0.0075, Accuracy: 32897/50000 (65.79%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6509/10000 (65.09%)\n",
            "Train Epoch: 77 [    0/50000 (  0%)]  Loss: 1.009367\n",
            "Train Epoch: 77 [12800/50000 ( 26%)]  Loss: 0.923004\n",
            "Train Epoch: 77 [25600/50000 ( 51%)]  Loss: 1.046344\n",
            "Train Epoch: 77 [38400/50000 ( 77%)]  Loss: 0.884677\n",
            "Test set: Average loss: 0.0074, Accuracy: 32920/50000 (65.84%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6487/10000 (64.87%)\n",
            "Train Epoch: 78 [    0/50000 (  0%)]  Loss: 0.931433\n",
            "Train Epoch: 78 [12800/50000 ( 26%)]  Loss: 0.941696\n",
            "Train Epoch: 78 [25600/50000 ( 51%)]  Loss: 0.756139\n",
            "Train Epoch: 78 [38400/50000 ( 77%)]  Loss: 1.241746\n",
            "Test set: Average loss: 0.0074, Accuracy: 33251/50000 (66.50%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6554/10000 (65.54%)\n",
            "Train Epoch: 79 [    0/50000 (  0%)]  Loss: 0.852658\n",
            "Train Epoch: 79 [12800/50000 ( 26%)]  Loss: 0.924763\n",
            "Train Epoch: 79 [25600/50000 ( 51%)]  Loss: 0.942495\n",
            "Train Epoch: 79 [38400/50000 ( 77%)]  Loss: 0.954869\n",
            "Test set: Average loss: 0.0074, Accuracy: 33233/50000 (66.47%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6478/10000 (64.78%)\n",
            "Train Epoch: 80 [    0/50000 (  0%)]  Loss: 1.075119\n",
            "Train Epoch: 80 [12800/50000 ( 26%)]  Loss: 1.036582\n",
            "Train Epoch: 80 [25600/50000 ( 51%)]  Loss: 0.906247\n",
            "Train Epoch: 80 [38400/50000 ( 77%)]  Loss: 0.812499\n",
            "Test set: Average loss: 0.0073, Accuracy: 33314/50000 (66.63%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6531/10000 (65.31%)\n",
            "Train Epoch: 81 [    0/50000 (  0%)]  Loss: 0.977565\n",
            "Train Epoch: 81 [12800/50000 ( 26%)]  Loss: 0.870054\n",
            "Train Epoch: 81 [25600/50000 ( 51%)]  Loss: 0.857418\n",
            "Train Epoch: 81 [38400/50000 ( 77%)]  Loss: 0.904272\n",
            "Test set: Average loss: 0.0074, Accuracy: 33152/50000 (66.30%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6527/10000 (65.27%)\n",
            "Train Epoch: 82 [    0/50000 (  0%)]  Loss: 0.964146\n",
            "Train Epoch: 82 [12800/50000 ( 26%)]  Loss: 0.960810\n",
            "Train Epoch: 82 [25600/50000 ( 51%)]  Loss: 0.922262\n",
            "Train Epoch: 82 [38400/50000 ( 77%)]  Loss: 0.889789\n",
            "Test set: Average loss: 0.0074, Accuracy: 33288/50000 (66.58%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6529/10000 (65.29%)\n",
            "Train Epoch: 83 [    0/50000 (  0%)]  Loss: 1.004996\n",
            "Train Epoch: 83 [12800/50000 ( 26%)]  Loss: 1.073944\n",
            "Train Epoch: 83 [25600/50000 ( 51%)]  Loss: 0.891395\n",
            "Train Epoch: 83 [38400/50000 ( 77%)]  Loss: 1.000604\n",
            "Test set: Average loss: 0.0074, Accuracy: 33116/50000 (66.23%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6540/10000 (65.40%)\n",
            "Train Epoch: 84 [    0/50000 (  0%)]  Loss: 0.882347\n",
            "Train Epoch: 84 [12800/50000 ( 26%)]  Loss: 1.048631\n",
            "Train Epoch: 84 [25600/50000 ( 51%)]  Loss: 0.699180\n",
            "Train Epoch: 84 [38400/50000 ( 77%)]  Loss: 1.102788\n",
            "Test set: Average loss: 0.0073, Accuracy: 33397/50000 (66.79%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6533/10000 (65.33%)\n",
            "Train Epoch: 85 [    0/50000 (  0%)]  Loss: 1.062422\n",
            "Train Epoch: 85 [12800/50000 ( 26%)]  Loss: 0.861747\n",
            "Train Epoch: 85 [25600/50000 ( 51%)]  Loss: 1.025133\n",
            "Train Epoch: 85 [38400/50000 ( 77%)]  Loss: 0.951212\n",
            "Test set: Average loss: 0.0073, Accuracy: 33483/50000 (66.97%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6633/10000 (66.33%)\n",
            "Train Epoch: 86 [    0/50000 (  0%)]  Loss: 0.927888\n",
            "Train Epoch: 86 [12800/50000 ( 26%)]  Loss: 0.904762\n",
            "Train Epoch: 86 [25600/50000 ( 51%)]  Loss: 0.950766\n",
            "Train Epoch: 86 [38400/50000 ( 77%)]  Loss: 0.868892\n",
            "Test set: Average loss: 0.0072, Accuracy: 33487/50000 (66.97%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6567/10000 (65.67%)\n",
            "Train Epoch: 87 [    0/50000 (  0%)]  Loss: 1.051545\n",
            "Train Epoch: 87 [12800/50000 ( 26%)]  Loss: 1.070194\n",
            "Train Epoch: 87 [25600/50000 ( 51%)]  Loss: 1.035250\n",
            "Train Epoch: 87 [38400/50000 ( 77%)]  Loss: 0.803139\n",
            "Test set: Average loss: 0.0073, Accuracy: 33528/50000 (67.06%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6571/10000 (65.71%)\n",
            "Train Epoch: 88 [    0/50000 (  0%)]  Loss: 0.765967\n",
            "Train Epoch: 88 [12800/50000 ( 26%)]  Loss: 0.936454\n",
            "Train Epoch: 88 [25600/50000 ( 51%)]  Loss: 0.882868\n",
            "Train Epoch: 88 [38400/50000 ( 77%)]  Loss: 0.877807\n",
            "Test set: Average loss: 0.0072, Accuracy: 33556/50000 (67.11%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6565/10000 (65.65%)\n",
            "Train Epoch: 89 [    0/50000 (  0%)]  Loss: 0.886292\n",
            "Train Epoch: 89 [12800/50000 ( 26%)]  Loss: 1.150183\n",
            "Train Epoch: 89 [25600/50000 ( 51%)]  Loss: 0.951342\n",
            "Train Epoch: 89 [38400/50000 ( 77%)]  Loss: 0.913005\n",
            "Test set: Average loss: 0.0072, Accuracy: 33564/50000 (67.13%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6627/10000 (66.27%)\n",
            "Train Epoch: 90 [    0/50000 (  0%)]  Loss: 0.944688\n",
            "Train Epoch: 90 [12800/50000 ( 26%)]  Loss: 0.856542\n",
            "Train Epoch: 90 [25600/50000 ( 51%)]  Loss: 0.937541\n",
            "Train Epoch: 90 [38400/50000 ( 77%)]  Loss: 0.833084\n",
            "Test set: Average loss: 0.0072, Accuracy: 33618/50000 (67.24%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6578/10000 (65.78%)\n",
            "Train Epoch: 91 [    0/50000 (  0%)]  Loss: 1.089860\n",
            "Train Epoch: 91 [12800/50000 ( 26%)]  Loss: 0.745088\n",
            "Train Epoch: 91 [25600/50000 ( 51%)]  Loss: 0.737761\n",
            "Train Epoch: 91 [38400/50000 ( 77%)]  Loss: 1.007733\n",
            "Test set: Average loss: 0.0072, Accuracy: 33555/50000 (67.11%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6563/10000 (65.63%)\n",
            "Train Epoch: 92 [    0/50000 (  0%)]  Loss: 1.146126\n",
            "Train Epoch: 92 [12800/50000 ( 26%)]  Loss: 0.747217\n",
            "Train Epoch: 92 [25600/50000 ( 51%)]  Loss: 0.940238\n",
            "Train Epoch: 92 [38400/50000 ( 77%)]  Loss: 1.119555\n",
            "Test set: Average loss: 0.0073, Accuracy: 33356/50000 (66.71%)\n",
            "Test set: Average loss: 0.0100, Accuracy: 6602/10000 (66.02%)\n",
            "Train Epoch: 93 [    0/50000 (  0%)]  Loss: 0.855495\n",
            "Train Epoch: 93 [12800/50000 ( 26%)]  Loss: 0.886848\n",
            "Train Epoch: 93 [25600/50000 ( 51%)]  Loss: 1.032107\n",
            "Train Epoch: 93 [38400/50000 ( 77%)]  Loss: 0.986070\n",
            "Test set: Average loss: 0.0072, Accuracy: 33746/50000 (67.49%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6641/10000 (66.41%)\n",
            "Train Epoch: 94 [    0/50000 (  0%)]  Loss: 0.800129\n",
            "Train Epoch: 94 [12800/50000 ( 26%)]  Loss: 0.976484\n",
            "Train Epoch: 94 [25600/50000 ( 51%)]  Loss: 1.018625\n",
            "Train Epoch: 94 [38400/50000 ( 77%)]  Loss: 0.981452\n",
            "Test set: Average loss: 0.0072, Accuracy: 33693/50000 (67.39%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6586/10000 (65.86%)\n",
            "Train Epoch: 95 [    0/50000 (  0%)]  Loss: 0.869804\n",
            "Train Epoch: 95 [12800/50000 ( 26%)]  Loss: 1.053512\n",
            "Train Epoch: 95 [25600/50000 ( 51%)]  Loss: 0.967951\n",
            "Train Epoch: 95 [38400/50000 ( 77%)]  Loss: 0.692538\n",
            "Test set: Average loss: 0.0072, Accuracy: 33617/50000 (67.23%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6547/10000 (65.47%)\n",
            "Train Epoch: 96 [    0/50000 (  0%)]  Loss: 1.029898\n",
            "Train Epoch: 96 [12800/50000 ( 26%)]  Loss: 0.852232\n",
            "Train Epoch: 96 [25600/50000 ( 51%)]  Loss: 0.940179\n",
            "Train Epoch: 96 [38400/50000 ( 77%)]  Loss: 0.893946\n",
            "Test set: Average loss: 0.0071, Accuracy: 33799/50000 (67.60%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6597/10000 (65.97%)\n",
            "Train Epoch: 97 [    0/50000 (  0%)]  Loss: 1.014008\n",
            "Train Epoch: 97 [12800/50000 ( 26%)]  Loss: 0.955572\n",
            "Train Epoch: 97 [25600/50000 ( 51%)]  Loss: 0.935680\n",
            "Train Epoch: 97 [38400/50000 ( 77%)]  Loss: 0.989821\n",
            "Test set: Average loss: 0.0072, Accuracy: 33703/50000 (67.41%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6524/10000 (65.24%)\n",
            "Train Epoch: 98 [    0/50000 (  0%)]  Loss: 0.974015\n",
            "Train Epoch: 98 [12800/50000 ( 26%)]  Loss: 0.937012\n",
            "Train Epoch: 98 [25600/50000 ( 51%)]  Loss: 0.845315\n",
            "Train Epoch: 98 [38400/50000 ( 77%)]  Loss: 0.899581\n",
            "Test set: Average loss: 0.0071, Accuracy: 33756/50000 (67.51%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6591/10000 (65.91%)\n",
            "Train Epoch: 99 [    0/50000 (  0%)]  Loss: 0.883763\n",
            "Train Epoch: 99 [12800/50000 ( 26%)]  Loss: 0.965539\n",
            "Train Epoch: 99 [25600/50000 ( 51%)]  Loss: 0.948647\n",
            "Train Epoch: 99 [38400/50000 ( 77%)]  Loss: 0.985298\n",
            "Test set: Average loss: 0.0071, Accuracy: 33793/50000 (67.59%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6561/10000 (65.61%)\n",
            "Train Epoch: 100 [    0/50000 (  0%)]  Loss: 0.766211\n",
            "Train Epoch: 100 [12800/50000 ( 26%)]  Loss: 0.950952\n",
            "Train Epoch: 100 [25600/50000 ( 51%)]  Loss: 0.888528\n",
            "Train Epoch: 100 [38400/50000 ( 77%)]  Loss: 1.089843\n",
            "Test set: Average loss: 0.0071, Accuracy: 33875/50000 (67.75%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6592/10000 (65.92%)\n",
            "Train Epoch: 101 [    0/50000 (  0%)]  Loss: 0.925935\n",
            "Train Epoch: 101 [12800/50000 ( 26%)]  Loss: 0.854089\n",
            "Train Epoch: 101 [25600/50000 ( 51%)]  Loss: 0.874057\n",
            "Train Epoch: 101 [38400/50000 ( 77%)]  Loss: 1.077505\n",
            "Test set: Average loss: 0.0071, Accuracy: 33862/50000 (67.72%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6581/10000 (65.81%)\n",
            "Train Epoch: 102 [    0/50000 (  0%)]  Loss: 0.930283\n",
            "Train Epoch: 102 [12800/50000 ( 26%)]  Loss: 0.870789\n",
            "Train Epoch: 102 [25600/50000 ( 51%)]  Loss: 0.998904\n",
            "Train Epoch: 102 [38400/50000 ( 77%)]  Loss: 0.893881\n",
            "Test set: Average loss: 0.0071, Accuracy: 33881/50000 (67.76%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6610/10000 (66.10%)\n",
            "Train Epoch: 103 [    0/50000 (  0%)]  Loss: 1.033736\n",
            "Train Epoch: 103 [12800/50000 ( 26%)]  Loss: 0.912523\n",
            "Train Epoch: 103 [25600/50000 ( 51%)]  Loss: 0.955002\n",
            "Train Epoch: 103 [38400/50000 ( 77%)]  Loss: 0.875410\n",
            "Test set: Average loss: 0.0071, Accuracy: 33765/50000 (67.53%)\n",
            "Test set: Average loss: 0.0099, Accuracy: 6547/10000 (65.47%)\n",
            "Train Epoch: 104 [    0/50000 (  0%)]  Loss: 0.981059\n",
            "Train Epoch: 104 [12800/50000 ( 26%)]  Loss: 0.873085\n",
            "Train Epoch: 104 [25600/50000 ( 51%)]  Loss: 0.920680\n",
            "Train Epoch: 104 [38400/50000 ( 77%)]  Loss: 0.803129\n",
            "Test set: Average loss: 0.0071, Accuracy: 33727/50000 (67.45%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6614/10000 (66.14%)\n",
            "Train Epoch: 105 [    0/50000 (  0%)]  Loss: 0.962262\n",
            "Train Epoch: 105 [12800/50000 ( 26%)]  Loss: 0.955127\n",
            "Train Epoch: 105 [25600/50000 ( 51%)]  Loss: 0.921017\n",
            "Train Epoch: 105 [38400/50000 ( 77%)]  Loss: 0.858650\n",
            "Test set: Average loss: 0.0071, Accuracy: 33825/50000 (67.65%)\n",
            "Test set: Average loss: 0.0098, Accuracy: 6582/10000 (65.82%)\n",
            "Train Epoch: 106 [    0/50000 (  0%)]  Loss: 0.885001\n",
            "Train Epoch: 106 [12800/50000 ( 26%)]  Loss: 0.988043\n",
            "Train Epoch: 106 [25600/50000 ( 51%)]  Loss: 1.066106\n",
            "Train Epoch: 106 [38400/50000 ( 77%)]  Loss: 1.001858\n",
            "Test set: Average loss: 0.0071, Accuracy: 33876/50000 (67.75%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6637/10000 (66.37%)\n",
            "Train Epoch: 107 [    0/50000 (  0%)]  Loss: 0.951298\n",
            "Train Epoch: 107 [12800/50000 ( 26%)]  Loss: 0.831453\n",
            "Train Epoch: 107 [25600/50000 ( 51%)]  Loss: 0.889665\n",
            "Train Epoch: 107 [38400/50000 ( 77%)]  Loss: 1.020455\n",
            "Test set: Average loss: 0.0070, Accuracy: 33959/50000 (67.92%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6674/10000 (66.74%)\n",
            "Train Epoch: 108 [    0/50000 (  0%)]  Loss: 0.821254\n",
            "Train Epoch: 108 [12800/50000 ( 26%)]  Loss: 0.702017\n",
            "Train Epoch: 108 [25600/50000 ( 51%)]  Loss: 0.958377\n",
            "Train Epoch: 108 [38400/50000 ( 77%)]  Loss: 0.953951\n",
            "Test set: Average loss: 0.0070, Accuracy: 34081/50000 (68.16%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6622/10000 (66.22%)\n",
            "Train Epoch: 109 [    0/50000 (  0%)]  Loss: 0.803674\n",
            "Train Epoch: 109 [12800/50000 ( 26%)]  Loss: 0.869790\n",
            "Train Epoch: 109 [25600/50000 ( 51%)]  Loss: 0.932342\n",
            "Train Epoch: 109 [38400/50000 ( 77%)]  Loss: 0.767101\n",
            "Test set: Average loss: 0.0071, Accuracy: 34019/50000 (68.04%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6648/10000 (66.48%)\n",
            "Train Epoch: 110 [    0/50000 (  0%)]  Loss: 0.932009\n",
            "Train Epoch: 110 [12800/50000 ( 26%)]  Loss: 1.035827\n",
            "Train Epoch: 110 [25600/50000 ( 51%)]  Loss: 0.997260\n",
            "Train Epoch: 110 [38400/50000 ( 77%)]  Loss: 0.909840\n",
            "Test set: Average loss: 0.0070, Accuracy: 33956/50000 (67.91%)\n",
            "Test set: Average loss: 0.0095, Accuracy: 6674/10000 (66.74%)\n",
            "Train Epoch: 111 [    0/50000 (  0%)]  Loss: 0.892651\n",
            "Train Epoch: 111 [12800/50000 ( 26%)]  Loss: 0.849016\n",
            "Train Epoch: 111 [25600/50000 ( 51%)]  Loss: 0.898636\n",
            "Train Epoch: 111 [38400/50000 ( 77%)]  Loss: 0.894324\n",
            "Test set: Average loss: 0.0071, Accuracy: 33874/50000 (67.75%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6628/10000 (66.28%)\n",
            "Train Epoch: 112 [    0/50000 (  0%)]  Loss: 1.086300\n",
            "Train Epoch: 112 [12800/50000 ( 26%)]  Loss: 0.909814\n",
            "Train Epoch: 112 [25600/50000 ( 51%)]  Loss: 0.985101\n",
            "Train Epoch: 112 [38400/50000 ( 77%)]  Loss: 0.836287\n",
            "Test set: Average loss: 0.0070, Accuracy: 34119/50000 (68.24%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6641/10000 (66.41%)\n",
            "Train Epoch: 113 [    0/50000 (  0%)]  Loss: 1.109302\n",
            "Train Epoch: 113 [12800/50000 ( 26%)]  Loss: 0.813762\n",
            "Train Epoch: 113 [25600/50000 ( 51%)]  Loss: 0.873446\n",
            "Train Epoch: 113 [38400/50000 ( 77%)]  Loss: 0.962390\n",
            "Test set: Average loss: 0.0070, Accuracy: 34165/50000 (68.33%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6681/10000 (66.81%)\n",
            "Train Epoch: 114 [    0/50000 (  0%)]  Loss: 0.929254\n",
            "Train Epoch: 114 [12800/50000 ( 26%)]  Loss: 0.930531\n",
            "Train Epoch: 114 [25600/50000 ( 51%)]  Loss: 0.869485\n",
            "Train Epoch: 114 [38400/50000 ( 77%)]  Loss: 0.858607\n",
            "Test set: Average loss: 0.0069, Accuracy: 34202/50000 (68.40%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6620/10000 (66.20%)\n",
            "Train Epoch: 115 [    0/50000 (  0%)]  Loss: 1.186753\n",
            "Train Epoch: 115 [12800/50000 ( 26%)]  Loss: 0.820361\n",
            "Train Epoch: 115 [25600/50000 ( 51%)]  Loss: 0.972807\n",
            "Train Epoch: 115 [38400/50000 ( 77%)]  Loss: 0.886802\n",
            "Test set: Average loss: 0.0069, Accuracy: 34218/50000 (68.44%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6689/10000 (66.89%)\n",
            "Train Epoch: 116 [    0/50000 (  0%)]  Loss: 0.906505\n",
            "Train Epoch: 116 [12800/50000 ( 26%)]  Loss: 1.210785\n",
            "Train Epoch: 116 [25600/50000 ( 51%)]  Loss: 0.719828\n",
            "Train Epoch: 116 [38400/50000 ( 77%)]  Loss: 0.903603\n",
            "Test set: Average loss: 0.0069, Accuracy: 34289/50000 (68.58%)\n",
            "Test set: Average loss: 0.0095, Accuracy: 6685/10000 (66.85%)\n",
            "Train Epoch: 117 [    0/50000 (  0%)]  Loss: 0.919232\n",
            "Train Epoch: 117 [12800/50000 ( 26%)]  Loss: 1.021920\n",
            "Train Epoch: 117 [25600/50000 ( 51%)]  Loss: 0.793164\n",
            "Train Epoch: 117 [38400/50000 ( 77%)]  Loss: 0.913268\n",
            "Test set: Average loss: 0.0070, Accuracy: 34160/50000 (68.32%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6630/10000 (66.30%)\n",
            "Train Epoch: 118 [    0/50000 (  0%)]  Loss: 0.875328\n",
            "Train Epoch: 118 [12800/50000 ( 26%)]  Loss: 0.688228\n",
            "Train Epoch: 118 [25600/50000 ( 51%)]  Loss: 0.902882\n",
            "Train Epoch: 118 [38400/50000 ( 77%)]  Loss: 0.845395\n",
            "Test set: Average loss: 0.0070, Accuracy: 34152/50000 (68.30%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6618/10000 (66.18%)\n",
            "Train Epoch: 119 [    0/50000 (  0%)]  Loss: 0.895119\n",
            "Train Epoch: 119 [12800/50000 ( 26%)]  Loss: 0.939650\n",
            "Train Epoch: 119 [25600/50000 ( 51%)]  Loss: 0.989616\n",
            "Train Epoch: 119 [38400/50000 ( 77%)]  Loss: 0.937275\n",
            "Test set: Average loss: 0.0070, Accuracy: 34012/50000 (68.02%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6608/10000 (66.08%)\n",
            "Train Epoch: 120 [    0/50000 (  0%)]  Loss: 0.871876\n",
            "Train Epoch: 120 [12800/50000 ( 26%)]  Loss: 0.883015\n",
            "Train Epoch: 120 [25600/50000 ( 51%)]  Loss: 0.846907\n",
            "Train Epoch: 120 [38400/50000 ( 77%)]  Loss: 0.858348\n",
            "Test set: Average loss: 0.0070, Accuracy: 34107/50000 (68.21%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6654/10000 (66.54%)\n",
            "Train Epoch: 121 [    0/50000 (  0%)]  Loss: 0.833476\n",
            "Train Epoch: 121 [12800/50000 ( 26%)]  Loss: 0.956035\n",
            "Train Epoch: 121 [25600/50000 ( 51%)]  Loss: 0.963707\n",
            "Train Epoch: 121 [38400/50000 ( 77%)]  Loss: 0.844241\n",
            "Test set: Average loss: 0.0069, Accuracy: 34224/50000 (68.45%)\n",
            "Test set: Average loss: 0.0097, Accuracy: 6598/10000 (65.98%)\n",
            "Train Epoch: 122 [    0/50000 (  0%)]  Loss: 1.010956\n",
            "Train Epoch: 122 [12800/50000 ( 26%)]  Loss: 0.807184\n",
            "Train Epoch: 122 [25600/50000 ( 51%)]  Loss: 0.911287\n",
            "Train Epoch: 122 [38400/50000 ( 77%)]  Loss: 0.999157\n",
            "Test set: Average loss: 0.0069, Accuracy: 34320/50000 (68.64%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6656/10000 (66.56%)\n",
            "Train Epoch: 123 [    0/50000 (  0%)]  Loss: 0.910825\n",
            "Train Epoch: 123 [12800/50000 ( 26%)]  Loss: 0.980282\n",
            "Train Epoch: 123 [25600/50000 ( 51%)]  Loss: 0.906902\n",
            "Train Epoch: 123 [38400/50000 ( 77%)]  Loss: 0.900017\n",
            "Test set: Average loss: 0.0069, Accuracy: 34336/50000 (68.67%)\n",
            "Test set: Average loss: 0.0095, Accuracy: 6700/10000 (67.00%)\n",
            "Train Epoch: 124 [    0/50000 (  0%)]  Loss: 1.019085\n",
            "Train Epoch: 124 [12800/50000 ( 26%)]  Loss: 0.619773\n",
            "Train Epoch: 124 [25600/50000 ( 51%)]  Loss: 0.741268\n",
            "Train Epoch: 124 [38400/50000 ( 77%)]  Loss: 0.955026\n",
            "Test set: Average loss: 0.0069, Accuracy: 34413/50000 (68.83%)\n",
            "Test set: Average loss: 0.0096, Accuracy: 6680/10000 (66.80%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXDAzxwFewV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def softmax_by_row(logits, T = 1.0):\n",
        "    mx = np.max(logits, axis=-1, keepdims=True)\n",
        "    exp = np.exp((logits - mx)/T)\n",
        "    denominator = np.sum(exp, axis=-1, keepdims=True)\n",
        "    return exp/denominator\n",
        "\n",
        "def classifier_performance(model, train_loader, test_loader):\n",
        "\n",
        "    output_train_benign = []\n",
        "    train_label = []\n",
        "    for num, data in enumerate(train_loader):\n",
        "        images,labels = data\n",
        "        image_tensor= images.to(device)\n",
        "        img_variable = Variable(image_tensor, requires_grad=True)\n",
        "        output = model.forward(img_variable)\n",
        "\n",
        "        train_label.append(labels.numpy())\n",
        "        output_train_benign.append(softmax_by_row(output.data.cpu().numpy(),T = 1))\n",
        "\n",
        "\n",
        "    train_label = np.concatenate(train_label)\n",
        "    output_train_benign=np.concatenate(output_train_benign)\n",
        "\n",
        "    test_label = []\n",
        "    output_test_benign = []\n",
        "\n",
        "    for num, data in enumerate(test_loader):\n",
        "        images,labels = data\n",
        "\n",
        "        image_tensor= images.to(device)\n",
        "        img_variable = Variable(image_tensor, requires_grad=True)\n",
        "\n",
        "        output = model.forward(img_variable)\n",
        "\n",
        "        test_label.append(labels.numpy())\n",
        "        output_test_benign.append(softmax_by_row(output.data.cpu().numpy(),T = 1))\n",
        "\n",
        "\n",
        "    test_label = np.concatenate(test_label)\n",
        "    output_test_benign=np.concatenate(output_test_benign)\n",
        "\n",
        "\n",
        "    train_acc1 = np.sum(np.argmax(output_train_benign,axis=1) == train_label.flatten())/len(train_label)\n",
        "    test_acc1 = np.sum(np.argmax(output_test_benign,axis=1) == test_label.flatten())/len(test_label)\n",
        "\n",
        "    print('Accuracy: ', (train_acc1, test_acc1))\n",
        "\n",
        "    return output_train_benign, output_test_benign, train_label, test_label\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def inference_via_confidence(confidence_mtx1, confidence_mtx2, label_vec1, label_vec2):\n",
        "    \n",
        "    #----------------First step: obtain confidence lists for both training dataset and test dataset--------------\n",
        "    confidence1 = []\n",
        "    confidence2 = []\n",
        "    acc1 = 0\n",
        "    acc2 = 0\n",
        "    for num in range(confidence_mtx1.shape[0]):\n",
        "        confidence1.append(confidence_mtx1[num,label_vec1[num]])\n",
        "        if np.argmax(confidence_mtx1[num,:]) == label_vec1[num]:\n",
        "            acc1 += 1\n",
        "            \n",
        "    for num in range(confidence_mtx2.shape[0]):\n",
        "        confidence2.append(confidence_mtx2[num,label_vec2[num]])\n",
        "        if np.argmax(confidence_mtx2[num,:]) == label_vec2[num]:\n",
        "            acc2 += 1\n",
        "    confidence1 = np.array(confidence1)\n",
        "    confidence2 = np.array(confidence2)\n",
        "    \n",
        "    print('model accuracy for training and test-', (acc1/confidence_mtx1.shape[0], acc2/confidence_mtx2.shape[0]) )\n",
        "    \n",
        "    \n",
        "    #sort_confidence = np.sort(confidence1)\n",
        "    sort_confidence = np.sort(np.concatenate((confidence1, confidence2)))\n",
        "    max_accuracy = 0.5\n",
        "    best_precision = 0.5\n",
        "    best_recall = 0.5\n",
        "    for num in range(len(sort_confidence)):\n",
        "        delta = sort_confidence[num]\n",
        "        ratio1 = np.sum(confidence1>=delta)/confidence_mtx1.shape[0]\n",
        "        ratio2 = np.sum(confidence2>=delta)/confidence_mtx2.shape[0]\n",
        "        accuracy_now = 0.5*(ratio1+1-ratio2)\n",
        "        if accuracy_now > max_accuracy:\n",
        "            max_accuracy = accuracy_now\n",
        "            best_precision = ratio1/(ratio1+ratio2)\n",
        "            best_recall = ratio1\n",
        "    print('membership inference accuracy is:', max_accuracy)\n",
        "    return max_accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-O0GyDrezes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "fd2ea819-ed7d-43e9-efbe-a23dbd80403f"
      },
      "source": [
        "from torch.autograd import Variable\n",
        "import os\n",
        "import numpy as np\n",
        "import math \n",
        "import scipy\n",
        "import sys  \n",
        "\n",
        "output_train, output_test, train_label, test_label = classifier_performance(model, trainloader, testloader)\n",
        "inference_accuracy=inference_via_confidence(output_train, output_test, train_label, test_label)\n",
        "print(\"Maximum Accuracy:\",inference_accuracy)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  (0.68628, 0.668)\n",
            "model accuracy for training and test- (0.68628, 0.668)\n",
            "membership inference accuracy is: 0.5140100000000001\n",
            "Maximum Accuracy: 0.5140100000000001\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}