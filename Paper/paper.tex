\documentclass[sigconf]{acmart}

\settopmatter{printacmref=false} % Removes citation information below abstract
\renewcommand\footnotetextcopyrightpermission[1]{} % removes footnote with conference information in first column
\pagestyle{plain} % removes running headers

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{multirow}
\usepackage{colortbl}
\usepackage[most]{tcolorbox}
\usepackage{dblfloatfix}
\usepackage{pifont}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{enumitem}
\usepackage{subfigure}
\usepackage{wasysym}
\usepackage{xspace}
\usetikzlibrary{backgrounds, positioning, fit}
\usetikzlibrary{shapes.geometric}
\usepackage{amsmath}
\usetikzlibrary{patterns}
\usetikzlibrary{pgfplots.groupplots}
\newcommand{\ballnumber}[1]{\tikz[baseline=(myanchor.base)] \node[circle,fill=.,inner sep=1pt] (myanchor) {\color{-.}\bfseries\footnotesize #1};}
\newcommand{\method}{{\scshape Gecko}}
%\newcommand{\method}{{\textsc{Gecko}\xspace}}
\newcommand{\cmark}{\CIRCLE}
\newcommand{\xmark}{\Circle}
\newcommand{\smark}{\LEFTcircle}


\begin{filecontents}{comparedef.txt}
z   n   pFA pFB
10  FP   98.16   86.16
10  AdvReg   87.48   83.66
10  DP   92.80   85.11
10  Gecko   90.49   83.52
20  {}  0   0
20  FP   97.86   80.34
20  AdvReg   73.97  71.02
20  DP   84.76  79.27
20  Gecko   76.79  73.5
30  {}  0   0
30  DP   99.58  88.95
30  AdvReg   89.09  85.19
30  DP   90.46  84.91
30  Gecko   93.45  85.8
\end{filecontents}

\begin{document}

\title{GECKO: Reconciling Privacy, Accuracy and Efficiency in Embedded Deep Learning}

\author{.}
%\author{Vasisht Duddu$^1$, Virat Shejwalkar$^2$, Antoine Boutet$^1$}
%\affiliation{\institution{$^1$ \large Univ Lyon, INSA Lyon, Inria, CITI \\ $^2$ \large University of Massachusetts Amherst}}
%\email{vduddu@tutamail.com, vshejwalkar@cs.umass.edu, antoine.boutet@insa-lyon.fr}


\begin{abstract}
Embedded systems demand on-device processing of data using Neural Networks while conforming to the memory, power and computation constraints, leading to an efficiency and accuracy tradeoff.
In order to bring Neural Networks to edge devices, several state of the art optimizations such as model compression through \textit{pruning}, \textit{quantization}, and \textit{off-the-shelf architectures} with efficient design have been extensively adopted.
These algorithms when deployed to real world sensitive applications, such as healthcare monitoring wearables, requires to resist inference attacks to protect privacy of user's training data.
However, resistance against inference attacks is not accounted for designing NN models for embedded systems.
In this work, we analyse the three-dimensional \textit{privacy-accuracy-efficiency} tradeoff in Neural Networks for embedded systems and propose \method\hspace{0.02in} training methodology where we explicitly add resistance to private inferences as a design objective of Neural Networks.
We use the inference-time memory, computation and power constraints of embedded devices as a criterion for designing Neural Network architecture while preserving privacy (captured through membership inference attack where the adversary aims to infer whether a given data point was a member of the model's training data or not).
Given the flexibility of modifying a model during training, we choose quantization as our design choice for highly efficient and private models.
This choice is driven by the observation that compressed models leak more information compared to baseline models while off-the-shelf efficient architectures indicate poor efficiency and privacy trade-off.
We show that models trained using \method\hspace{0.02in} methodology are comparable to prior state of the art defences against blackbox membership inference attacks in terms of test accuracy and privacy while additionally providing efficiency.
\end{abstract}
\keywords{Membership Privacy, Inference Attacks, Efficient Deep Learning, Embedded Computing.}

\maketitle


\input{introduction}
\input{background}
\input{design2}
%\input{analysis}
\input{setting}
%\input{motivation}
\input{evaluation}
\input{related}
\input{conclusions}


%{\footnotesize
%\bibliographystyle{IEEEtranS}
%\bibliography{paper.bib}
%}

\bibliographystyle{ACM-Reference-Format}
\bibliography{paper}

\input{appendix}


\end{document}
\endinput
