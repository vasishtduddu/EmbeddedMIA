\section{Parameter Distribution and Privacy Leakage}


Pruning modifies the parameter distribution by each parameter storing more information compared to prior models.
Quantization restricts the parameter values to a set of values and hence removes the gaussian distribution of the model.
Overfitting indicates a higher standard deviaiton for the parameter distribution compared to regularized model.
For instance, parameter distribution of L2 regularized models and differential privacy show lower standard deviation.
hence, Overfitting is a specific case of modifying parameter distribution and Membership Privacy Leakage is better explained using parameter distribution which is a more fundamental reason to influence model leakge.
