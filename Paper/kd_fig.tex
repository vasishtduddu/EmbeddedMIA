\pgfdeclarelayer{background}
\pgfdeclarelayer{foreground}
\pgfsetlayers{background,main,foreground}


\tikzstyle{input} = [rectangle, rounded corners, minimum width=0.5cm, minimum height=3cm,text centered, draw=black, fill=gray!15]
\tikzstyle{layer11} = [rectangle, rounded corners, minimum width=0.25cm, minimum height=4.5cm,text centered, draw=black, fill=gray!15]
\tikzstyle{layer12} = [rectangle, rounded corners, minimum width=0.25cm, minimum height=3.5cm,text centered, draw=black, fill=gray!15]
\tikzstyle{layer13} = [rectangle, rounded corners, minimum width=0.25cm, minimum height=2.5cm,text centered, draw=black, fill=gray!15]
\tikzstyle{layer14} = [rectangle, rounded corners, minimum width=0.25cm, minimum height=1.5cm,text centered, draw=black, fill=gray!15]



\tikzstyle{input} = [rectangle, rounded corners, minimum width=0.5cm, minimum height=3cm,text centered, draw=black, fill=gray!15]
\tikzstyle{layer1} = [rectangle, rounded corners, minimum width=0.25cm, minimum height=3cm,text centered, draw=black, fill=gray!15]
\tikzstyle{layer2} = [rectangle, rounded corners, minimum width=0.25cm, minimum height=2cm,text centered, draw=black, fill=gray!15]
\tikzstyle{layer3} = [rectangle, rounded corners, minimum width=0.25cm, minimum height=1.5cm,text centered, draw=black, fill=gray!15]
\tikzstyle{layer4} = [rectangle, rounded corners, minimum width=0.25cm, minimum height=1cm,text centered, draw=black, fill=gray!15]
\tikzstyle{write} = [rectangle, rounded corners, minimum width=2.5cm, minimum height=1.5cm,text centered, draw=black, fill=gray!15]
\tikzstyle{neuron}=[circle,draw=black, fill=gray!15,minimum size=8pt,inner sep=0pt]
\tikzstyle{hidden neuron}=[neuron, draw=black, fill=gray!15]
\tikzstyle{output neuron}=[neuron, draw=black, fill=gray!15]

\begin{figure}[!htb]
\centering
\resizebox{\columnwidth}{!}{%
\begin{tikzpicture}[node distance=2cm, line width=1pt,every node/.style={align=center}]




\node (teach1) [layer11]  at (-9.75,0) {};
\node (teach2) [layer12]  at (-9.25,0) {};
\node (teach3) [layer13]  at (-8.75,0) {};
\node (teach4) [layer14]  at (-8.25,0) {};


\path[yshift=1.5cm, xshift=-0.5cm] node[hidden neuron] (H11) at (-7,-0.5 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm]node[hidden neuron] (H12) at (-7,-1 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm] node[hidden neuron] (H13) at (-7,-1.5 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm]node[hidden neuron] (H14) at (-7,-2 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm] node[hidden neuron] (H15) at (-7,-2.5 cm) {};

\path[yshift=1.5cm, xshift=-0.5cm] node[output neuron] (O11) at (-6.5,-1 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm] node[output neuron] (O12) at (-6.5,-1.5 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm] node[output neuron] (O13) at (-6.5,-2 cm) {};

\node (out1) [output neuron, right of=H13, xshift=-1cm] {};
\begin{scope}[on background layer]
    \node (teacher) [fit=(teach1) (teach2) (teach3) (teach4) (H11) (H12) (H13) (H14) (H15) (O11) (O12) (O13) (out1), fill= gray!20, rounded corners, inner sep=.2cm, label={below:Teacher Model\\(Full Precision)}] {};
\end{scope}







\node (stu1) [layer1]  at (7.5,0) {};
\node (stu2) [layer2]  at (7,0) {};
\node (stu3) [layer3]  at (6.5,0) {};
\node (stu4) [layer4]  at (6,0) {};

\path[yshift=1.5cm, xshift=-0.5cm] node[hidden neuron] (H1) at (5.75,-0.5 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm]node[hidden neuron] (H2) at (5.75,-1 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm] node[hidden neuron] (H3) at (5.75,-1.5 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm]node[hidden neuron] (H4) at (5.75,-2 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm] node[hidden neuron] (H5) at (5.75,-2.5 cm) {};

\path[yshift=1.5cm, xshift=-0.5cm] node[output neuron] (O1) at (5.25,-1 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm] node[output neuron] (O2) at (5.25,-1.5 cm) {};
\path[yshift=1.5cm, xshift=-0.5cm] node[output neuron] (O3) at (5.25,-2 cm) {};

\node (out) [output neuron, left of=H3, xshift=1cm] {};
\begin{scope}[on background layer]
    \node (student) [fit=(stu1) (stu2) (stu3) (stu4) (H1) (H2) (H3) (H4) (H5) (O1) (O2) (O3) (out), fill= gray!20, rounded corners, inner sep=.2cm, label={below:Student Model\\(Binary Precision)}] {};
\end{scope}


\node (x_recon) [draw, left of=out] {$f_{student}(\mathcal{X})$};
\node (y_labels) [draw, right of=out1] {$f_{teacher}(\mathcal{X})$};

\node (classification_loss) [draw, left of=x_recon, xshift=-40] {Knowledge Distillation Loss\\$Loss_{KD}$ ($f_{student}, f_{teacher}$)};



\draw[thick,->] ([xshift=0.7cm] classification_loss.south) |- node[anchor=north, yshift=-0cm, xshift=1.5cm] {Weight Update\\(Backpropagation)} ([yshift=-1cm]student.west);
\draw[thick,->] (teacher.east) -- node[anchor=north] {} (y_labels.west);
\draw[thick,->] (y_labels.east) -- node[anchor=north] {} (classification_loss.west);
\draw[thick,->] (x_recon.west) |- node[anchor=north] {} (classification_loss.east);
\draw[thick,->] (student.west) -- node[anchor=north] {} (x_recon);

\end{tikzpicture}
}
\caption{\underline{\textbf{Improving the Binary Model Performance.}} The full precision model is used as a teacher model and the loss function uses the soft labels of the teacher as the target to train and update the Binary Model's performance. The resultant Binary model has a higher test accuracy trained using this fashion at the cost of a small increase in Membership Inference accuracy.}
\label{fig:advclassifier}
\end{figure}
