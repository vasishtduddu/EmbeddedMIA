%\documentclass[conference]{IEEEtran}
\documentclass{article}

\usepackage[final]{neurips_2020}

\usepackage{multirow}
\usepackage{subfig}
%\usepackage{enumitem}
\usepackage{colortbl}
%\usepackage{pifont}
\usepackage{wasysym}
\usepackage{xspace}
\usepackage{dblfloatfix}
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{backgrounds, positioning, fit}
\usetikzlibrary{shapes.geometric}
\usetikzlibrary{patterns}
\usetikzlibrary{pgfplots.groupplots}
%\usepackage{subfigure}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{hyperref}
%\usepackage{biblatex}

\newcommand{\cmark}{\CIRCLE}
\newcommand{\xmark}{\Circle}
\newcommand{\smark}{\LEFTcircle}



\begin{document}

\title{Privacy Risks in Embedded Deep Learning}


\author{
Vasisht Duddu \\
Univ Lyon, INSA Lyon, Inria, CITI\\
\texttt{vduddu@tutamail.com}\\
\and
Virat Shejwalkar\\
Univ Massachusetts Amherst\\
\texttt{vshejwalkar@cs.umass.edu}\\
\and
Antoine Boutet\\
Univ Lyon, INSA Lyon, Inria, CITI\\
\texttt{antoine.boutet@insa-lyon.fr}\\
}




\maketitle


\begin{abstract}
Embedded systems demand on-device processing of data using Neural Networks (NNs) while conforming to the memory, power and computation constraints, leading to an efficiency and accuracy tradeoff. To bring NNs to edge devices, several optimizations such as model compression through pruning, quantization, and off-the-shelf architectures with efficient design have been extensively adopted. These algorithms when deployed to real world sensitive applications, requires to resist inference attacks to protect privacy of userâ€™s training data. However, resistance against inference attacks is not accounted for designing NN models for embedded systems. In this work, we analyse the three-dimensional privacy-accuracy-efficiency tradeoff in NNs for embedded systems and propose Gecko training methodology where we explicitly add resistance to private inferences as a design objective.
We optimize the inference-time memory, computation, and power constraints of embedded devices as a criterion for designing NN architecture while also preserving privacy.
We choose quantization as design choice for highly efficient and private models. This choice is driven by the observation that compressed models leak more information compared to baseline models while off-the-shelf efficient architectures indicate poor efficiency and privacy tradeoff.
\end{abstract}



\input{introduction}
\input{evaluation}
\input{discussions}



\bibliographystyle{acm}
\bibliography{paper.bib}
%\printbibliography

\input{appendix}

\end{document}
%\endinput
