\section{Experimental setting}
\label{setting}

We carried out an extensive evaluation of \method. %the three state of the art design techniques for efficient model computation.
%: a) Model Compression via pruning redundant parameters and nodes, b) Quantization to lower the precision of model parameters and activations, and c) Efficient off-the-shelf architectures.
%
%We show that ... In addition, we show that ... 
We first describe the datasets and architectures used in this analysis in Section~\ref{datasets} before to present the considered comparative baselines and metrics in Section~\ref{baselines} and Section~\ref{metrics}, respectively. %Finally, we analyse efficiency Section~\ref{eval-efficiency} and privacy leakage Section~\ref{eval-leakage}.


\subsection{Datasets and Architectures}
\label{datasets}

For evaluating and comparing different efficiency algorithms, we use four datasets: FashionMNIST, Purchase100, Location, and CIFAR10.
For Location and Purchase100 datasets, we train the model for 50 epochs while for FashionMNIST dataset we train the model for 75 epochs. 
For CIFAR10, we train the models for 100-150 epochs.
%These provide us with the necessary direction to choose the optimal efficiency algorithm which satisfies all the efficiency and privacy requirement as describes in Section~\ref{motivate}.

\noindent\textbf{FashionMNIST.} This dataset consists of 60,000 training examples and a test set of 10,000 examples.
Each data record is a 28$\times$28 grayscale image which is mapped to one of 10 classes consisting of fashion products such as coat, sneaker, shirt, shoes.
For this dataset, we use a modified LeNet architecture with two convolution layers followed by maxpool and dense layers: [Conv 32 (3,3), Conv 64 (3,3), Maxpool (2,2), Dense 128, Dense 10] (Architecture 1). Additionally, we use a fully connected model [512,512,512] (Architecture 2).

\noindent\textbf{Purchase100.} This dataset is a privacy sensitive dataset capturing the purchase preferences of online customers taken from the authors of~\cite{shokri2017membership}.
The data records have 600 binary features and each record is classified into one of 100 classes identifying each user's purchase.
For this dataset, we use a fully connected architecture with the nodes in each layers as [1024,512,256,128,100].

\noindent\textbf{Location.} This dataset is a privacy sensitive dataset capturing user's location "check-ins" taken from the authors of~\cite{shokri2017membership} where each record has 446 binary features which is mapped to one of 30 classes each representing a location. For this dataset we use a fully connected architecture with hyperparameters as [512,256,128,30].



%The \method\hspace{0.02in} NN design methodology is evaluated on sophisticated dataset: 
\noindent\textbf{CIFAR10}. 
%This dataset has been commonly used for evaluating defences against membership inference attacks, it enables to accurately compare our work with prior state of the art defences~\cite{Abadi:2016:DLD:2976749.2978318,10.1145/3319535.3363201,DBLP:conf/ccs/NasrSH18}.
%The optimization described as part of \method\hspace{0.02in} is for large convolutional NNs and does not cover the fully connected dense layers % (detailed description in Section~\ref{}) 
%which are used for Purchase100 and Location datasets.
%It is important to evaluate on standard architectures as different custom classifiers tend to underestimate the inference leakage due to hyperparameter settings.
This dataset is a major image classification benchmarking dataset where the data records are composed of 32$\times$32 RGB images where each record is mapped to one of 10 classes of common objects such as airplane, bird, cat, dog.
For this dataset, we use standard state of the art architectures: Network in Network (NiN), AlexNet and VGGNet. 
%In addition, we train the models using standard hyperparameter setting for 100-150 epochs.


\subsection{Comparative Baselines}
\label{baselines}

\subsubsection{NN models for embedded systems}

%In order to execute trained NN models on low powered edge devices, optimizations are required for the design of the NN architectures.
Model designers use three state of the art approaches for designing efficient NN models for embedded systems: (a) Model Compression via Pruning, (b) quantization of model parameters and activations and (c) designing standard architectures (off the shelf efficient architectures).
%In this work, we consider these three approaches as baselines for comparison and evaluation to select the choice of optimization for \method.

\begin{itemize}[leftmargin=*]
\item {\em Model Compression (Pruning).} 
NNs are overparameterized, i.e, have large number of redundant weights.
Pruning of the network refers to removing these redundant weights (setting them as zero) without a degradation of model accuracy.
The pruning operation results in a model with sparse parameters for which the hardware can be designed to skip the multiplication and memory storage, improving the efficiency.
Sparse weights can be stored in a compressed format in the hardware using the compressed sparse row or column format which reduces the overall memory bandwidth~\cite{DBLP:journals/corr/HanMD15,10.1109/ISCA.2016.30,Han:2015:LBW:2969239.2969366}.
Aggressive pruning, while compresses the model significantly, requires to be re-trained to restore the model's original accuracy.
For a threshold $T$, the parameters close to zero are replaced by zero which is given as:
\[
\footnotesize
    f(W)=
\begin{cases}
    0, & \text{if } -T \leq w \leq T\\
    w,  & \text{otherwise}
\end{cases}
\]

\item {\em Off-the-Shelf Efficient Architectures.} 
NNs can be redesigned by changing the hyperparameters (filter size in convolution, number of layers and their types) to reduce the number of parameters and hence, the memory footprint.
One approach is to replace larger convolution filters with multiple smaller filters with less number of parameters but covering the same receptive fields.
For instance, one 5x5 filter can be replaced by two 3x3 filters.
Alternatively, 1x1 convolutional layers reduce the number of channels in output feature map, lowering the computation and number of parameters.
For instance, for an input activation of dimension 1x1x64, 32 1x1 convolutional filters downsamples the activation maps to get an output of 32 channels.
Such optimizations enable to design compact network architecture with layers having lower parameters compared to the original model, extensively adopted in MobileNet~\cite{conf/cvpr/SandlerHZZC18} and SqueezeNet~\cite{DBLP:journals/corr/IandolaMAHDK16}.


\item {\em Quantization.}
Quantization reduces the precision of the model's parameters and the intermediate activations during execution.
Quantization maps parameters and activations values to a fixed set of quantization levels~\cite{Hubara:2017:QNN:3122009.3242044}.
The number of quantized levels determines the precision of the operands ($log_2(\#levels)$).
Reducing the precision of the (a) parameters lowers the storage cost of the model in memory, (b) activations lowers the computation overhead by replacing MACs with binary arithmetic and (c) lowers the energy consumption by lowering the memory accesses and increasing throughput.
Aggressively quantizing the parameters and activations to binary and ternary precision significantly improves the overall efficiency, however, at the cost of accuracy~\cite{rastegari2016xnornet}.
For instance, Binarized NNs quantize the operands to \{-1,+1\} values~\cite{NIPS2016_6573} while ternary NNs have values \{-w, 0, w\} where $w$ can be fixed or learnt during training~\cite{Li2016TernaryWN}. These are examples of uniform quantization.
Alternatively, weight sharing maps several parameters to a single value reducing the number of unique parameters.
This mapping is done using K-Means clustering or a hashing function and the corresponding shared values are read from a "codebook" which maps different parameters to its shared value.
\end{itemize}


\subsubsection{Privacy defences}


%In this work, 
We consider two state of the art baselines: Adversarial Regularization and Differential Privacy.
These defences have mainly focussed on improving the model's generalization and reduce overfitting which has been considered as the main cause for leakage through membership inference attacks.

\begin{itemize}[leftmargin=*]
\item {\em Adversarial Regularization (AdvReg)~\cite{DBLP:conf/ccs/NasrSH18}.} Here, the problem of defending against membership inference attack is modelled as a minimax game between two NNs: classifier network and attacker network.
The two networks are trained alternatively with contradictory objectives: first, the attacker network is trained to distinguish between the training data members and non-members followed by training the classifier network to minimize the loss as well as fool the attacker network.
Formally, the target classifier outputs a single probability $I(F(x),y) \in [0,1]$ which indicates the likelihood of $x$ being part of the training data.
The classifier minimizes the loss along with the output of the attacker classifier balanced with a privacy risk hyperparameter $\lambda$ : $min_{\theta} l(F(x),y) + \lambda log(I(F(x),y))$.

\item {\em Differential Privacy (DP)~\cite{Abadi:2016:DLD:2976749.2978318}.} In this work, we specifically consider DP-SGD which adds carefully crafted noise to the gradients during backpropagation in SGD algorithm.
The noise is sampled from a Laplacian or Gaussian distribution proportional to the model's Sensitivity which is then added to the gradients during backpropagation.
This provides provable bound on the information leaked about an individual data record in the dataset and ensures that the presence or absence of a data record does not change the model's output, hence defending against membership inference attacks.
\end{itemize}

\subsection{Metrics}
\label{metrics}

\paragraph{Efficiency} We evaluate efficiency of the three baseline algorithms based on Memory efficiency, Computation efficiency and Energy efficiency. Memory efficiency is compared based on the reduction in the memory footprint of the model computed from the parameters stored in the memory. Computation efficiency is compared based on the reduction in the MAC operations which influences the execution time. Finally, the energy consumption is compared based on memory accesses from reading inputs and writing results to the memory. Since, significant literature has compared the efficiency empirically, we provide a qualitative comparison for the baseline algorithms.

\paragraph{Privacy}
We use the inference attack accuracy to estimate the success of membership inference attack.
An accuracy above random guess $50\%$ indicates a training data leakage through membership inference attack.
This indicates that the adversary is able to identify the membership details of a data record with an accuracy higher than random guess.
The success of inference attack accuracy is strongly correlated with the model's extent of overfitting empirically measured as the difference between the train and test accuracy (generalization error). Higher generalization error (overfitting) results in higher distinguishability between the test and train resulting in higher membership inference accuracy~\cite{shokri2017membership}.
Additionally, the accuracy of the model is computed using the model's performance on unseen test data.



